20/02/19 05:39:54 INFO SparkContext: Running Spark version 2.2.1
20/02/19 05:39:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/19 05:39:55 INFO SparkContext: Submitted application: sparklyr
20/02/19 05:39:55 INFO SecurityManager: Changing view acls to: Reinhard
20/02/19 05:39:55 INFO SecurityManager: Changing modify acls to: Reinhard
20/02/19 05:39:55 INFO SecurityManager: Changing view acls groups to: 
20/02/19 05:39:55 INFO SecurityManager: Changing modify acls groups to: 
20/02/19 05:39:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Reinhard); groups with view permissions: Set(); users  with modify permissions: Set(Reinhard); groups with modify permissions: Set()
20/02/19 05:39:55 INFO Utils: Successfully started service 'sparkDriver' on port 61659.
20/02/19 05:39:55 INFO SparkEnv: Registering MapOutputTracker
20/02/19 05:39:55 INFO SparkEnv: Registering BlockManagerMaster
20/02/19 05:39:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/19 05:39:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/19 05:39:55 INFO DiskBlockManager: Created local directory at C:\Users\Reinhard\AppData\Local\Temp\blockmgr-6f855abe-f510-4472-ad68-b670e3cac025
20/02/19 05:39:55 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
20/02/19 05:39:55 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/19 05:39:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/19 05:39:56 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/19 05:39:56 INFO SparkContext: Added JAR file:/D:/apps/R/R-3.6.1/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:61659/jars/sparklyr-2.0-2.11.jar with timestamp 1582087196368
20/02/19 05:39:56 INFO Executor: Starting executor ID driver on host localhost
20/02/19 05:39:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61681.
20/02/19 05:39:56 INFO NettyBlockTransferService: Server created on 127.0.0.1:61681
20/02/19 05:39:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/19 05:39:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61681, None)
20/02/19 05:39:56 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61681 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 61681, None)
20/02/19 05:39:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61681, None)
20/02/19 05:39:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61681, None)
20/02/19 05:39:57 INFO SharedState: loading hive config file: file:/C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/conf/hive-site.xml
20/02/19 05:39:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive').
20/02/19 05:39:57 INFO SharedState: Warehouse path is 'C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive'.
20/02/19 05:39:58 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/02/19 05:39:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 05:40:00 INFO CodeGenerator: Code generated in 206.8825 ms
20/02/19 06:07:50 INFO SparkContext: Running Spark version 2.2.1
20/02/19 06:07:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/19 06:07:50 INFO SparkContext: Submitted application: sparklyr
20/02/19 06:07:50 INFO SecurityManager: Changing view acls to: Reinhard
20/02/19 06:07:50 INFO SecurityManager: Changing modify acls to: Reinhard
20/02/19 06:07:50 INFO SecurityManager: Changing view acls groups to: 
20/02/19 06:07:50 INFO SecurityManager: Changing modify acls groups to: 
20/02/19 06:07:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Reinhard); groups with view permissions: Set(); users  with modify permissions: Set(Reinhard); groups with modify permissions: Set()
20/02/19 06:07:50 INFO Utils: Successfully started service 'sparkDriver' on port 64567.
20/02/19 06:07:50 INFO SparkEnv: Registering MapOutputTracker
20/02/19 06:07:50 INFO SparkEnv: Registering BlockManagerMaster
20/02/19 06:07:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/19 06:07:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/19 06:07:50 INFO DiskBlockManager: Created local directory at C:\Users\Reinhard\AppData\Local\Temp\blockmgr-f51b108e-01dc-4397-91de-db357d7a3b4b
20/02/19 06:07:50 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
20/02/19 06:07:50 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/19 06:07:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
20/02/19 06:07:50 INFO Utils: Successfully started service 'SparkUI' on port 4041.
20/02/19 06:07:50 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
20/02/19 06:07:50 INFO SparkContext: Added JAR file:/D:/apps/R/R-3.6.1/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:64567/jars/sparklyr-2.0-2.11.jar with timestamp 1582088870893
20/02/19 06:07:50 INFO Executor: Starting executor ID driver on host localhost
20/02/19 06:07:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64588.
20/02/19 06:07:50 INFO NettyBlockTransferService: Server created on 127.0.0.1:64588
20/02/19 06:07:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/19 06:07:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64588, None)
20/02/19 06:07:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64588 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 64588, None)
20/02/19 06:07:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64588, None)
20/02/19 06:07:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64588, None)
20/02/19 06:07:52 INFO SparkContext: Invoking stop() from shutdown hook
20/02/19 06:07:52 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
20/02/19 06:07:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/19 06:07:52 INFO MemoryStore: MemoryStore cleared
20/02/19 06:07:52 INFO BlockManager: BlockManager stopped
20/02/19 06:07:52 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/19 06:07:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/19 06:07:52 INFO SparkContext: Successfully stopped SparkContext
20/02/19 06:07:52 INFO ShutdownHookManager: Shutdown hook called
20/02/19 06:07:52 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-91b53ebe-41a8-4867-84ac-d1deb9bf8289
20/02/19 06:13:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:13:45 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:13:45 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:13:45 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
20/02/19 06:13:45 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:13:45 INFO DAGScheduler: Missing parents: List()
20/02/19 06:13:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
20/02/19 06:13:46 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/19 06:13:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 413.9 MB)
20/02/19 06:13:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.9 MB)
20/02/19 06:13:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:13:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/19 06:13:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
20/02/19 06:13:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/19 06:13:46 INFO Executor: Fetching spark://127.0.0.1:61659/jars/sparklyr-2.0-2.11.jar with timestamp 1582087196368
20/02/19 06:13:46 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61659 after 16 ms (0 ms spent in bootstraps)
20/02/19 06:13:46 INFO Utils: Fetching spark://127.0.0.1:61659/jars/sparklyr-2.0-2.11.jar to C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63\fetchFileTemp2844025491001011047.tmp
20/02/19 06:13:46 INFO Executor: Adding file:/C:/Users/Reinhard/AppData/Local/Temp/spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913/userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63/sparklyr-2.0-2.11.jar to class loader
20/02/19 06:13:46 INFO CodeGenerator: Code generated in 6.0338 ms
20/02/19 06:13:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
20/02/19 06:13:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 639 ms on localhost (executor driver) (1/1)
20/02/19 06:13:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/19 06:13:46 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.666 s
20/02/19 06:13:46 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.978344 s
20/02/19 06:13:47 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:13:47 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
20/02/19 06:13:47 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:13:47 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:13:47 INFO CodeGenerator: Code generated in 11.6802 ms
20/02/19 06:13:47 INFO CodeGenerator: Code generated in 12.5173 ms
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 253.9 KB, free 413.7 MB)
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.6 MB)
20/02/19 06:13:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO SparkContext: Created broadcast 1 from csv at <unknown>:0
20/02/19 06:13:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:13:47 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:13:47 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:13:47 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
20/02/19 06:13:47 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:13:47 INFO DAGScheduler: Missing parents: List()
20/02/19 06:13:47 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0), which has no missing parents
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 413.6 MB)
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.6 MB)
20/02/19 06:13:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/19 06:13:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:13:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/19 06:13:47 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:13:47 INFO CodeGenerator: Code generated in 5.2892 ms
20/02/19 06:13:47 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:13:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1275 bytes result sent to driver
20/02/19 06:13:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 97 ms on localhost (executor driver) (1/1)
20/02/19 06:13:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/19 06:13:47 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 0.097 s
20/02/19 06:13:47 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 0.113456 s
20/02/19 06:13:47 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:13:47 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:13:47 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:13:47 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:13:47 INFO CodeGenerator: Code generated in 3.938 ms
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 253.9 KB, free 413.4 MB)
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.4 MB)
20/02/19 06:13:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO SparkContext: Created broadcast 3 from csv at <unknown>:0
20/02/19 06:13:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:13:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:13:47 INFO DAGScheduler: Got job 2 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:13:47 INFO DAGScheduler: Final stage: ResultStage 2 (csv at <unknown>:0)
20/02/19 06:13:47 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:13:47 INFO DAGScheduler: Missing parents: List()
20/02/19 06:13:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0), which has no missing parents
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.9 KB, free 413.6 MB)
20/02/19 06:13:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.6 MB)
20/02/19 06:13:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:13:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/19 06:13:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:13:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/19 06:13:47 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:13:47 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:13:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1425 bytes result sent to driver
20/02/19 06:13:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 92 ms on localhost (executor driver) (1/1)
20/02/19 06:13:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/19 06:13:48 INFO DAGScheduler: ResultStage 2 (csv at <unknown>:0) finished in 0.093 s
20/02/19 06:13:48 INFO DAGScheduler: Job 2 finished: csv at <unknown>:0, took 0.101450 s
20/02/19 06:13:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:13:48 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:13:48 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:13:48 INFO FileSourceStrategy: Output Data Schema: struct<kmer	count: string>
20/02/19 06:13:48 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 4.8492 ms
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 254.9 KB, free 413.4 MB)
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.4 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.9 MB)
20/02/19 06:13:48 INFO SparkContext: Created broadcast 5 from sql at <unknown>:0
20/02/19 06:13:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 7.401 ms
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 6.1506 ms
20/02/19 06:13:48 INFO ContextCleaner: Cleaned accumulator 114
20/02/19 06:13:48 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:13:48 INFO DAGScheduler: Registering RDD 18 (sql at <unknown>:0)
20/02/19 06:13:48 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:13:48 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
20/02/19 06:13:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/19 06:13:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/19 06:13:48 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.7 KB, free 413.4 MB)
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.9 MB)
20/02/19 06:13:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/19 06:13:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:13:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/19 06:13:48 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:13:48 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:13:48 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 81.7 KB, free 413.3 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:61681 (size: 81.7 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 2.7581 ms
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 13.2179 ms
20/02/19 06:13:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
20/02/19 06:13:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 244 ms on localhost (executor driver) (1/1)
20/02/19 06:13:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/19 06:13:48 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 0.245 s
20/02/19 06:13:48 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:13:48 INFO DAGScheduler: running: Set()
20/02/19 06:13:48 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/19 06:13:48 INFO DAGScheduler: failed: Set()
20/02/19 06:13:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0), which has no missing parents
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/19 06:13:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:13:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/19 06:13:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:13:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
20/02/19 06:13:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
20/02/19 06:13:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 39 ms on localhost (executor driver) (1/1)
20/02/19 06:13:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/19 06:13:48 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.040 s
20/02/19 06:13:48 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 0.326117 s
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:13:48 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO CodeGenerator: Code generated in 4.0148 ms
20/02/19 06:13:48 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:13:48 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
20/02/19 06:13:48 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:13:48 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
20/02/19 06:13:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/02/19 06:13:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
20/02/19 06:13:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.7 KB, free 413.2 MB)
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.1 KB, free 413.2 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/19 06:13:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:13:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/19 06:13:48 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:13:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1737 bytes result sent to driver
20/02/19 06:13:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
20/02/19 06:13:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/19 06:13:48 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.012 s
20/02/19 06:13:48 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:13:48 INFO DAGScheduler: running: Set()
20/02/19 06:13:48 INFO DAGScheduler: waiting: Set(ResultStage 6)
20/02/19 06:13:48 INFO DAGScheduler: failed: Set()
20/02/19 06:13:48 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 413.2 MB)
20/02/19 06:13:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.2 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/19 06:13:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:13:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/19 06:13:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:13:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:13:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1495 bytes result sent to driver
20/02/19 06:13:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:13:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/19 06:13:48 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
20/02/19 06:13:48 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.031723 s
20/02/19 06:13:48 INFO ContextCleaner: Cleaned accumulator 175
20/02/19 06:13:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:13:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz1`
WHERE (0 = 1)
20/02/19 06:13:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:13:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
LIMIT 1000
20/02/19 06:13:49 INFO CodeGenerator: Code generated in 4.799 ms
20/02/19 06:13:49 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:13:49 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:13:49 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
20/02/19 06:13:49 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:13:49 INFO DAGScheduler: Missing parents: List()
20/02/19 06:13:49 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[29] at collect at utils.scala:204), which has no missing parents
20/02/19 06:13:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 13.8 KB, free 413.3 MB)
20/02/19 06:13:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.6 KB, free 413.2 MB)
20/02/19 06:13:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.8 MB)
20/02/19 06:13:49 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
20/02/19 06:13:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:13:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/19 06:13:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:13:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/19 06:13:49 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:13:49 INFO CodeGenerator: Code generated in 9.7454 ms
20/02/19 06:13:49 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_15_0]
20/02/19 06:13:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 10537 bytes result sent to driver
20/02/19 06:13:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 50 ms on localhost (executor driver) (1/1)
20/02/19 06:13:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/19 06:13:49 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.051 s
20/02/19 06:13:49 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.057619 s
20/02/19 06:13:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:14:41 INFO CodeGenerator: Code generated in 5.8595 ms
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:14:41 INFO DAGScheduler: Got job 6 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:14:41 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:44)
20/02/19 06:14:41 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:14:41 INFO DAGScheduler: Missing parents: List()
20/02/19 06:14:41 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at map at utils.scala:41), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.9 KB, free 413.3 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.3 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 894 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:14:41 INFO DAGScheduler: Job 6 finished: collect at utils.scala:44, took 0.009475 s
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:14:41 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
20/02/19 06:14:41 INFO BlockManager: Removing RDD 15
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 261
20/02/19 06:14:41 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:14:41 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#109)) > 0)
20/02/19 06:14:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:14:41 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 253.9 KB, free 413.1 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.1 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 12 from csv at <unknown>:0
20/02/19 06:14:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:14:41 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:14:41 INFO DAGScheduler: Got job 7 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:14:41 INFO DAGScheduler: Final stage: ResultStage 9 (csv at <unknown>:0)
20/02/19 06:14:41 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:14:41 INFO DAGScheduler: Missing parents: List()
20/02/19 06:14:41 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[37] at csv at <unknown>:0), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.2 KB, free 413.1 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.1 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/19 06:14:41 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:14:41 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1189 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ResultStage 9 (csv at <unknown>:0) finished in 0.007 s
20/02/19 06:14:41 INFO DAGScheduler: Job 7 finished: csv at <unknown>:0, took 0.013055 s
20/02/19 06:14:41 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:14:41 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:14:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:14:41 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 253.9 KB, free 412.8 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 288
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 286
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 289
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 291
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 290
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 287
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.1 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 14 from csv at <unknown>:0
20/02/19 06:14:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:14:41 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:14:41 INFO DAGScheduler: Got job 8 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:14:41 INFO DAGScheduler: Final stage: ResultStage 10 (csv at <unknown>:0)
20/02/19 06:14:41 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:14:41 INFO DAGScheduler: Missing parents: List()
20/02/19 06:14:41 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[42] at csv at <unknown>:0), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 13.9 KB, free 413.1 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.1 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[42] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/19 06:14:41 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:14:41 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1425 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 18 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ResultStage 10 (csv at <unknown>:0) finished in 0.019 s
20/02/19 06:14:41 INFO DAGScheduler: Job 8 finished: csv at <unknown>:0, took 0.023358 s
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:14:41 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:14:41 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:14:41 INFO FileSourceStrategy: Output Data Schema: struct<kmer	count: string>
20/02/19 06:14:41 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 254.9 KB, free 412.8 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 121
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 54
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 52
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 318
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 320
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 317
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 316
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 319
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 0
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 123
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 126
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 120
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 81
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.1 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 122
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 82
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 50
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 53
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 125
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 117
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 80
20/02/19 06:14:41 INFO SparkContext: Created broadcast 16 from sql at <unknown>:0
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:14:41 INFO ContextCleaner: Cleaned shuffle 0
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 49
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 116
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 118
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 83
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 119
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 51
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 79
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 124
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 115
20/02/19 06:14:41 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:14:41 INFO DAGScheduler: Registering RDD 48 (sql at <unknown>:0)
20/02/19 06:14:41 INFO DAGScheduler: Got job 9 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:14:41 INFO DAGScheduler: Final stage: ResultStage 12 (sql at <unknown>:0)
20/02/19 06:14:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
20/02/19 06:14:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
20/02/19 06:14:41 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[48] at sql at <unknown>:0), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 17.7 KB, free 413.4 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.1 KB, free 413.4 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.9 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[48] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/19 06:14:41 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:14:41 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:14:41 INFO MemoryStore: Block rdd_45_0 stored as values in memory (estimated size 81.7 KB, free 413.3 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added rdd_45_0 in memory on 127.0.0.1:61681 (size: 81.7 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2461 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 49 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ShuffleMapStage 11 (sql at <unknown>:0) finished in 0.050 s
20/02/19 06:14:41 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:14:41 INFO DAGScheduler: running: Set()
20/02/19 06:14:41 INFO DAGScheduler: waiting: Set(ResultStage 12)
20/02/19 06:14:41 INFO DAGScheduler: failed: Set()
20/02/19 06:14:41 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[51] at sql at <unknown>:0), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[51] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/19 06:14:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:14:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1495 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ResultStage 12 (sql at <unknown>:0) finished in 0.006 s
20/02/19 06:14:41 INFO DAGScheduler: Job 9 finished: sql at <unknown>:0, took 0.076407 s
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 354
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 353
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 357
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 351
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 361
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 356
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 355
20/02/19 06:14:41 INFO ContextCleaner: Cleaned accumulator 360
20/02/19 06:14:41 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:14:41 INFO DAGScheduler: Registering RDD 54 (collect at utils.scala:204)
20/02/19 06:14:41 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:14:41 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
20/02/19 06:14:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
20/02/19 06:14:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
20/02/19 06:14:41 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.7 KB, free 413.3 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 9.1 KB, free 413.3 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/19 06:14:41 INFO BlockManager: Found block rdd_45_0 locally
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1737 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:204) finished in 0.009 s
20/02/19 06:14:41 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:14:41 INFO DAGScheduler: running: Set()
20/02/19 06:14:41 INFO DAGScheduler: waiting: Set(ResultStage 14)
20/02/19 06:14:41 INFO DAGScheduler: failed: Set()
20/02/19 06:14:41 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204), which has no missing parents
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:14:41 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:14:41 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:14:41 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
20/02/19 06:14:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:14:41 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/19 06:14:41 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:14:41 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/02/19 06:14:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:14:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:14:41 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1495 bytes result sent to driver
20/02/19 06:14:41 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:14:41 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/19 06:14:41 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:14:41 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.025842 s
20/02/19 06:14:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz2`
WHERE (0 = 1)
20/02/19 06:14:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:15:13 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:15:13 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:15:13 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:44)
20/02/19 06:15:13 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:15:13 INFO DAGScheduler: Missing parents: List()
20/02/19 06:15:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[62] at map at utils.scala:41), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 5.9 KB, free 413.3 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.3 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[62] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 894 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:15:13 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0.009000 s
20/02/19 06:15:13 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:15:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#189)) > 0)
20/02/19 06:15:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:15:13 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 473
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned shuffle 3
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 253.9 KB, free 413.1 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.0 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 22 from csv at <unknown>:0
20/02/19 06:15:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:15:13 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:15:13 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:15:13 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
20/02/19 06:15:13 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:15:13 INFO DAGScheduler: Missing parents: List()
20/02/19 06:15:13 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at csv at <unknown>:0), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.2 KB, free 413.0 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.0 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
20/02/19 06:15:13 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:15:13 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1189 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:15:13 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0.010715 s
20/02/19 06:15:13 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:15:13 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:15:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:15:13 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 253.9 KB, free 412.8 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.7 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 24 from csv at <unknown>:0
20/02/19 06:15:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:15:13 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:15:13 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:15:13 INFO DAGScheduler: Final stage: ResultStage 17 (csv at <unknown>:0)
20/02/19 06:15:13 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:15:13 INFO DAGScheduler: Missing parents: List()
20/02/19 06:15:13 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[70] at csv at <unknown>:0), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 13.9 KB, free 412.7 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.9 KB, free 412.7 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[70] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
20/02/19 06:15:13 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:15:13 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1382 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 14 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ResultStage 17 (csv at <unknown>:0) finished in 0.015 s
20/02/19 06:15:13 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0.019848 s
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:15:13 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:15:13 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:15:13 INFO FileSourceStrategy: Output Data Schema: struct<kmer	count: string>
20/02/19 06:15:13 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 500
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 530
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 499
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 502
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 531
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 498
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 254.9 KB, free 412.5 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 532
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 529
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 503
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 501
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 528
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.0 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 26 from sql at <unknown>:0
20/02/19 06:15:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:15:13 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:15:13 INFO DAGScheduler: Registering RDD 76 (sql at <unknown>:0)
20/02/19 06:15:13 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:15:13 INFO DAGScheduler: Final stage: ResultStage 19 (sql at <unknown>:0)
20/02/19 06:15:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
20/02/19 06:15:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
20/02/19 06:15:13 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[76] at sql at <unknown>:0), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 17.7 KB, free 413.0 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.1 KB, free 413.0 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[76] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
20/02/19 06:15:13 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:15:13 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:15:13 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 82.0 KB, free 412.9 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:61681 (size: 82.0 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2418 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 40 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ShuffleMapStage 18 (sql at <unknown>:0) finished in 0.041 s
20/02/19 06:15:13 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:15:13 INFO DAGScheduler: running: Set()
20/02/19 06:15:13 INFO DAGScheduler: waiting: Set(ResultStage 19)
20/02/19 06:15:13 INFO DAGScheduler: failed: Set()
20/02/19 06:15:13 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[79] at sql at <unknown>:0), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[79] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
20/02/19 06:15:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1452 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ResultStage 19 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:15:13 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0.055854 s
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 570
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 565
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 563
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 624
20/02/19 06:15:13 INFO ContextCleaner: Cleaned shuffle 4
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 573
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 568
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 571
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 572
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 564
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 566
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 575
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 569
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 574
20/02/19 06:15:13 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO ContextCleaner: Cleaned accumulator 567
20/02/19 06:15:13 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:15:13 INFO DAGScheduler: Registering RDD 82 (collect at utils.scala:204)
20/02/19 06:15:13 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:15:13 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
20/02/19 06:15:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
20/02/19 06:15:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
20/02/19 06:15:13 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[82] at collect at utils.scala:204), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 17.7 KB, free 412.9 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 9.1 KB, free 412.9 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[82] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
20/02/19 06:15:13 INFO BlockManager: Found block rdd_73_0 locally
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1737 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 14 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.015 s
20/02/19 06:15:13 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:15:13 INFO DAGScheduler: running: Set()
20/02/19 06:15:13 INFO DAGScheduler: waiting: Set(ResultStage 21)
20/02/19 06:15:13 INFO DAGScheduler: failed: Set()
20/02/19 06:15:13 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[85] at collect at utils.scala:204), which has no missing parents
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:15:13 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:15:13 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:15:13 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[85] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:13 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/02/19 06:15:13 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:15:13 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
20/02/19 06:15:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:15:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:15:13 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1495 bytes result sent to driver
20/02/19 06:15:13 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:15:13 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/02/19 06:15:13 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:15:13 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.029418 s
20/02/19 06:15:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz3`
WHERE (0 = 1)
20/02/19 06:15:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
LIMIT 11
20/02/19 06:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
LIMIT 11
20/02/19 06:15:49 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:15:49 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:15:49 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
20/02/19 06:15:49 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:15:49 INFO DAGScheduler: Missing parents: List()
20/02/19 06:15:49 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
20/02/19 06:15:49 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 13.8 KB, free 412.9 MB)
20/02/19 06:15:49 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.9 MB)
20/02/19 06:15:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:15:49 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
20/02/19 06:15:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:15:49 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/02/19 06:15:49 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:15:49 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
20/02/19 06:15:49 INFO BlockManager: Found block rdd_73_0 locally
20/02/19 06:15:49 INFO Executor: 1 block locks were not released by TID = 22:
[rdd_73_0]
20/02/19 06:15:49 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1322 bytes result sent to driver
20/02/19 06:15:49 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:15:49 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/02/19 06:15:49 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:15:49 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.009628 s
20/02/19 06:15:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:15 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:18:15 INFO DAGScheduler: Got job 17 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:18:15 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:44)
20/02/19 06:18:15 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:15 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:15 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[92] at map at utils.scala:41), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 5.9 KB, free 412.9 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.3 KB, free 412.9 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[92] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:18:15 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
20/02/19 06:18:15 INFO Executor: Running task 1.0 in stage 23.0 (TID 24)
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 851 bytes result sent to driver
20/02/19 06:18:15 INFO Executor: Finished task 1.0 in stage 23.0 (TID 24). 851 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 4 ms on localhost (executor driver) (1/2)
20/02/19 06:18:15 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 24) in 4 ms on localhost (executor driver) (2/2)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:18:15 INFO DAGScheduler: Job 17 finished: collect at utils.scala:44, took 0.009111 s
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:18:15 INFO MapPartitionsRDD: Removing RDD 45 from persistence list
20/02/19 06:18:15 INFO BlockManager: Removing RDD 45
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 626
20/02/19 06:18:15 INFO ContextCleaner: Cleaned shuffle 5
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 628
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 625
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 633
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 631
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.8 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 627
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 632
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 635
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 685
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 630
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 629
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 634
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 636
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 710
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.8 MB)
20/02/19 06:18:15 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#287)) > 0)
20/02/19 06:18:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:18:15 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 253.9 KB, free 412.8 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.8 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 33 from csv at <unknown>:0
20/02/19 06:18:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:15 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:18:15 INFO DAGScheduler: Got job 18 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:18:15 INFO DAGScheduler: Final stage: ResultStage 24 (csv at <unknown>:0)
20/02/19 06:18:15 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:15 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:15 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[95] at csv at <unknown>:0), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 8.2 KB, free 412.7 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KB, free 412.7 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[95] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 24.0 (TID 25)
20/02/19 06:18:15 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:18:15 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 24.0 (TID 25). 1189 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 25) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ResultStage 24 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:18:15 INFO DAGScheduler: Job 18 finished: csv at <unknown>:0, took 0.009609 s
20/02/19 06:18:15 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:15 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:18:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:18:15 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 253.9 KB, free 412.5 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.5 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 35 from csv at <unknown>:0
20/02/19 06:18:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:15 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:18:15 INFO DAGScheduler: Got job 19 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:18:15 INFO DAGScheduler: Final stage: ResultStage 25 (csv at <unknown>:0)
20/02/19 06:18:15 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:15 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:15 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[100] at csv at <unknown>:0), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 13.9 KB, free 412.5 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 7.9 KB, free 412.5 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 740
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 737
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 735
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 736
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 739
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[100] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 25.0 (TID 26)
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 738
20/02/19 06:18:15 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:18:15 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 25.0 (TID 26). 1524 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 26) in 20 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ResultStage 25 (csv at <unknown>:0) finished in 0.021 s
20/02/19 06:18:15 INFO DAGScheduler: Job 19 finished: csv at <unknown>:0, took 0.029492 s
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:18:15 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:15 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:18:15 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:18:15 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 254.9 KB, free 412.5 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.1 KB, free 412.5 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 37 from sql at <unknown>:0
20/02/19 06:18:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:15 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:18:15 INFO DAGScheduler: Registering RDD 106 (sql at <unknown>:0)
20/02/19 06:18:15 INFO DAGScheduler: Got job 20 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:18:15 INFO DAGScheduler: Final stage: ResultStage 27 (sql at <unknown>:0)
20/02/19 06:18:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
20/02/19 06:18:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
20/02/19 06:18:15 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[106] at sql at <unknown>:0), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 17.5 KB, free 412.4 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.4 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[106] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 26.0 (TID 27)
20/02/19 06:18:15 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:18:15 INFO CodeGenerator: Code generated in 5.0328 ms
20/02/19 06:18:15 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 768
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 766
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 800
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 765
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 769
20/02/19 06:18:15 INFO ContextCleaner: Cleaned accumulator 767
20/02/19 06:18:15 INFO MemoryStore: Block rdd_103_0 stored as values in memory (estimated size 71.5 KB, free 412.7 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added rdd_103_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 26.0 (TID 27). 2461 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 27) in 68 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ShuffleMapStage 26 (sql at <unknown>:0) finished in 0.069 s
20/02/19 06:18:15 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:18:15 INFO DAGScheduler: running: Set()
20/02/19 06:18:15 INFO DAGScheduler: waiting: Set(ResultStage 27)
20/02/19 06:18:15 INFO DAGScheduler: failed: Set()
20/02/19 06:18:15 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.0 KB, free 412.7 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.6 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 28, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 27.0 (TID 28)
20/02/19 06:18:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:18:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 27.0 (TID 28). 1495 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 28) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ResultStage 27 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:18:15 INFO DAGScheduler: Job 20 finished: sql at <unknown>:0, took 0.084125 s
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:18:15 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:18:15 INFO DAGScheduler: Registering RDD 112 (collect at utils.scala:204)
20/02/19 06:18:15 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:18:15 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
20/02/19 06:18:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
20/02/19 06:18:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
20/02/19 06:18:15 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 17.5 KB, free 412.6 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.6 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
20/02/19 06:18:15 INFO BlockManager: Found block rdd_103_0 locally
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 1737 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:18:15 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:18:15 INFO DAGScheduler: running: Set()
20/02/19 06:18:15 INFO DAGScheduler: waiting: Set(ResultStage 29)
20/02/19 06:18:15 INFO DAGScheduler: failed: Set()
20/02/19 06:18:15 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.0 KB, free 412.6 MB)
20/02/19 06:18:15 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.6 MB)
20/02/19 06:18:15 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:18:15 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:15 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/02/19 06:18:15 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:18:15 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
20/02/19 06:18:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:18:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:18:15 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1495 bytes result sent to driver
20/02/19 06:18:15 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:18:15 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/02/19 06:18:15 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0.003 s
20/02/19 06:18:15 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.021015 s
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz4`
WHERE (0 = 1)
20/02/19 06:18:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:16 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:18:16 INFO DAGScheduler: Got job 22 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:18:16 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
20/02/19 06:18:16 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:16 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:16 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[120] at map at utils.scala:41), which has no missing parents
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 5.9 KB, free 412.6 MB)
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.3 KB, free 412.6 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (MapPartitionsRDD[120] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:18:16 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
20/02/19 06:18:16 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:18:16 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:18:16 INFO Executor: Running task 1.0 in stage 30.0 (TID 32)
20/02/19 06:18:16 INFO Executor: Running task 0.0 in stage 30.0 (TID 31)
20/02/19 06:18:16 INFO Executor: Finished task 0.0 in stage 30.0 (TID 31). 851 bytes result sent to driver
20/02/19 06:18:16 INFO Executor: Finished task 1.0 in stage 30.0 (TID 32). 894 bytes result sent to driver
20/02/19 06:18:16 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 31) in 3 ms on localhost (executor driver) (1/2)
20/02/19 06:18:16 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 32) in 2 ms on localhost (executor driver) (2/2)
20/02/19 06:18:16 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/02/19 06:18:16 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:18:16 INFO DAGScheduler: Job 22 finished: collect at utils.scala:44, took 0.008592 s
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: DROP TABLE `mut_tab`
20/02/19 06:18:16 INFO MapPartitionsRDD: Removing RDD 73 from persistence list
20/02/19 06:18:16 INFO BlockManager: Removing RDD 73
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 809
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 922
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 803
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 805
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 811
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 812
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 807
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 806
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned shuffle 6
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 810
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 804
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 801
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 808
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 861
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 802
20/02/19 06:18:16 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:16 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#389)) > 0)
20/02/19 06:18:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:18:16 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 253.9 KB, free 412.5 MB)
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.5 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 43 from csv at <unknown>:0
20/02/19 06:18:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:16 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:18:16 INFO DAGScheduler: Got job 23 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:18:16 INFO DAGScheduler: Final stage: ResultStage 31 (csv at <unknown>:0)
20/02/19 06:18:16 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:16 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:16 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[123] at csv at <unknown>:0), which has no missing parents
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 8.2 KB, free 412.5 MB)
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.3 KB, free 412.5 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[123] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:16 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/02/19 06:18:16 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:18:16 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
20/02/19 06:18:16 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:18:16 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:16 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 1189 bytes result sent to driver
20/02/19 06:18:16 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:18:16 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/02/19 06:18:16 INFO DAGScheduler: ResultStage 31 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:18:16 INFO DAGScheduler: Job 23 finished: csv at <unknown>:0, took 0.008769 s
20/02/19 06:18:16 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:16 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:18:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:18:16 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 253.9 KB, free 412.2 MB)
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.2 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 45 from csv at <unknown>:0
20/02/19 06:18:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:16 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:18:16 INFO DAGScheduler: Got job 24 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:18:16 INFO DAGScheduler: Final stage: ResultStage 32 (csv at <unknown>:0)
20/02/19 06:18:16 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:16 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:16 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[128] at csv at <unknown>:0), which has no missing parents
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 13.9 KB, free 412.2 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 951
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.9 KB, free 412.2 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 950
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 949
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 948
20/02/19 06:18:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[128] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:16 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
20/02/19 06:18:16 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 947
20/02/19 06:18:16 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
20/02/19 06:18:16 INFO ContextCleaner: Cleaned accumulator 952
20/02/19 06:18:16 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:18:16 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:16 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1481 bytes result sent to driver
20/02/19 06:18:16 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 14 ms on localhost (executor driver) (1/1)
20/02/19 06:18:16 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
20/02/19 06:18:16 INFO DAGScheduler: ResultStage 32 (csv at <unknown>:0) finished in 0.014 s
20/02/19 06:18:16 INFO DAGScheduler: Job 24 finished: csv at <unknown>:0, took 0.022914 s
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:18:16 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:18:16 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:18:16 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:18:16 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:18:16 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 254.9 KB, free 412.2 MB)
20/02/19 06:18:16 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 24.1 KB, free 412.2 MB)
20/02/19 06:18:16 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:18:16 INFO SparkContext: Created broadcast 47 from sql at <unknown>:0
20/02/19 06:18:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:18:17 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:18:17 INFO DAGScheduler: Registering RDD 134 (sql at <unknown>:0)
20/02/19 06:18:17 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:18:17 INFO DAGScheduler: Final stage: ResultStage 34 (sql at <unknown>:0)
20/02/19 06:18:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
20/02/19 06:18:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
20/02/19 06:18:17 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 17.5 KB, free 412.2 MB)
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.2 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:18:17 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:17 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
20/02/19 06:18:17 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:18:17 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
20/02/19 06:18:17 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:18:17 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 977
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 1012
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 979
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 980
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 978
20/02/19 06:18:17 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:18:17 INFO ContextCleaner: Cleaned accumulator 981
20/02/19 06:18:17 INFO MemoryStore: Block rdd_131_0 stored as values in memory (estimated size 71.8 KB, free 412.4 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Added rdd_131_0 in memory on 127.0.0.1:61681 (size: 71.8 KB, free: 413.7 MB)
20/02/19 06:18:17 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2461 bytes result sent to driver
20/02/19 06:18:17 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 81 ms on localhost (executor driver) (1/1)
20/02/19 06:18:17 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
20/02/19 06:18:17 INFO DAGScheduler: ShuffleMapStage 33 (sql at <unknown>:0) finished in 0.082 s
20/02/19 06:18:17 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:18:17 INFO DAGScheduler: running: Set()
20/02/19 06:18:17 INFO DAGScheduler: waiting: Set(ResultStage 34)
20/02/19 06:18:17 INFO DAGScheduler: failed: Set()
20/02/19 06:18:17 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[137] at sql at <unknown>:0), which has no missing parents
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 7.0 KB, free 412.4 MB)
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.4 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:18:17 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[137] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:17 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
20/02/19 06:18:17 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:18:17 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
20/02/19 06:18:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:18:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:18:17 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 1538 bytes result sent to driver
20/02/19 06:18:17 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:18:17 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
20/02/19 06:18:17 INFO DAGScheduler: ResultStage 34 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:18:17 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 0.095406 s
20/02/19 06:18:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:18:17 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:18:17 INFO DAGScheduler: Registering RDD 140 (collect at utils.scala:204)
20/02/19 06:18:17 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:18:17 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
20/02/19 06:18:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
20/02/19 06:18:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
20/02/19 06:18:17 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 17.5 KB, free 412.4 MB)
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.4 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:18:17 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:17 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
20/02/19 06:18:17 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:18:17 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
20/02/19 06:18:17 INFO BlockManager: Found block rdd_131_0 locally
20/02/19 06:18:17 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 1694 bytes result sent to driver
20/02/19 06:18:17 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:18:17 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
20/02/19 06:18:17 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.007 s
20/02/19 06:18:17 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:18:17 INFO DAGScheduler: running: Set()
20/02/19 06:18:17 INFO DAGScheduler: waiting: Set(ResultStage 36)
20/02/19 06:18:17 INFO DAGScheduler: failed: Set()
20/02/19 06:18:17 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[143] at collect at utils.scala:204), which has no missing parents
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 7.0 KB, free 412.4 MB)
20/02/19 06:18:17 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.4 MB)
20/02/19 06:18:17 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:18:17 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[143] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:17 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
20/02/19 06:18:17 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:18:17 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
20/02/19 06:18:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:18:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:18:17 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 1495 bytes result sent to driver
20/02/19 06:18:17 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:18:17 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
20/02/19 06:18:17 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:18:17 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.020145 s
20/02/19 06:18:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz5`
WHERE (0 = 1)
20/02/19 06:18:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:18:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:18:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:18:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
LIMIT 11
20/02/19 06:18:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
LIMIT 11
20/02/19 06:18:24 INFO CodeGenerator: Code generated in 4.7936 ms
20/02/19 06:18:24 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:18:24 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:18:24 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
20/02/19 06:18:24 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:18:24 INFO DAGScheduler: Missing parents: List()
20/02/19 06:18:24 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[145] at collect at utils.scala:204), which has no missing parents
20/02/19 06:18:24 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 13.6 KB, free 412.3 MB)
20/02/19 06:18:24 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.3 MB)
20/02/19 06:18:24 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:18:24 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
20/02/19 06:18:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[145] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:18:24 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
20/02/19 06:18:24 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:18:24 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
20/02/19 06:18:24 INFO BlockManager: Found block rdd_131_0 locally
20/02/19 06:18:24 INFO CodeGenerator: Code generated in 9.6365 ms
20/02/19 06:18:24 INFO Executor: 1 block locks were not released by TID = 39:
[rdd_131_0]
20/02/19 06:18:24 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1410 bytes result sent to driver
20/02/19 06:18:24 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 15 ms on localhost (executor driver) (1/1)
20/02/19 06:18:24 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
20/02/19 06:18:24 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.015 s
20/02/19 06:18:24 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.019958 s
20/02/19 06:18:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab`
20/02/19 06:18:24 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1020
20/02/19 06:18:24 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1017
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1073
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1022
20/02/19 06:18:24 INFO ContextCleaner: Cleaned shuffle 8
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1019
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1016
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1015
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1023
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1024
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1014
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1013
20/02/19 06:18:24 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1018
20/02/19 06:18:24 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:18:24 INFO ContextCleaner: Cleaned accumulator 1021
20/02/19 06:18:24 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:07 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:19:07 INFO DAGScheduler: Got job 28 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:19:07 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:44)
20/02/19 06:19:07 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:07 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:07 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[150] at map at utils.scala:41), which has no missing parents
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 5.9 KB, free 412.4 MB)
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.3 KB, free 412.4 MB)
20/02/19 06:19:07 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[150] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:19:07 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks
20/02/19 06:19:07 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:07 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 41, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:07 INFO Executor: Running task 1.0 in stage 38.0 (TID 41)
20/02/19 06:19:07 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
20/02/19 06:19:07 INFO Executor: Finished task 1.0 in stage 38.0 (TID 41). 851 bytes result sent to driver
20/02/19 06:19:07 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 894 bytes result sent to driver
20/02/19 06:19:07 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 41) in 4 ms on localhost (executor driver) (1/2)
20/02/19 06:19:07 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 6 ms on localhost (executor driver) (2/2)
20/02/19 06:19:07 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
20/02/19 06:19:07 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:44) finished in 0.006 s
20/02/19 06:19:07 INFO DAGScheduler: Job 28 finished: collect at utils.scala:44, took 0.011865 s
20/02/19 06:19:07 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:19:07 INFO MapPartitionsRDD: Removing RDD 103 from persistence list
20/02/19 06:19:07 INFO BlockManager: Removing RDD 103
20/02/19 06:19:07 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:07 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#517)) > 0)
20/02/19 06:19:07 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:07 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 253.9 KB, free 412.2 MB)
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.2 MB)
20/02/19 06:19:07 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkContext: Created broadcast 54 from csv at <unknown>:0
20/02/19 06:19:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:07 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:07 INFO DAGScheduler: Got job 29 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:07 INFO DAGScheduler: Final stage: ResultStage 39 (csv at <unknown>:0)
20/02/19 06:19:07 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:07 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:07 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[153] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 8.2 KB, free 412.2 MB)
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.3 KB, free 412.2 MB)
20/02/19 06:19:07 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO ContextCleaner: Cleaned accumulator 1159
20/02/19 06:19:07 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[153] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:07 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
20/02/19 06:19:07 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:07 INFO Executor: Running task 0.0 in stage 39.0 (TID 42)
20/02/19 06:19:07 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:07 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:07 INFO Executor: Finished task 0.0 in stage 39.0 (TID 42). 1232 bytes result sent to driver
20/02/19 06:19:07 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:19:07 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
20/02/19 06:19:07 INFO DAGScheduler: ResultStage 39 (csv at <unknown>:0) finished in 0.004 s
20/02/19 06:19:07 INFO DAGScheduler: Job 29 finished: csv at <unknown>:0, took 0.012734 s
20/02/19 06:19:07 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:07 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:07 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:07 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 253.9 KB, free 412.0 MB)
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.9 MB)
20/02/19 06:19:07 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkContext: Created broadcast 56 from csv at <unknown>:0
20/02/19 06:19:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:07 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:07 INFO DAGScheduler: Got job 30 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:07 INFO DAGScheduler: Final stage: ResultStage 40 (csv at <unknown>:0)
20/02/19 06:19:07 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:07 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:07 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[158] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 13.9 KB, free 411.9 MB)
20/02/19 06:19:07 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 7.9 KB, free 411.9 MB)
20/02/19 06:19:07 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:19:07 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[158] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:07 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
20/02/19 06:19:07 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:07 INFO Executor: Running task 0.0 in stage 40.0 (TID 43)
20/02/19 06:19:07 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:07 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:07 INFO Executor: Finished task 0.0 in stage 40.0 (TID 43). 1481 bytes result sent to driver
20/02/19 06:19:07 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 43) in 16 ms on localhost (executor driver) (1/1)
20/02/19 06:19:07 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
20/02/19 06:19:07 INFO DAGScheduler: ResultStage 40 (csv at <unknown>:0) finished in 0.017 s
20/02/19 06:19:07 INFO DAGScheduler: Job 30 finished: csv at <unknown>:0, took 0.020220 s
20/02/19 06:19:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:19:08 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:08 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:08 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:19:08 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 254.9 KB, free 411.7 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 24.1 KB, free 411.6 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 58 from sql at <unknown>:0
20/02/19 06:19:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1215
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1189
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1184
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1218
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1186
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1188
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1216
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1249
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1217
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1187
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1185
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1214
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:19:08 INFO DAGScheduler: Registering RDD 164 (sql at <unknown>:0)
20/02/19 06:19:08 INFO DAGScheduler: Got job 31 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:19:08 INFO DAGScheduler: Final stage: ResultStage 42 (sql at <unknown>:0)
20/02/19 06:19:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
20/02/19 06:19:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
20/02/19 06:19:08 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[164] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 17.5 KB, free 412.2 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.2 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[164] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 41.0 (TID 44)
20/02/19 06:19:08 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:08 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:08 INFO MemoryStore: Block rdd_161_0 stored as values in memory (estimated size 71.5 KB, free 412.1 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added rdd_161_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 41.0 (TID 44). 2418 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 44) in 51 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ShuffleMapStage 41 (sql at <unknown>:0) finished in 0.051 s
20/02/19 06:19:08 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:08 INFO DAGScheduler: running: Set()
20/02/19 06:19:08 INFO DAGScheduler: waiting: Set(ResultStage 42)
20/02/19 06:19:08 INFO DAGScheduler: failed: Set()
20/02/19 06:19:08 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[167] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.0 KB, free 412.1 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.1 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[167] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 42.0 (TID 45)
20/02/19 06:19:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 42.0 (TID 45). 1495 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 45) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ResultStage 42 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:19:08 INFO DAGScheduler: Job 31 finished: sql at <unknown>:0, took 0.063222 s
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:19:08 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:19:08 INFO DAGScheduler: Registering RDD 170 (collect at utils.scala:204)
20/02/19 06:19:08 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:19:08 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:204)
20/02/19 06:19:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
20/02/19 06:19:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
20/02/19 06:19:08 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[170] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 17.5 KB, free 412.1 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.1 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[170] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 43.0 (TID 46)
20/02/19 06:19:08 INFO BlockManager: Found block rdd_161_0 locally
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 43.0 (TID 46). 1737 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 46) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ShuffleMapStage 43 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:19:08 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:08 INFO DAGScheduler: running: Set()
20/02/19 06:19:08 INFO DAGScheduler: waiting: Set(ResultStage 44)
20/02/19 06:19:08 INFO DAGScheduler: failed: Set()
20/02/19 06:19:08 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[173] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.0 KB, free 412.1 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.1 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1256
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1258
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1260
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1261
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1252
20/02/19 06:19:08 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[173] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
20/02/19 06:19:08 INFO ContextCleaner: Cleaned shuffle 10
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1254
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1310
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 47, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1255
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1253
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1259
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1257
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1250
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1251
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 44.0 (TID 47)
20/02/19 06:19:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 44.0 (TID 47). 1538 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 47) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:204) finished in 0.006 s
20/02/19 06:19:08 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.030624 s
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz6`
WHERE (0 = 1)
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:08 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:19:08 INFO DAGScheduler: Got job 33 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:19:08 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:44)
20/02/19 06:19:08 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:08 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:08 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[178] at map at utils.scala:41), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 5.9 KB, free 412.1 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.3 KB, free 412.1 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.6 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[178] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:08 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 49, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 45.0 (TID 48)
20/02/19 06:19:08 INFO Executor: Running task 1.0 in stage 45.0 (TID 49)
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 45.0 (TID 48). 894 bytes result sent to driver
20/02/19 06:19:08 INFO Executor: Finished task 1.0 in stage 45.0 (TID 49). 851 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 48) in 3 ms on localhost (executor driver) (1/2)
20/02/19 06:19:08 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 49) in 3 ms on localhost (executor driver) (2/2)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:44) finished in 0.003 s
20/02/19 06:19:08 INFO DAGScheduler: Job 33 finished: collect at utils.scala:44, took 0.006619 s
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:19:08 INFO MapPartitionsRDD: Removing RDD 161 from persistence list
20/02/19 06:19:08 INFO BlockManager: Removing RDD 161
20/02/19 06:19:08 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:08 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#613)) > 0)
20/02/19 06:19:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:08 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 253.9 KB, free 411.9 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.9 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 64 from csv at <unknown>:0
20/02/19 06:19:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:08 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:08 INFO DAGScheduler: Got job 34 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:08 INFO DAGScheduler: Final stage: ResultStage 46 (csv at <unknown>:0)
20/02/19 06:19:08 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:08 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:08 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[181] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 8.2 KB, free 411.9 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.3 KB, free 411.9 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO BlockManager: Removing RDD 161
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[181] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 46.0 (TID 50)
20/02/19 06:19:08 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:08 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 46.0 (TID 50). 1189 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 50) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ResultStage 46 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:19:08 INFO DAGScheduler: Job 34 finished: csv at <unknown>:0, took 0.015098 s
20/02/19 06:19:08 INFO ContextCleaner: Cleaned RDD 161
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1315
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1318
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1313
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1371
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1322
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1248
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1311
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1243
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1316
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1317
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1321
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1244
20/02/19 06:19:08 INFO ContextCleaner: Cleaned shuffle 11
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:08 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:08 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1320
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1314
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1245
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1312
20/02/19 06:19:08 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1247
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1246
20/02/19 06:19:08 INFO ContextCleaner: Cleaned accumulator 1319
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 253.9 KB, free 412.0 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.9 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 66 from csv at <unknown>:0
20/02/19 06:19:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:08 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:08 INFO DAGScheduler: Got job 35 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:08 INFO DAGScheduler: Final stage: ResultStage 47 (csv at <unknown>:0)
20/02/19 06:19:08 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:08 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:08 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[186] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 13.9 KB, free 411.9 MB)
20/02/19 06:19:08 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 7.9 KB, free 411.9 MB)
20/02/19 06:19:08 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:19:08 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[186] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:08 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
20/02/19 06:19:08 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:08 INFO Executor: Running task 0.0 in stage 47.0 (TID 51)
20/02/19 06:19:08 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:08 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:08 INFO Executor: Finished task 0.0 in stage 47.0 (TID 51). 1481 bytes result sent to driver
20/02/19 06:19:08 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 51) in 18 ms on localhost (executor driver) (1/1)
20/02/19 06:19:08 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
20/02/19 06:19:08 INFO DAGScheduler: ResultStage 47 (csv at <unknown>:0) finished in 0.019 s
20/02/19 06:19:08 INFO DAGScheduler: Job 35 finished: csv at <unknown>:0, took 0.023928 s
20/02/19 06:19:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:19:09 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:09 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:09 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:19:09 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 254.9 KB, free 411.7 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 24.1 KB, free 411.6 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 68 from sql at <unknown>:0
20/02/19 06:19:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1426
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1428
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1399
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1401
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1398
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1427
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1396
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1400
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1429
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1430
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1397
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1461
20/02/19 06:19:09 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:19:09 INFO DAGScheduler: Registering RDD 192 (sql at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Got job 36 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 49 (sql at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
20/02/19 06:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[192] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 17.5 KB, free 412.2 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 9.0 KB, free 412.2 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[192] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 48.0 (TID 52)
20/02/19 06:19:09 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:19:09 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:09 INFO MemoryStore: Block rdd_189_0 stored as values in memory (estimated size 71.5 KB, free 412.1 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added rdd_189_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 48.0 (TID 52). 2461 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 52) in 45 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ShuffleMapStage 48 (sql at <unknown>:0) finished in 0.045 s
20/02/19 06:19:09 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:09 INFO DAGScheduler: running: Set()
20/02/19 06:19:09 INFO DAGScheduler: waiting: Set(ResultStage 49)
20/02/19 06:19:09 INFO DAGScheduler: failed: Set()
20/02/19 06:19:09 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[195] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 7.0 KB, free 412.1 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.1 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[195] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 53, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 49.0 (TID 53)
20/02/19 06:19:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 49.0 (TID 53). 1495 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 53) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ResultStage 49 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:19:09 INFO DAGScheduler: Job 36 finished: sql at <unknown>:0, took 0.057303 s
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:19:09 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:19:09 INFO DAGScheduler: Registering RDD 198 (collect at utils.scala:204)
20/02/19 06:19:09 INFO DAGScheduler: Got job 37 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
20/02/19 06:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[198] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 17.5 KB, free 412.1 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 9.1 KB, free 412.1 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[198] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 50.0 (TID 54)
20/02/19 06:19:09 INFO BlockManager: Found block rdd_189_0 locally
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 50.0 (TID 54). 1694 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 54) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.007 s
20/02/19 06:19:09 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:09 INFO DAGScheduler: running: Set()
20/02/19 06:19:09 INFO DAGScheduler: waiting: Set(ResultStage 51)
20/02/19 06:19:09 INFO DAGScheduler: failed: Set()
20/02/19 06:19:09 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[201] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 7.0 KB, free 412.1 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned shuffle 12
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1464
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1522
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1463
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1472
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1466
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1473
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.1 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[201] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1467
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1469
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1465
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1468
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1462
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1470
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1471
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 55, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 51.0 (TID 55)
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 51.0 (TID 55). 1495 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 55) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:19:09 INFO DAGScheduler: Job 37 finished: collect at utils.scala:204, took 0.025389 s
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz7`
WHERE (0 = 1)
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:09 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:19:09 INFO DAGScheduler: Got job 38 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:44)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:09 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[206] at map at utils.scala:41), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 5.9 KB, free 412.1 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.3 KB, free 412.1 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 52 (MapPartitionsRDD[206] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:09 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 57, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:19:09 INFO Executor: Running task 1.0 in stage 52.0 (TID 57)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 52.0 (TID 56)
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 52.0 (TID 56). 851 bytes result sent to driver
20/02/19 06:19:09 INFO Executor: Finished task 1.0 in stage 52.0 (TID 57). 851 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 56) in 3 ms on localhost (executor driver) (1/2)
20/02/19 06:19:09 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 57) in 2 ms on localhost (executor driver) (2/2)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:19:09 INFO DAGScheduler: Job 38 finished: collect at utils.scala:44, took 0.007441 s
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: DROP TABLE `mut_tab`
20/02/19 06:19:09 INFO MapPartitionsRDD: Removing RDD 131 from persistence list
20/02/19 06:19:09 INFO BlockManager: Removing RDD 131
20/02/19 06:19:09 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#723)) > 0)
20/02/19 06:19:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:09 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 253.9 KB, free 411.9 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.9 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 74 from csv at <unknown>:0
20/02/19 06:19:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1583
20/02/19 06:19:09 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO DAGScheduler: Got job 39 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 53 (csv at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:09 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[209] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 8.2 KB, free 411.9 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.3 KB, free 411.9 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[209] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 53.0 (TID 58)
20/02/19 06:19:09 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:19:09 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 53.0 (TID 58). 1189 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 58) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ResultStage 53 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:19:09 INFO DAGScheduler: Job 39 finished: csv at <unknown>:0, took 0.008743 s
20/02/19 06:19:09 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:09 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:19:09 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 253.9 KB, free 411.7 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.7 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 76 from csv at <unknown>:0
20/02/19 06:19:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:09 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:19:09 INFO DAGScheduler: Got job 40 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 54 (csv at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:09 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[214] at csv at <unknown>:0), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 13.9 KB, free 411.7 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 7.9 KB, free 411.6 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[214] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 54.0 (TID 59)
20/02/19 06:19:09 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:19:09 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:09 INFO Executor: Finished task 0.0 in stage 54.0 (TID 59). 1481 bytes result sent to driver
20/02/19 06:19:09 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 59) in 13 ms on localhost (executor driver) (1/1)
20/02/19 06:19:09 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
20/02/19 06:19:09 INFO DAGScheduler: ResultStage 54 (csv at <unknown>:0) finished in 0.014 s
20/02/19 06:19:09 INFO DAGScheduler: Job 40 finished: csv at <unknown>:0, took 0.018215 s
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:19:09 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:19:09 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:19:09 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:19:09 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:19:09 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 254.9 KB, free 411.4 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 24.1 KB, free 411.4 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 78 from sql at <unknown>:0
20/02/19 06:19:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1612
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1609
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1639
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1638
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1642
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1673
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.6 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1613
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1608
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1640
20/02/19 06:19:09 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1610
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1611
20/02/19 06:19:09 INFO ContextCleaner: Cleaned accumulator 1641
20/02/19 06:19:09 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:19:09 INFO DAGScheduler: Registering RDD 220 (sql at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Got job 41 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:19:09 INFO DAGScheduler: Final stage: ResultStage 56 (sql at <unknown>:0)
20/02/19 06:19:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
20/02/19 06:19:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
20/02/19 06:19:09 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[220] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 17.5 KB, free 411.9 MB)
20/02/19 06:19:09 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 9.0 KB, free 411.9 MB)
20/02/19 06:19:09 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:19:09 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[220] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:09 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
20/02/19 06:19:09 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:09 INFO Executor: Running task 0.0 in stage 55.0 (TID 60)
20/02/19 06:19:09 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:19:09 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:19:10 INFO MemoryStore: Block rdd_217_0 stored as values in memory (estimated size 71.8 KB, free 411.9 MB)
20/02/19 06:19:10 INFO BlockManagerInfo: Added rdd_217_0 in memory on 127.0.0.1:61681 (size: 71.8 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO Executor: Finished task 0.0 in stage 55.0 (TID 60). 2418 bytes result sent to driver
20/02/19 06:19:10 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 60) in 95 ms on localhost (executor driver) (1/1)
20/02/19 06:19:10 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
20/02/19 06:19:10 INFO DAGScheduler: ShuffleMapStage 55 (sql at <unknown>:0) finished in 0.095 s
20/02/19 06:19:10 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:10 INFO DAGScheduler: running: Set()
20/02/19 06:19:10 INFO DAGScheduler: waiting: Set(ResultStage 56)
20/02/19 06:19:10 INFO DAGScheduler: failed: Set()
20/02/19 06:19:10 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[223] at sql at <unknown>:0), which has no missing parents
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:19:10 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[223] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:10 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
20/02/19 06:19:10 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 61, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:10 INFO Executor: Running task 0.0 in stage 56.0 (TID 61)
20/02/19 06:19:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:19:10 INFO Executor: Finished task 0.0 in stage 56.0 (TID 61). 1495 bytes result sent to driver
20/02/19 06:19:10 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 61) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:19:10 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
20/02/19 06:19:10 INFO DAGScheduler: ResultStage 56 (sql at <unknown>:0) finished in 0.007 s
20/02/19 06:19:10 INFO DAGScheduler: Job 41 finished: sql at <unknown>:0, took 0.113740 s
20/02/19 06:19:10 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:19:10 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:19:10 INFO DAGScheduler: Registering RDD 226 (collect at utils.scala:204)
20/02/19 06:19:10 INFO DAGScheduler: Got job 42 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:19:10 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
20/02/19 06:19:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
20/02/19 06:19:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
20/02/19 06:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[226] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 17.5 KB, free 411.8 MB)
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 9.1 KB, free 411.8 MB)
20/02/19 06:19:10 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[226] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:10 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
20/02/19 06:19:10 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:19:10 INFO Executor: Running task 0.0 in stage 57.0 (TID 62)
20/02/19 06:19:10 INFO BlockManager: Found block rdd_217_0 locally
20/02/19 06:19:10 INFO Executor: Finished task 0.0 in stage 57.0 (TID 62). 1737 bytes result sent to driver
20/02/19 06:19:10 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 62) in 12 ms on localhost (executor driver) (1/1)
20/02/19 06:19:10 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
20/02/19 06:19:10 INFO DAGScheduler: ShuffleMapStage 57 (collect at utils.scala:204) finished in 0.012 s
20/02/19 06:19:10 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:19:10 INFO DAGScheduler: running: Set()
20/02/19 06:19:10 INFO DAGScheduler: waiting: Set(ResultStage 58)
20/02/19 06:19:10 INFO DAGScheduler: failed: Set()
20/02/19 06:19:10 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[229] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1676
20/02/19 06:19:10 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:19:10 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO ContextCleaner: Cleaned shuffle 14
20/02/19 06:19:10 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1675
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1677
20/02/19 06:19:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[229] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:10 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
20/02/19 06:19:10 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:19:10 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:19:10 INFO Executor: Running task 0.0 in stage 58.0 (TID 63)
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1682
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1679
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1683
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1685
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1674
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1684
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1734
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1681
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1678
20/02/19 06:19:10 INFO ContextCleaner: Cleaned accumulator 1680
20/02/19 06:19:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:19:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:19:10 INFO Executor: Finished task 0.0 in stage 58.0 (TID 63). 1495 bytes result sent to driver
20/02/19 06:19:10 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:19:10 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
20/02/19 06:19:10 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:19:10 INFO DAGScheduler: Job 42 finished: collect at utils.scala:204, took 0.031154 s
20/02/19 06:19:10 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz8`
WHERE (0 = 1)
20/02/19 06:19:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:19:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:19:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:19:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
LIMIT 11
20/02/19 06:19:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
LIMIT 11
20/02/19 06:19:31 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:19:31 INFO DAGScheduler: Got job 43 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:19:31 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:204)
20/02/19 06:19:31 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:19:31 INFO DAGScheduler: Missing parents: List()
20/02/19 06:19:31 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[231] at collect at utils.scala:204), which has no missing parents
20/02/19 06:19:31 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 13.6 KB, free 411.8 MB)
20/02/19 06:19:31 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 7.6 KB, free 411.8 MB)
20/02/19 06:19:31 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:19:31 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
20/02/19 06:19:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[231] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:19:31 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
20/02/19 06:19:31 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:19:31 INFO Executor: Running task 0.0 in stage 59.0 (TID 64)
20/02/19 06:19:31 INFO BlockManager: Found block rdd_189_0 locally
20/02/19 06:19:31 INFO Executor: 1 block locks were not released by TID = 64:
[rdd_189_0]
20/02/19 06:19:31 INFO Executor: Finished task 0.0 in stage 59.0 (TID 64). 1357 bytes result sent to driver
20/02/19 06:19:31 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 64) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:19:31 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
20/02/19 06:19:31 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:204) finished in 0.003 s
20/02/19 06:19:31 INFO DAGScheduler: Job 43 finished: collect at utils.scala:204, took 0.008613 s
20/02/19 06:19:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:22:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:22:18 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:22:18 INFO DAGScheduler: Got job 44 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:22:18 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:44)
20/02/19 06:22:18 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:22:18 INFO DAGScheduler: Missing parents: List()
20/02/19 06:22:18 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[236] at map at utils.scala:41), which has no missing parents
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 5.9 KB, free 411.8 MB)
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.3 KB, free 411.8 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 60 (MapPartitionsRDD[236] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:22:18 INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks
20/02/19 06:22:18 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:22:18 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:22:18 INFO Executor: Running task 0.0 in stage 60.0 (TID 65)
20/02/19 06:22:18 INFO Executor: Running task 1.0 in stage 60.0 (TID 66)
20/02/19 06:22:18 INFO Executor: Finished task 1.0 in stage 60.0 (TID 66). 894 bytes result sent to driver
20/02/19 06:22:18 INFO Executor: Finished task 0.0 in stage 60.0 (TID 65). 894 bytes result sent to driver
20/02/19 06:22:18 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 66) in 3 ms on localhost (executor driver) (1/2)
20/02/19 06:22:18 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 65) in 3 ms on localhost (executor driver) (2/2)
20/02/19 06:22:18 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
20/02/19 06:22:18 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:22:18 INFO DAGScheduler: Job 44 finished: collect at utils.scala:44, took 0.007910 s
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: iris
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: `iris`
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1820
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1847
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:22:18 INFO DAGScheduler: Registering RDD 244 (sql at <unknown>:0)
20/02/19 06:22:18 INFO DAGScheduler: Got job 45 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:22:18 INFO DAGScheduler: Final stage: ResultStage 62 (sql at <unknown>:0)
20/02/19 06:22:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
20/02/19 06:22:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
20/02/19 06:22:18 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[244] at sql at <unknown>:0), which has no missing parents
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 18.4 KB, free 411.9 MB)
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 8.5 KB, free 411.9 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:61681 (size: 8.5 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[244] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:22:18 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
20/02/19 06:22:18 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
20/02/19 06:22:18 INFO Executor: Running task 0.0 in stage 61.0 (TID 67)
20/02/19 06:22:18 INFO CodeGenerator: Code generated in 8.0383 ms
20/02/19 06:22:18 INFO CodeGenerator: Code generated in 39.0836 ms
20/02/19 06:22:18 INFO MemoryStore: Block rdd_241_0 stored as values in memory (estimated size 5.5 KB, free 411.8 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added rdd_241_0 in memory on 127.0.0.1:61681 (size: 5.5 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO Executor: Finished task 0.0 in stage 61.0 (TID 67). 2242 bytes result sent to driver
20/02/19 06:22:18 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 67) in 78 ms on localhost (executor driver) (1/1)
20/02/19 06:22:18 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
20/02/19 06:22:18 INFO DAGScheduler: ShuffleMapStage 61 (sql at <unknown>:0) finished in 0.080 s
20/02/19 06:22:18 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:22:18 INFO DAGScheduler: running: Set()
20/02/19 06:22:18 INFO DAGScheduler: waiting: Set(ResultStage 62)
20/02/19 06:22:18 INFO DAGScheduler: failed: Set()
20/02/19 06:22:18 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[247] at sql at <unknown>:0), which has no missing parents
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[247] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:22:18 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
20/02/19 06:22:18 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 68, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:22:18 INFO Executor: Running task 0.0 in stage 62.0 (TID 68)
20/02/19 06:22:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:22:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:22:18 INFO Executor: Finished task 0.0 in stage 62.0 (TID 68). 1495 bytes result sent to driver
20/02/19 06:22:18 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 68) in 2 ms on localhost (executor driver) (1/1)
20/02/19 06:22:18 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
20/02/19 06:22:18 INFO DAGScheduler: ResultStage 62 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:22:18 INFO DAGScheduler: Job 45 finished: sql at <unknown>:0, took 0.092134 s
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
20/02/19 06:22:18 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:22:18 INFO DAGScheduler: Registering RDD 250 (collect at utils.scala:204)
20/02/19 06:22:18 INFO DAGScheduler: Got job 46 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:22:18 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:204)
20/02/19 06:22:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
20/02/19 06:22:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63)
20/02/19 06:22:18 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[250] at collect at utils.scala:204), which has no missing parents
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 18.4 KB, free 411.8 MB)
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 8.5 KB, free 411.8 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:61681 (size: 8.5 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[250] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:22:18 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
20/02/19 06:22:18 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
20/02/19 06:22:18 INFO Executor: Running task 0.0 in stage 63.0 (TID 69)
20/02/19 06:22:18 INFO BlockManager: Found block rdd_241_0 locally
20/02/19 06:22:18 INFO Executor: Finished task 0.0 in stage 63.0 (TID 69). 1604 bytes result sent to driver
20/02/19 06:22:18 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 69) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:22:18 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
20/02/19 06:22:18 INFO DAGScheduler: ShuffleMapStage 63 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:22:18 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:22:18 INFO DAGScheduler: running: Set()
20/02/19 06:22:18 INFO DAGScheduler: waiting: Set(ResultStage 64)
20/02/19 06:22:18 INFO DAGScheduler: failed: Set()
20/02/19 06:22:18 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[253] at collect at utils.scala:204), which has no missing parents
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1857
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1852
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1853
20/02/19 06:22:18 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1854
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1859
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1855
20/02/19 06:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[253] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1849
20/02/19 06:22:18 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1858
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1850
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1848
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1851
20/02/19 06:22:18 INFO ContextCleaner: Cleaned shuffle 16
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1856
20/02/19 06:22:18 INFO ContextCleaner: Cleaned accumulator 1908
20/02/19 06:22:18 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 70, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:22:18 INFO Executor: Running task 0.0 in stage 64.0 (TID 70)
20/02/19 06:22:18 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:61681 in memory (size: 8.5 KB, free: 413.6 MB)
20/02/19 06:22:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:22:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:22:18 INFO Executor: Finished task 0.0 in stage 64.0 (TID 70). 1495 bytes result sent to driver
20/02/19 06:22:18 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 70) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:22:18 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
20/02/19 06:22:18 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:204) finished in 0.006 s
20/02/19 06:22:18 INFO DAGScheduler: Job 46 finished: collect at utils.scala:204, took 0.027832 s
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz9`
WHERE (0 = 1)
20/02/19 06:22:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:22:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
20/02/19 06:22:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
20/02/19 06:22:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
20/02/19 06:22:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
20/02/19 06:22:22 INFO CodeGenerator: Code generated in 9.8471 ms
20/02/19 06:22:22 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:22:22 INFO DAGScheduler: Got job 47 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:22:22 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:204)
20/02/19 06:22:22 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:22:22 INFO DAGScheduler: Missing parents: List()
20/02/19 06:22:22 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[255] at collect at utils.scala:204), which has no missing parents
20/02/19 06:22:22 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 14.0 KB, free 411.8 MB)
20/02/19 06:22:22 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 6.5 KB, free 411.8 MB)
20/02/19 06:22:22 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:61681 (size: 6.5 KB, free: 413.6 MB)
20/02/19 06:22:22 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
20/02/19 06:22:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[255] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:22:22 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
20/02/19 06:22:22 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
20/02/19 06:22:22 INFO Executor: Running task 0.0 in stage 65.0 (TID 71)
20/02/19 06:22:22 INFO BlockManager: Found block rdd_241_0 locally
20/02/19 06:22:23 INFO CodeGenerator: Code generated in 12.4652 ms
20/02/19 06:22:23 INFO Executor: 1 block locks were not released by TID = 71:
[rdd_241_0]
20/02/19 06:22:23 INFO Executor: Finished task 0.0 in stage 65.0 (TID 71). 1355 bytes result sent to driver
20/02/19 06:22:23 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 71) in 18 ms on localhost (executor driver) (1/1)
20/02/19 06:22:23 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
20/02/19 06:22:23 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:204) finished in 0.018 s
20/02/19 06:22:23 INFO DAGScheduler: Job 47 finished: collect at utils.scala:204, took 0.024895 s
20/02/19 06:22:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:23:37 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:23:37 INFO DAGScheduler: Got job 48 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:23:37 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:44)
20/02/19 06:23:37 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:23:37 INFO DAGScheduler: Missing parents: List()
20/02/19 06:23:37 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[260] at map at utils.scala:41), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 5.9 KB, free 411.8 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.3 KB, free 411.8 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 66 (MapPartitionsRDD[260] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 66.0 with 3 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:23:37 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 73, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:23:37 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 74, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 66.0 (TID 72)
20/02/19 06:23:37 INFO Executor: Running task 1.0 in stage 66.0 (TID 73)
20/02/19 06:23:37 INFO Executor: Running task 2.0 in stage 66.0 (TID 74)
20/02/19 06:23:37 INFO Executor: Finished task 1.0 in stage 66.0 (TID 73). 894 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 73) in 5 ms on localhost (executor driver) (1/3)
20/02/19 06:23:37 INFO Executor: Finished task 2.0 in stage 66.0 (TID 74). 894 bytes result sent to driver
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 66.0 (TID 72). 891 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 74) in 5 ms on localhost (executor driver) (2/3)
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 72) in 5 ms on localhost (executor driver) (3/3)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:44) finished in 0.006 s
20/02/19 06:23:37 INFO DAGScheduler: Job 48 finished: collect at utils.scala:44, took 0.010177 s
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:23:37 INFO MapPartitionsRDD: Removing RDD 189 from persistence list
20/02/19 06:23:37 INFO BlockManager: Removing RDD 189
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1910
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1913
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1736
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1914
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1534
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:61681 in memory (size: 6.5 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1457
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1739
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1532
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1738
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1911
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1458
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1529
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1460
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1528
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1912
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1915
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1527
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1523
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1531
20/02/19 06:23:37 INFO ContextCleaner: Cleaned shuffle 13
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:61681 in memory (size: 8.5 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1459
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1746
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1743
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1530
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1745
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1917
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1744
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1525
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1742
20/02/19 06:23:37 INFO BlockManager: Removing RDD 189
20/02/19 06:23:37 INFO ContextCleaner: Cleaned RDD 189
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1918
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1524
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1795
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1920
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1533
20/02/19 06:23:37 INFO ContextCleaner: Cleaned shuffle 17
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1909
20/02/19 06:23:37 INFO ContextCleaner: Cleaned shuffle 15
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1916
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1919
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1735
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1455
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1740
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1994
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1526
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1456
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1741
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 1737
20/02/19 06:23:37 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:23:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1052)) > 0)
20/02/19 06:23:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:23:37 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 253.9 KB, free 412.0 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.9 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 91 from csv at <unknown>:0
20/02/19 06:23:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:23:37 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:23:37 INFO DAGScheduler: Got job 49 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:23:37 INFO DAGScheduler: Final stage: ResultStage 67 (csv at <unknown>:0)
20/02/19 06:23:37 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:23:37 INFO DAGScheduler: Missing parents: List()
20/02/19 06:23:37 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[263] at csv at <unknown>:0), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 8.2 KB, free 411.9 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 4.3 KB, free 411.9 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[263] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 67.0 (TID 75)
20/02/19 06:23:37 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:23:37 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 67.0 (TID 75). 1189 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 75) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ResultStage 67 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:23:37 INFO DAGScheduler: Job 49 finished: csv at <unknown>:0, took 0.011635 s
20/02/19 06:23:37 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:23:37 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:23:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:23:37 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 253.9 KB, free 411.7 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 23.9 KB, free 411.7 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 93 from csv at <unknown>:0
20/02/19 06:23:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:23:37 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:23:37 INFO DAGScheduler: Got job 50 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:23:37 INFO DAGScheduler: Final stage: ResultStage 68 (csv at <unknown>:0)
20/02/19 06:23:37 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:23:37 INFO DAGScheduler: Missing parents: List()
20/02/19 06:23:37 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[268] at csv at <unknown>:0), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 13.9 KB, free 411.6 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 7.9 KB, free 411.6 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2022
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2019
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[268] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2024
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 68.0 (TID 76)
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2023
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2021
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2020
20/02/19 06:23:37 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:23:37 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 68.0 (TID 76). 1481 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 76) in 25 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ResultStage 68 (csv at <unknown>:0) finished in 0.025 s
20/02/19 06:23:37 INFO DAGScheduler: Job 50 finished: csv at <unknown>:0, took 0.036103 s
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:23:37 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:23:37 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:23:37 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:23:37 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 254.9 KB, free 411.7 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 24.1 KB, free 411.7 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 95 from sql at <unknown>:0
20/02/19 06:23:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:23:37 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:23:37 INFO DAGScheduler: Registering RDD 274 (sql at <unknown>:0)
20/02/19 06:23:37 INFO DAGScheduler: Got job 51 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:23:37 INFO DAGScheduler: Final stage: ResultStage 70 (sql at <unknown>:0)
20/02/19 06:23:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
20/02/19 06:23:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 69)
20/02/19 06:23:37 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[274] at sql at <unknown>:0), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 17.5 KB, free 411.6 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 9.0 KB, free 411.6 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[274] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 69.0 (TID 77)
20/02/19 06:23:37 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:23:37 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:23:37 INFO MemoryStore: Block rdd_271_0 stored as values in memory (estimated size 71.5 KB, free 411.6 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added rdd_271_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2049
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2084
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2051
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2050
20/02/19 06:23:37 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2052
20/02/19 06:23:37 INFO ContextCleaner: Cleaned accumulator 2053
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 69.0 (TID 77). 2504 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 77) in 48 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ShuffleMapStage 69 (sql at <unknown>:0) finished in 0.048 s
20/02/19 06:23:37 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:23:37 INFO DAGScheduler: running: Set()
20/02/19 06:23:37 INFO DAGScheduler: waiting: Set(ResultStage 70)
20/02/19 06:23:37 INFO DAGScheduler: failed: Set()
20/02/19 06:23:37 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[277] at sql at <unknown>:0), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[277] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 78, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 70.0 (TID 78)
20/02/19 06:23:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 70.0 (TID 78). 1452 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 78) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ResultStage 70 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:23:37 INFO DAGScheduler: Job 51 finished: sql at <unknown>:0, took 0.059422 s
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:23:37 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:23:37 INFO DAGScheduler: Registering RDD 280 (collect at utils.scala:204)
20/02/19 06:23:37 INFO DAGScheduler: Got job 52 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:23:37 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:204)
20/02/19 06:23:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
20/02/19 06:23:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
20/02/19 06:23:37 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[280] at collect at utils.scala:204), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 17.5 KB, free 411.8 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 9.1 KB, free 411.8 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[280] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 71.0 (TID 79)
20/02/19 06:23:37 INFO BlockManager: Found block rdd_271_0 locally
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 71.0 (TID 79). 1694 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 79) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ShuffleMapStage 71 (collect at utils.scala:204) finished in 0.007 s
20/02/19 06:23:37 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:23:37 INFO DAGScheduler: running: Set()
20/02/19 06:23:37 INFO DAGScheduler: waiting: Set(ResultStage 72)
20/02/19 06:23:37 INFO DAGScheduler: failed: Set()
20/02/19 06:23:37 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[283] at collect at utils.scala:204), which has no missing parents
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 7.0 KB, free 411.8 MB)
20/02/19 06:23:37 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.7 KB, free 411.8 MB)
20/02/19 06:23:37 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:23:37 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[283] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:37 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
20/02/19 06:23:37 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 80, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:23:37 INFO Executor: Running task 0.0 in stage 72.0 (TID 80)
20/02/19 06:23:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:23:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:23:37 INFO Executor: Finished task 0.0 in stage 72.0 (TID 80). 1495 bytes result sent to driver
20/02/19 06:23:37 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 80) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:23:37 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
20/02/19 06:23:37 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:204) finished in 0.003 s
20/02/19 06:23:37 INFO DAGScheduler: Job 52 finished: collect at utils.scala:204, took 0.018277 s
20/02/19 06:23:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz10`
WHERE (0 = 1)
20/02/19 06:23:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:23:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:23:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:23:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
LIMIT 11
20/02/19 06:23:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
LIMIT 11
20/02/19 06:23:48 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:23:48 INFO DAGScheduler: Got job 53 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:23:48 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:204)
20/02/19 06:23:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:23:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:23:48 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[285] at collect at utils.scala:204), which has no missing parents
20/02/19 06:23:48 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 13.6 KB, free 411.8 MB)
20/02/19 06:23:48 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 7.6 KB, free 411.8 MB)
20/02/19 06:23:48 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:23:48 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
20/02/19 06:23:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[285] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:23:48 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
20/02/19 06:23:48 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:23:48 INFO Executor: Running task 0.0 in stage 73.0 (TID 81)
20/02/19 06:23:48 INFO BlockManager: Found block rdd_271_0 locally
20/02/19 06:23:48 INFO Executor: 1 block locks were not released by TID = 81:
[rdd_271_0]
20/02/19 06:23:48 INFO Executor: Finished task 0.0 in stage 73.0 (TID 81). 1400 bytes result sent to driver
20/02/19 06:23:48 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 81) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:23:48 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
20/02/19 06:23:48 INFO DAGScheduler: ResultStage 73 (collect at utils.scala:204) finished in 0.006 s
20/02/19 06:23:48 INFO DAGScheduler: Job 53 finished: collect at utils.scala:204, took 0.012913 s
20/02/19 06:23:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab`
20/02/19 06:25:13 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:25:13 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:25:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM ((SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)) `dbplyr_001`
LIMIT 11
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2095
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2156
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2091
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2090
20/02/19 06:25:13 INFO ContextCleaner: Cleaned shuffle 18
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2146
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2150
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2092
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO ContextCleaner: Cleaned shuffle 19
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2151
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2152
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2089
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2088
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2149
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2148
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2147
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2206
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2157
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2096
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2153
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2093
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2155
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2086
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2145
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2085
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2154
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2087
20/02/19 06:25:13 INFO ContextCleaner: Cleaned accumulator 2094
20/02/19 06:25:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM ((SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)) `dbplyr_002`
LIMIT 11
20/02/19 06:25:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:25:13 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:25:13 INFO DAGScheduler: Got job 54 (run at <unknown>:0) with 1 output partitions
20/02/19 06:25:13 INFO DAGScheduler: Final stage: ResultStage 74 (run at <unknown>:0)
20/02/19 06:25:13 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:25:13 INFO DAGScheduler: Missing parents: List()
20/02/19 06:25:13 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[287] at run at <unknown>:0), which has no missing parents
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 13.7 KB, free 411.9 MB)
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 7.6 KB, free 411.9 MB)
20/02/19 06:25:13 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:25:13 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[287] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:25:13 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
20/02/19 06:25:13 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:25:13 INFO Executor: Running task 0.0 in stage 74.0 (TID 82)
20/02/19 06:25:13 INFO BlockManager: Found block rdd_217_0 locally
20/02/19 06:25:13 INFO Executor: Finished task 0.0 in stage 74.0 (TID 82). 59024 bytes result sent to driver
20/02/19 06:25:13 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 82) in 16 ms on localhost (executor driver) (1/1)
20/02/19 06:25:13 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
20/02/19 06:25:13 INFO DAGScheduler: ResultStage 74 (run at <unknown>:0) finished in 0.017 s
20/02/19 06:25:13 INFO DAGScheduler: Job 54 finished: run at <unknown>:0, took 0.021114 s
20/02/19 06:25:13 INFO CodeGenerator: Code generated in 27.2016 ms
20/02/19 06:25:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:25:13 INFO CodeGenerator: Code generated in 4.926 ms
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 4.3 MB, free 407.6 MB)
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 137.7 KB, free 407.5 MB)
20/02/19 06:25:13 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:61681 (size: 137.7 KB, free: 413.5 MB)
20/02/19 06:25:13 INFO SparkContext: Created broadcast 102 from run at <unknown>:0
20/02/19 06:25:13 INFO CodeGenerator: Code generated in 13.4001 ms
20/02/19 06:25:13 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:25:13 INFO DAGScheduler: Registering RDD 290 (collect at utils.scala:204)
20/02/19 06:25:13 INFO DAGScheduler: Got job 55 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:25:13 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:204)
20/02/19 06:25:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
20/02/19 06:25:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
20/02/19 06:25:13 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[290] at collect at utils.scala:204), which has no missing parents
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 30.2 KB, free 407.4 MB)
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 14.0 KB, free 407.4 MB)
20/02/19 06:25:13 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:61681 (size: 14.0 KB, free: 413.5 MB)
20/02/19 06:25:13 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[290] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:25:13 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
20/02/19 06:25:13 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:25:13 INFO Executor: Running task 0.0 in stage 75.0 (TID 83)
20/02/19 06:25:13 INFO BlockManager: Found block rdd_271_0 locally
20/02/19 06:25:13 INFO CodeGenerator: Code generated in 5.6965 ms
20/02/19 06:25:13 INFO CodeGenerator: Code generated in 2.7706 ms
20/02/19 06:25:13 INFO Executor: Finished task 0.0 in stage 75.0 (TID 83). 2409 bytes result sent to driver
20/02/19 06:25:13 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 83) in 45 ms on localhost (executor driver) (1/1)
20/02/19 06:25:13 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
20/02/19 06:25:13 INFO DAGScheduler: ShuffleMapStage 75 (collect at utils.scala:204) finished in 0.045 s
20/02/19 06:25:13 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:25:13 INFO DAGScheduler: running: Set()
20/02/19 06:25:13 INFO DAGScheduler: waiting: Set(ResultStage 76)
20/02/19 06:25:13 INFO DAGScheduler: failed: Set()
20/02/19 06:25:13 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[293] at collect at utils.scala:204), which has no missing parents
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 18.9 KB, free 407.4 MB)
20/02/19 06:25:13 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 8.6 KB, free 407.4 MB)
20/02/19 06:25:13 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:61681 (size: 8.6 KB, free: 413.5 MB)
20/02/19 06:25:13 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[293] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:25:13 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
20/02/19 06:25:13 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 84, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:25:13 INFO Executor: Running task 0.0 in stage 76.0 (TID 84)
20/02/19 06:25:13 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:61681 in memory (size: 14.0 KB, free: 413.5 MB)
20/02/19 06:25:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:25:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:25:13 WARN Executor: Managed memory leak detected; size = 4456448 bytes, TID = 84
20/02/19 06:25:13 INFO Executor: Finished task 0.0 in stage 76.0 (TID 84). 2889 bytes result sent to driver
20/02/19 06:25:13 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 84) in 16 ms on localhost (executor driver) (1/1)
20/02/19 06:25:13 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
20/02/19 06:25:13 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:204) finished in 0.016 s
20/02/19 06:25:13 INFO DAGScheduler: Job 55 finished: collect at utils.scala:204, took 0.070162 s
20/02/19 06:25:13 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:25:30 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:25:30 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:25:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:25:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:25:30 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:25:30 INFO DAGScheduler: Got job 56 (run at <unknown>:0) with 1 output partitions
20/02/19 06:25:30 INFO DAGScheduler: Final stage: ResultStage 77 (run at <unknown>:0)
20/02/19 06:25:30 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:25:30 INFO DAGScheduler: Missing parents: List()
20/02/19 06:25:30 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[295] at run at <unknown>:0), which has no missing parents
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 13.7 KB, free 407.4 MB)
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 7.6 KB, free 407.4 MB)
20/02/19 06:25:30 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.5 MB)
20/02/19 06:25:30 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[295] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:25:30 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
20/02/19 06:25:30 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:25:30 INFO Executor: Running task 0.0 in stage 77.0 (TID 85)
20/02/19 06:25:30 INFO BlockManager: Found block rdd_217_0 locally
20/02/19 06:25:30 INFO Executor: Finished task 0.0 in stage 77.0 (TID 85). 58981 bytes result sent to driver
20/02/19 06:25:30 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 85) in 9 ms on localhost (executor driver) (1/1)
20/02/19 06:25:30 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
20/02/19 06:25:30 INFO DAGScheduler: ResultStage 77 (run at <unknown>:0) finished in 0.010 s
20/02/19 06:25:30 INFO DAGScheduler: Job 56 finished: run at <unknown>:0, took 0.017550 s
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 4.3 MB, free 403.2 MB)
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 137.7 KB, free 403.0 MB)
20/02/19 06:25:30 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:61681 (size: 137.7 KB, free: 413.3 MB)
20/02/19 06:25:30 INFO SparkContext: Created broadcast 106 from run at <unknown>:0
20/02/19 06:25:30 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:25:30 INFO DAGScheduler: Registering RDD 298 (collect at utils.scala:204)
20/02/19 06:25:30 INFO DAGScheduler: Got job 57 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:25:30 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:204)
20/02/19 06:25:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
20/02/19 06:25:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
20/02/19 06:25:30 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[298] at collect at utils.scala:204), which has no missing parents
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 30.2 KB, free 403.0 MB)
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 14.0 KB, free 403.0 MB)
20/02/19 06:25:30 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:61681 (size: 14.0 KB, free: 413.3 MB)
20/02/19 06:25:30 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[298] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:25:30 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
20/02/19 06:25:30 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:25:30 INFO Executor: Running task 0.0 in stage 78.0 (TID 86)
20/02/19 06:25:30 INFO BlockManager: Found block rdd_271_0 locally
20/02/19 06:25:30 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:25:30 INFO ContextCleaner: Cleaned accumulator 2324
20/02/19 06:25:30 INFO ContextCleaner: Cleaned accumulator 2326
20/02/19 06:25:30 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:61681 in memory (size: 8.6 KB, free: 413.3 MB)
20/02/19 06:25:30 INFO Executor: Finished task 0.0 in stage 78.0 (TID 86). 2452 bytes result sent to driver
20/02/19 06:25:30 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 86) in 42 ms on localhost (executor driver) (1/1)
20/02/19 06:25:30 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
20/02/19 06:25:30 INFO DAGScheduler: ShuffleMapStage 78 (collect at utils.scala:204) finished in 0.043 s
20/02/19 06:25:30 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:25:30 INFO DAGScheduler: running: Set()
20/02/19 06:25:30 INFO DAGScheduler: waiting: Set(ResultStage 79)
20/02/19 06:25:30 INFO DAGScheduler: failed: Set()
20/02/19 06:25:30 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[301] at collect at utils.scala:204), which has no missing parents
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 19.1 KB, free 403.0 MB)
20/02/19 06:25:30 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.7 KB, free 403.0 MB)
20/02/19 06:25:30 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:61681 (size: 8.7 KB, free: 413.3 MB)
20/02/19 06:25:30 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
20/02/19 06:25:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 79 (MapPartitionsRDD[301] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:25:30 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks
20/02/19 06:25:30 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:25:30 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:25:30 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:25:30 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:25:30 INFO Executor: Running task 0.0 in stage 79.0 (TID 87)
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:25:30 INFO Executor: Running task 1.0 in stage 79.0 (TID 88)
20/02/19 06:25:30 INFO Executor: Running task 2.0 in stage 79.0 (TID 89)
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:25:30 INFO Executor: Running task 3.0 in stage 79.0 (TID 90)
20/02/19 06:25:30 INFO Executor: Finished task 1.0 in stage 79.0 (TID 88). 17566 bytes result sent to driver
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:25:30 INFO Executor: Finished task 2.0 in stage 79.0 (TID 89). 17240 bytes result sent to driver
20/02/19 06:25:30 INFO Executor: Finished task 0.0 in stage 79.0 (TID 87). 16974 bytes result sent to driver
20/02/19 06:25:30 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 88) in 23 ms on localhost (executor driver) (1/4)
20/02/19 06:25:30 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 89) in 23 ms on localhost (executor driver) (2/4)
20/02/19 06:25:30 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 87) in 24 ms on localhost (executor driver) (3/4)
20/02/19 06:25:30 INFO Executor: Finished task 3.0 in stage 79.0 (TID 90). 17489 bytes result sent to driver
20/02/19 06:25:30 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 90) in 30 ms on localhost (executor driver) (4/4)
20/02/19 06:25:30 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
20/02/19 06:25:30 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:204) finished in 0.032 s
20/02/19 06:25:30 INFO DAGScheduler: Job 57 finished: collect at utils.scala:204, took 0.088334 s
20/02/19 06:26:25 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:26:25 INFO SparkSqlParser: Parsing command: (SELECT *
FROM `ref_tab`)
EXCEPT
(SELECT *
FROM `mut_tab`)
20/02/19 06:26:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:26:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:26:25 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:26:25 INFO DAGScheduler: Got job 58 (run at <unknown>:0) with 1 output partitions
20/02/19 06:26:25 INFO DAGScheduler: Final stage: ResultStage 80 (run at <unknown>:0)
20/02/19 06:26:25 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:26:25 INFO DAGScheduler: Missing parents: List()
20/02/19 06:26:25 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[303] at run at <unknown>:0), which has no missing parents
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 13.7 KB, free 403.0 MB)
20/02/19 06:26:25 INFO ContextCleaner: Cleaned accumulator 2419
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 7.6 KB, free 403.0 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:61681 in memory (size: 14.0 KB, free: 413.3 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:26:25 INFO ContextCleaner: Cleaned accumulator 2417
20/02/19 06:26:25 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
20/02/19 06:26:25 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:61681 in memory (size: 8.7 KB, free: 413.3 MB)
20/02/19 06:26:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[303] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:26:25 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
20/02/19 06:26:25 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:26:25 INFO Executor: Running task 0.0 in stage 80.0 (TID 91)
20/02/19 06:26:25 INFO BlockManager: Found block rdd_217_0 locally
20/02/19 06:26:25 INFO Executor: Finished task 0.0 in stage 80.0 (TID 91). 59024 bytes result sent to driver
20/02/19 06:26:25 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 91) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:26:25 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
20/02/19 06:26:25 INFO DAGScheduler: ResultStage 80 (run at <unknown>:0) finished in 0.006 s
20/02/19 06:26:25 INFO DAGScheduler: Job 58 finished: run at <unknown>:0, took 0.015515 s
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 4.3 MB, free 398.8 MB)
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 137.7 KB, free 398.7 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:61681 (size: 137.7 KB, free: 413.2 MB)
20/02/19 06:26:25 INFO SparkContext: Created broadcast 110 from run at <unknown>:0
20/02/19 06:26:25 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:26:25 INFO DAGScheduler: Registering RDD 306 (collect at utils.scala:204)
20/02/19 06:26:25 INFO DAGScheduler: Got job 59 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:26:25 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:204)
20/02/19 06:26:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
20/02/19 06:26:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
20/02/19 06:26:25 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[306] at collect at utils.scala:204), which has no missing parents
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 30.2 KB, free 398.6 MB)
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 14.0 KB, free 398.6 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:61681 (size: 14.0 KB, free: 413.2 MB)
20/02/19 06:26:25 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
20/02/19 06:26:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[306] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:26:25 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
20/02/19 06:26:25 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:26:25 INFO Executor: Running task 0.0 in stage 81.0 (TID 92)
20/02/19 06:26:25 INFO BlockManager: Found block rdd_271_0 locally
20/02/19 06:26:25 INFO Executor: Finished task 0.0 in stage 81.0 (TID 92). 2409 bytes result sent to driver
20/02/19 06:26:25 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 92) in 23 ms on localhost (executor driver) (1/1)
20/02/19 06:26:25 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
20/02/19 06:26:25 INFO DAGScheduler: ShuffleMapStage 81 (collect at utils.scala:204) finished in 0.024 s
20/02/19 06:26:25 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:26:25 INFO DAGScheduler: running: Set()
20/02/19 06:26:25 INFO DAGScheduler: waiting: Set(ResultStage 82)
20/02/19 06:26:25 INFO DAGScheduler: failed: Set()
20/02/19 06:26:25 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[309] at collect at utils.scala:204), which has no missing parents
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 19.1 KB, free 398.6 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.2 MB)
20/02/19 06:26:25 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 8.7 KB, free 398.6 MB)
20/02/19 06:26:25 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:61681 (size: 8.7 KB, free: 413.2 MB)
20/02/19 06:26:25 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
20/02/19 06:26:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 82 (MapPartitionsRDD[309] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:26:25 INFO TaskSchedulerImpl: Adding task set 82.0 with 4 tasks
20/02/19 06:26:25 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:26:25 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:26:25 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:26:25 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:26:25 INFO Executor: Running task 0.0 in stage 82.0 (TID 93)
20/02/19 06:26:25 INFO Executor: Running task 3.0 in stage 82.0 (TID 96)
20/02/19 06:26:25 INFO Executor: Running task 2.0 in stage 82.0 (TID 95)
20/02/19 06:26:25 INFO Executor: Running task 1.0 in stage 82.0 (TID 94)
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:26:25 INFO Executor: Finished task 1.0 in stage 82.0 (TID 94). 17566 bytes result sent to driver
20/02/19 06:26:25 INFO Executor: Finished task 0.0 in stage 82.0 (TID 93). 17060 bytes result sent to driver
20/02/19 06:26:25 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 94) in 10 ms on localhost (executor driver) (1/4)
20/02/19 06:26:25 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 93) in 10 ms on localhost (executor driver) (2/4)
20/02/19 06:26:25 INFO Executor: Finished task 2.0 in stage 82.0 (TID 95). 17240 bytes result sent to driver
20/02/19 06:26:25 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 95) in 11 ms on localhost (executor driver) (3/4)
20/02/19 06:26:25 INFO Executor: Finished task 3.0 in stage 82.0 (TID 96). 17446 bytes result sent to driver
20/02/19 06:26:25 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 96) in 11 ms on localhost (executor driver) (4/4)
20/02/19 06:26:25 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
20/02/19 06:26:25 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:204) finished in 0.013 s
20/02/19 06:26:25 INFO DAGScheduler: Job 59 finished: collect at utils.scala:204, took 0.050946 s
20/02/19 06:27:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:27:35 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:27:35 INFO DAGScheduler: Got job 60 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:27:35 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:44)
20/02/19 06:27:35 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:27:35 INFO DAGScheduler: Missing parents: List()
20/02/19 06:27:35 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[314] at map at utils.scala:41), which has no missing parents
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 5.9 KB, free 398.6 MB)
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.3 KB, free 398.6 MB)
20/02/19 06:27:35 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.2 MB)
20/02/19 06:27:35 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
20/02/19 06:27:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 83 (MapPartitionsRDD[314] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:27:35 INFO TaskSchedulerImpl: Adding task set 83.0 with 3 tasks
20/02/19 06:27:35 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:27:35 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:27:35 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:27:35 INFO Executor: Running task 0.0 in stage 83.0 (TID 97)
20/02/19 06:27:35 INFO Executor: Running task 2.0 in stage 83.0 (TID 99)
20/02/19 06:27:35 INFO Executor: Running task 1.0 in stage 83.0 (TID 98)
20/02/19 06:27:35 INFO Executor: Finished task 0.0 in stage 83.0 (TID 97). 848 bytes result sent to driver
20/02/19 06:27:35 INFO Executor: Finished task 1.0 in stage 83.0 (TID 98). 937 bytes result sent to driver
20/02/19 06:27:35 INFO Executor: Finished task 2.0 in stage 83.0 (TID 99). 894 bytes result sent to driver
20/02/19 06:27:35 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 97) in 8 ms on localhost (executor driver) (1/3)
20/02/19 06:27:35 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 98) in 8 ms on localhost (executor driver) (2/3)
20/02/19 06:27:35 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 99) in 8 ms on localhost (executor driver) (3/3)
20/02/19 06:27:35 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:61681 in memory (size: 14.0 KB, free: 413.2 MB)
20/02/19 06:27:35 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
20/02/19 06:27:35 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:44) finished in 0.009 s
20/02/19 06:27:35 INFO DAGScheduler: Job 60 finished: collect at utils.scala:44, took 0.014303 s
20/02/19 06:27:35 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:61681 in memory (size: 8.7 KB, free: 413.2 MB)
20/02/19 06:27:35 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:27:35 INFO MapPartitionsRDD: Removing RDD 271 from persistence list
20/02/19 06:27:35 INFO BlockManager: Removing RDD 271
20/02/19 06:27:35 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:27:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1267)) > 0)
20/02/19 06:27:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:27:35 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 253.9 KB, free 398.5 MB)
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 23.9 KB, free 398.5 MB)
20/02/19 06:27:35 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.2 MB)
20/02/19 06:27:35 INFO SparkContext: Created broadcast 114 from csv at <unknown>:0
20/02/19 06:27:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:27:35 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:27:35 INFO DAGScheduler: Got job 61 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:27:35 INFO DAGScheduler: Final stage: ResultStage 84 (csv at <unknown>:0)
20/02/19 06:27:35 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:27:35 INFO DAGScheduler: Missing parents: List()
20/02/19 06:27:35 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[317] at csv at <unknown>:0), which has no missing parents
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 8.2 KB, free 398.5 MB)
20/02/19 06:27:35 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.3 KB, free 398.5 MB)
20/02/19 06:27:35 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.2 MB)
20/02/19 06:27:35 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
20/02/19 06:27:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[317] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:27:35 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
20/02/19 06:27:35 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:27:35 INFO Executor: Running task 0.0 in stage 84.0 (TID 100)
20/02/19 06:27:35 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:27:35 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:27:35 INFO Executor: Finished task 0.0 in stage 84.0 (TID 100). 1189 bytes result sent to driver
20/02/19 06:27:35 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 100) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:27:35 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
20/02/19 06:27:35 INFO DAGScheduler: ResultStage 84 (csv at <unknown>:0) finished in 0.004 s
20/02/19 06:27:35 INFO DAGScheduler: Job 61 finished: csv at <unknown>:0, took 0.008196 s
20/02/19 06:27:35 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:27:35 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:27:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:27:35 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:27:36 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 253.9 KB, free 398.2 MB)
20/02/19 06:27:36 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 23.9 KB, free 398.2 MB)
20/02/19 06:27:36 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.2 MB)
20/02/19 06:27:36 INFO SparkContext: Created broadcast 116 from csv at <unknown>:0
20/02/19 06:27:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2568
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2535
20/02/19 06:27:36 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.2 MB)
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2538
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2566
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2567
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2569
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2540
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2510
20/02/19 06:27:36 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.3 MB)
20/02/19 06:27:36 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.3 MB)
20/02/19 06:27:36 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.3 MB)
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2539
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2565
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2536
20/02/19 06:27:36 INFO ContextCleaner: Cleaned accumulator 2537
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:02 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:28:02 INFO DAGScheduler: Got job 62 (collect at utils.scala:44) with 2 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 85 (collect at utils.scala:44)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[327] at map at utils.scala:41), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 5.9 KB, free 398.8 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.3 KB, free 398.8 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.3 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[327] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:02 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 85.0 (TID 101)
20/02/19 06:28:02 INFO Executor: Running task 1.0 in stage 85.0 (TID 102)
20/02/19 06:28:02 INFO Executor: Finished task 1.0 in stage 85.0 (TID 102). 851 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 102) in 2 ms on localhost (executor driver) (1/2)
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 85.0 (TID 101). 891 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 101) in 3 ms on localhost (executor driver) (2/2)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 85 (collect at utils.scala:44) finished in 0.003 s
20/02/19 06:28:02 INFO DAGScheduler: Job 62 finished: collect at utils.scala:44, took 0.007299 s
20/02/19 06:28:02 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:02 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1294)) > 0)
20/02/19 06:28:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:02 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 253.9 KB, free 398.5 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 23.9 KB, free 398.5 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.2 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 118 from csv at <unknown>:0
20/02/19 06:28:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:02 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:02 INFO DAGScheduler: Got job 63 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 86 (csv at <unknown>:0)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[330] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 8.2 KB, free 398.5 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 4.3 KB, free 398.5 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.2 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[330] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 86.0 (TID 103)
20/02/19 06:28:02 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:02 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2436
20/02/19 06:28:02 INFO ContextCleaner: Cleaned shuffle 22
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2429
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2433
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2424
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2341
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2426
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2340
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 86.0 (TID 103). 1189 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 103) in 9 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:61681 in memory (size: 137.7 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 86 (csv at <unknown>:0) finished in 0.010 s
20/02/19 06:28:02 INFO DAGScheduler: Job 63 finished: csv at <unknown>:0, took 0.013600 s
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2343
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2427
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2335
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2437
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2421
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2342
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2332
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2331
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2432
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2330
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2337
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2570
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2325
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2339
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2338
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2327
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2329
20/02/19 06:28:02 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2428
20/02/19 06:28:02 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2418
20/02/19 06:28:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:02 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:61681 in memory (size: 137.7 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2431
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2435
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2333
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2422
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2420
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2425
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2336
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2344
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2434
20/02/19 06:28:02 INFO ContextCleaner: Cleaned shuffle 21
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2430
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2334
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2423
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2328
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 253.9 KB, free 407.0 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 23.9 KB, free 407.0 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 120 from csv at <unknown>:0
20/02/19 06:28:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:02 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:02 INFO DAGScheduler: Got job 64 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 87 (csv at <unknown>:0)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[335] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 13.9 KB, free 407.0 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 7.9 KB, free 407.0 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[335] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 87.0 (TID 104)
20/02/19 06:28:02 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:02 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 87.0 (TID 104). 1481 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 104) in 34 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 87 (csv at <unknown>:0) finished in 0.035 s
20/02/19 06:28:02 INFO DAGScheduler: Job 64 finished: csv at <unknown>:0, took 0.039167 s
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:28:02 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:02 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:02 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:28:02 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 254.9 KB, free 406.7 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 24.1 KB, free 406.7 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 122 from sql at <unknown>:0
20/02/19 06:28:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:02 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:28:02 INFO DAGScheduler: Registering RDD 341 (sql at <unknown>:0)
20/02/19 06:28:02 INFO DAGScheduler: Got job 65 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 89 (sql at <unknown>:0)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 88)
20/02/19 06:28:02 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[341] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 17.5 KB, free 406.7 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2595
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2626
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.7 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2627
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2629
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2596
20/02/19 06:28:02 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[341] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2660
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2599
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 88.0 (TID 105)
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2628
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2625
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2600
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2598
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2597
20/02/19 06:28:02 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:02 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:02 INFO MemoryStore: Block rdd_338_0 stored as values in memory (estimated size 71.5 KB, free 407.2 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added rdd_338_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 88.0 (TID 105). 2418 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 105) in 62 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ShuffleMapStage 88 (sql at <unknown>:0) finished in 0.063 s
20/02/19 06:28:02 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:02 INFO DAGScheduler: running: Set()
20/02/19 06:28:02 INFO DAGScheduler: waiting: Set(ResultStage 89)
20/02/19 06:28:02 INFO DAGScheduler: failed: Set()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[344] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 7.0 KB, free 407.2 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 3.7 KB, free 407.2 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[344] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 106, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 89.0 (TID 106)
20/02/19 06:28:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 89.0 (TID 106). 1495 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 106) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 89 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:28:02 INFO DAGScheduler: Job 65 finished: sql at <unknown>:0, took 0.080925 s
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:28:02 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:28:02 INFO DAGScheduler: Registering RDD 347 (collect at utils.scala:204)
20/02/19 06:28:02 INFO DAGScheduler: Got job 66 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 91 (collect at utils.scala:204)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
20/02/19 06:28:02 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[347] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 17.5 KB, free 407.1 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 9.1 KB, free 407.1 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[347] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 90.0 (TID 107)
20/02/19 06:28:02 INFO BlockManager: Found block rdd_338_0 locally
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 90.0 (TID 107). 1694 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 107) in 13 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ShuffleMapStage 90 (collect at utils.scala:204) finished in 0.014 s
20/02/19 06:28:02 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:02 INFO DAGScheduler: running: Set()
20/02/19 06:28:02 INFO DAGScheduler: waiting: Set(ResultStage 91)
20/02/19 06:28:02 INFO DAGScheduler: failed: Set()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[350] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 7.0 KB, free 407.1 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 3.7 KB, free 407.1 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[350] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 108, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 91.0 (TID 108)
20/02/19 06:28:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 91.0 (TID 108). 1452 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 108) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 91 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:28:02 INFO DAGScheduler: Job 66 finished: collect at utils.scala:204, took 0.026165 s
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz11`
WHERE (0 = 1)
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2721
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2664
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2661
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2667
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2663
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2662
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2672
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2666
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2665
20/02/19 06:28:02 INFO ContextCleaner: Cleaned shuffle 23
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2669
20/02/19 06:28:02 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2668
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2670
20/02/19 06:28:02 INFO ContextCleaner: Cleaned accumulator 2671
20/02/19 06:28:02 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:28:02 INFO DAGScheduler: Got job 67 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:28:02 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:44)
20/02/19 06:28:02 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:02 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:02 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[355] at map at utils.scala:41), which has no missing parents
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 5.9 KB, free 407.2 MB)
20/02/19 06:28:02 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.3 KB, free 407.2 MB)
20/02/19 06:28:02 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:28:02 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:02 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 92 (MapPartitionsRDD[355] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:28:02 INFO TaskSchedulerImpl: Adding task set 92.0 with 3 tasks
20/02/19 06:28:02 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:02 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:02 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:02 INFO Executor: Running task 0.0 in stage 92.0 (TID 109)
20/02/19 06:28:02 INFO Executor: Running task 2.0 in stage 92.0 (TID 111)
20/02/19 06:28:02 INFO Executor: Running task 1.0 in stage 92.0 (TID 110)
20/02/19 06:28:02 INFO Executor: Finished task 1.0 in stage 92.0 (TID 110). 894 bytes result sent to driver
20/02/19 06:28:02 INFO Executor: Finished task 0.0 in stage 92.0 (TID 109). 848 bytes result sent to driver
20/02/19 06:28:02 INFO Executor: Finished task 2.0 in stage 92.0 (TID 111). 851 bytes result sent to driver
20/02/19 06:28:02 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 110) in 3 ms on localhost (executor driver) (1/3)
20/02/19 06:28:02 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 109) in 3 ms on localhost (executor driver) (2/3)
20/02/19 06:28:02 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 111) in 3 ms on localhost (executor driver) (3/3)
20/02/19 06:28:02 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
20/02/19 06:28:02 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:44) finished in 0.003 s
20/02/19 06:28:02 INFO DAGScheduler: Job 67 finished: collect at utils.scala:44, took 0.009080 s
20/02/19 06:28:02 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:28:02 INFO MapPartitionsRDD: Removing RDD 338 from persistence list
20/02/19 06:28:02 INFO BlockManager: Removing RDD 338
20/02/19 06:28:03 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:03 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1390)) > 0)
20/02/19 06:28:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:03 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 253.9 KB, free 407.0 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 23.9 KB, free 407.0 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 128 from csv at <unknown>:0
20/02/19 06:28:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:03 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:03 INFO DAGScheduler: Got job 68 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:03 INFO DAGScheduler: Final stage: ResultStage 93 (csv at <unknown>:0)
20/02/19 06:28:03 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:03 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:03 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[358] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 8.2 KB, free 407.0 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 4.3 KB, free 407.0 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[358] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 93.0 (TID 112)
20/02/19 06:28:03 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:03 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 93.0 (TID 112). 1189 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 112) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ResultStage 93 (csv at <unknown>:0) finished in 0.004 s
20/02/19 06:28:03 INFO DAGScheduler: Job 68 finished: csv at <unknown>:0, took 0.008022 s
20/02/19 06:28:03 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:03 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:03 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 253.9 KB, free 406.7 MB)
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2782
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2808
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2810
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2812
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2807
20/02/19 06:28:03 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2811
20/02/19 06:28:03 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2809
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 23.9 KB, free 407.0 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 130 from csv at <unknown>:0
20/02/19 06:28:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:03 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:03 INFO DAGScheduler: Got job 69 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:03 INFO DAGScheduler: Final stage: ResultStage 94 (csv at <unknown>:0)
20/02/19 06:28:03 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:03 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:03 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[363] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 13.9 KB, free 407.0 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 7.9 KB, free 407.0 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[363] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 94.0 (TID 113)
20/02/19 06:28:03 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:03 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 94.0 (TID 113). 1524 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 113) in 13 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ResultStage 94 (csv at <unknown>:0) finished in 0.014 s
20/02/19 06:28:03 INFO DAGScheduler: Job 69 finished: csv at <unknown>:0, took 0.017929 s
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:28:03 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:03 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:03 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:28:03 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 254.9 KB, free 406.7 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 24.1 KB, free 406.7 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 132 from sql at <unknown>:0
20/02/19 06:28:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:03 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:28:03 INFO DAGScheduler: Registering RDD 369 (sql at <unknown>:0)
20/02/19 06:28:03 INFO DAGScheduler: Got job 70 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:28:03 INFO DAGScheduler: Final stage: ResultStage 96 (sql at <unknown>:0)
20/02/19 06:28:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
20/02/19 06:28:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 95)
20/02/19 06:28:03 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[369] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 17.5 KB, free 406.7 MB)
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2838
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2839
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.7 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[369] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2840
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2841
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2872
20/02/19 06:28:03 INFO ContextCleaner: Cleaned accumulator 2837
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 95.0 (TID 114)
20/02/19 06:28:03 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:03 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:03 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:03 INFO MemoryStore: Block rdd_366_0 stored as values in memory (estimated size 71.5 KB, free 406.9 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added rdd_366_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.4 MB)
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 95.0 (TID 114). 2418 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 114) in 217 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ShuffleMapStage 95 (sql at <unknown>:0) finished in 0.218 s
20/02/19 06:28:03 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:03 INFO DAGScheduler: running: Set()
20/02/19 06:28:03 INFO DAGScheduler: waiting: Set(ResultStage 96)
20/02/19 06:28:03 INFO DAGScheduler: failed: Set()
20/02/19 06:28:03 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[372] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 7.0 KB, free 406.9 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.9 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[372] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 115, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 96.0 (TID 115)
20/02/19 06:28:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 96.0 (TID 115). 1452 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 115) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ResultStage 96 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:28:03 INFO DAGScheduler: Job 70 finished: sql at <unknown>:0, took 0.245740 s
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:28:03 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:28:03 INFO DAGScheduler: Registering RDD 375 (collect at utils.scala:204)
20/02/19 06:28:03 INFO DAGScheduler: Got job 71 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:28:03 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:204)
20/02/19 06:28:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
20/02/19 06:28:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
20/02/19 06:28:03 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[375] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 17.5 KB, free 406.9 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.9 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[375] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 97.0 (TID 116)
20/02/19 06:28:03 INFO BlockManager: Found block rdd_366_0 locally
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 97.0 (TID 116). 1737 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 116) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ShuffleMapStage 97 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:28:03 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:03 INFO DAGScheduler: running: Set()
20/02/19 06:28:03 INFO DAGScheduler: waiting: Set(ResultStage 98)
20/02/19 06:28:03 INFO DAGScheduler: failed: Set()
20/02/19 06:28:03 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[378] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 7.0 KB, free 406.9 MB)
20/02/19 06:28:03 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.8 MB)
20/02/19 06:28:03 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:03 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[378] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:03 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
20/02/19 06:28:03 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 117, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:03 INFO Executor: Running task 0.0 in stage 98.0 (TID 117)
20/02/19 06:28:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:03 INFO Executor: Finished task 0.0 in stage 98.0 (TID 117). 1495 bytes result sent to driver
20/02/19 06:28:03 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 117) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:03 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
20/02/19 06:28:03 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:204) finished in 0.005 s
20/02/19 06:28:03 INFO DAGScheduler: Job 71 finished: collect at utils.scala:204, took 0.022086 s
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz12`
WHERE (0 = 1)
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2874
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2877
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2873
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2884
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2880
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2878
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2879
20/02/19 06:28:04 INFO ContextCleaner: Cleaned shuffle 25
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2875
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2876
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2883
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2882
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2933
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2881
20/02/19 06:28:04 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:28:04 INFO DAGScheduler: Got job 72 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:28:04 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:44)
20/02/19 06:28:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:04 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[383] at map at utils.scala:41), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 5.9 KB, free 406.9 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 3.3 KB, free 406.9 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 99 (MapPartitionsRDD[383] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 99.0 with 3 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:04 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 119, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:04 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 120, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:04 INFO Executor: Running task 1.0 in stage 99.0 (TID 119)
20/02/19 06:28:04 INFO Executor: Running task 2.0 in stage 99.0 (TID 120)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 99.0 (TID 118)
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 99.0 (TID 118). 934 bytes result sent to driver
20/02/19 06:28:04 INFO Executor: Finished task 2.0 in stage 99.0 (TID 120). 937 bytes result sent to driver
20/02/19 06:28:04 INFO Executor: Finished task 1.0 in stage 99.0 (TID 119). 937 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 118) in 6 ms on localhost (executor driver) (1/3)
20/02/19 06:28:04 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 120) in 5 ms on localhost (executor driver) (2/3)
20/02/19 06:28:04 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 119) in 7 ms on localhost (executor driver) (3/3)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:44) finished in 0.007 s
20/02/19 06:28:04 INFO DAGScheduler: Job 72 finished: collect at utils.scala:44, took 0.013540 s
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: DROP TABLE `mut_tab`
20/02/19 06:28:04 INFO MapPartitionsRDD: Removing RDD 217 from persistence list
20/02/19 06:28:04 INFO BlockManager: Removing RDD 217
20/02/19 06:28:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1500)) > 0)
20/02/19 06:28:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 253.9 KB, free 406.7 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.7 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 138 from csv at <unknown>:0
20/02/19 06:28:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:04 INFO DAGScheduler: Got job 73 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:04 INFO DAGScheduler: Final stage: ResultStage 100 (csv at <unknown>:0)
20/02/19 06:28:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:04 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[386] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 8.2 KB, free 406.7 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 4.3 KB, free 406.7 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[386] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 100.0 (TID 121)
20/02/19 06:28:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:28:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 100.0 (TID 121). 1189 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 121) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ResultStage 100 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:28:04 INFO DAGScheduler: Job 73 finished: csv at <unknown>:0, took 0.008861 s
20/02/19 06:28:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 253.9 KB, free 406.5 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3022
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3023
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3019
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3020
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 2994
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3024
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3021
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.7 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 140 from csv at <unknown>:0
20/02/19 06:28:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:04 INFO DAGScheduler: Got job 74 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:04 INFO DAGScheduler: Final stage: ResultStage 101 (csv at <unknown>:0)
20/02/19 06:28:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:04 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[391] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 13.9 KB, free 406.7 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 7.9 KB, free 406.7 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[391] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 101.0 (TID 122)
20/02/19 06:28:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:28:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 101.0 (TID 122). 1481 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 122) in 17 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ResultStage 101 (csv at <unknown>:0) finished in 0.018 s
20/02/19 06:28:04 INFO DAGScheduler: Job 74 finished: csv at <unknown>:0, took 0.021646 s
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:28:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:04 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:28:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 254.9 KB, free 406.5 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 24.1 KB, free 406.4 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 142 from sql at <unknown>:0
20/02/19 06:28:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:04 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:28:04 INFO DAGScheduler: Registering RDD 397 (sql at <unknown>:0)
20/02/19 06:28:04 INFO DAGScheduler: Got job 75 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:28:04 INFO DAGScheduler: Final stage: ResultStage 103 (sql at <unknown>:0)
20/02/19 06:28:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
20/02/19 06:28:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102)
20/02/19 06:28:04 INFO DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[397] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 17.5 KB, free 406.4 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.4 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3050
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[397] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3084
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3049
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 102.0 (TID 123)
20/02/19 06:28:04 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.5 MB)
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3052
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3053
20/02/19 06:28:04 INFO ContextCleaner: Cleaned accumulator 3051
20/02/19 06:28:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:28:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:04 INFO MemoryStore: Block rdd_394_0 stored as values in memory (estimated size 71.8 KB, free 406.6 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added rdd_394_0 in memory on 127.0.0.1:61681 (size: 71.8 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 102.0 (TID 123). 2418 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 123) in 48 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ShuffleMapStage 102 (sql at <unknown>:0) finished in 0.049 s
20/02/19 06:28:04 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:04 INFO DAGScheduler: running: Set()
20/02/19 06:28:04 INFO DAGScheduler: waiting: Set(ResultStage 103)
20/02/19 06:28:04 INFO DAGScheduler: failed: Set()
20/02/19 06:28:04 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[400] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 7.0 KB, free 406.6 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.6 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[400] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 124, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 103.0 (TID 124)
20/02/19 06:28:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 103.0 (TID 124). 1495 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 124) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ResultStage 103 (sql at <unknown>:0) finished in 0.004 s
20/02/19 06:28:04 INFO DAGScheduler: Job 75 finished: sql at <unknown>:0, took 0.066956 s
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:28:04 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:28:04 INFO DAGScheduler: Registering RDD 403 (collect at utils.scala:204)
20/02/19 06:28:04 INFO DAGScheduler: Got job 76 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:28:04 INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:204)
20/02/19 06:28:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
20/02/19 06:28:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
20/02/19 06:28:04 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[403] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 17.5 KB, free 406.6 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 9.1 KB, free 406.6 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:61681 (size: 9.1 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[403] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 104.0 (TID 125)
20/02/19 06:28:04 INFO BlockManager: Found block rdd_394_0 locally
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 104.0 (TID 125). 1694 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 125) in 12 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ShuffleMapStage 104 (collect at utils.scala:204) finished in 0.012 s
20/02/19 06:28:04 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:04 INFO DAGScheduler: running: Set()
20/02/19 06:28:04 INFO DAGScheduler: waiting: Set(ResultStage 105)
20/02/19 06:28:04 INFO DAGScheduler: failed: Set()
20/02/19 06:28:04 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[406] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 7.0 KB, free 406.6 MB)
20/02/19 06:28:04 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.6 MB)
20/02/19 06:28:04 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:04 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[406] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:04 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
20/02/19 06:28:04 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 126, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:04 INFO Executor: Running task 0.0 in stage 105.0 (TID 126)
20/02/19 06:28:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:04 INFO Executor: Finished task 0.0 in stage 105.0 (TID 126). 1495 bytes result sent to driver
20/02/19 06:28:04 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 126) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:04 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
20/02/19 06:28:04 INFO DAGScheduler: ResultStage 105 (collect at utils.scala:204) finished in 0.005 s
20/02/19 06:28:04 INFO DAGScheduler: Job 76 finished: collect at utils.scala:204, took 0.027092 s
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz13`
WHERE (0 = 1)
20/02/19 06:28:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3092
20/02/19 06:28:53 INFO ContextCleaner: Cleaned shuffle 27
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3090
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3087
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3093
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3088
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3094
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3095
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3145
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3096
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3089
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3085
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3091
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:61681 in memory (size: 9.1 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3086
20/02/19 06:28:53 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:28:53 INFO DAGScheduler: Got job 77 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:28:53 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:44)
20/02/19 06:28:53 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:53 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:53 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[411] at map at utils.scala:41), which has no missing parents
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 5.9 KB, free 406.6 MB)
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 3.3 KB, free 406.6 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:53 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 106 (MapPartitionsRDD[411] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:28:53 INFO TaskSchedulerImpl: Adding task set 106.0 with 3 tasks
20/02/19 06:28:53 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:53 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 128, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:53 INFO TaskSetManager: Starting task 2.0 in stage 106.0 (TID 129, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:28:53 INFO Executor: Running task 0.0 in stage 106.0 (TID 127)
20/02/19 06:28:53 INFO Executor: Running task 2.0 in stage 106.0 (TID 129)
20/02/19 06:28:53 INFO Executor: Running task 1.0 in stage 106.0 (TID 128)
20/02/19 06:28:53 INFO Executor: Finished task 0.0 in stage 106.0 (TID 127). 934 bytes result sent to driver
20/02/19 06:28:53 INFO Executor: Finished task 1.0 in stage 106.0 (TID 128). 937 bytes result sent to driver
20/02/19 06:28:53 INFO Executor: Finished task 2.0 in stage 106.0 (TID 129). 937 bytes result sent to driver
20/02/19 06:28:53 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 127) in 5 ms on localhost (executor driver) (1/3)
20/02/19 06:28:53 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 128) in 4 ms on localhost (executor driver) (2/3)
20/02/19 06:28:53 INFO TaskSetManager: Finished task 2.0 in stage 106.0 (TID 129) in 4 ms on localhost (executor driver) (3/3)
20/02/19 06:28:53 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
20/02/19 06:28:53 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:44) finished in 0.005 s
20/02/19 06:28:53 INFO DAGScheduler: Job 77 finished: collect at utils.scala:44, took 0.010696 s
20/02/19 06:28:53 INFO SparkSqlParser: Parsing command: DROP TABLE `ref_tab`
20/02/19 06:28:53 INFO MapPartitionsRDD: Removing RDD 366 from persistence list
20/02/19 06:28:53 INFO BlockManager: Removing RDD 366
20/02/19 06:28:53 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:53 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1603)) > 0)
20/02/19 06:28:53 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:53 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 253.9 KB, free 406.5 MB)
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.4 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO SparkContext: Created broadcast 148 from csv at <unknown>:0
20/02/19 06:28:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:53 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:53 INFO DAGScheduler: Got job 78 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:53 INFO DAGScheduler: Final stage: ResultStage 107 (csv at <unknown>:0)
20/02/19 06:28:53 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:53 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:53 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[414] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 8.2 KB, free 406.4 MB)
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 4.3 KB, free 406.4 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[414] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:53 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
20/02/19 06:28:53 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:53 INFO Executor: Running task 0.0 in stage 107.0 (TID 130)
20/02/19 06:28:53 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:53 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:53 INFO Executor: Finished task 0.0 in stage 107.0 (TID 130). 1189 bytes result sent to driver
20/02/19 06:28:53 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 130) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:28:53 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
20/02/19 06:28:53 INFO DAGScheduler: ResultStage 107 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:28:53 INFO DAGScheduler: Job 78 finished: csv at <unknown>:0, took 0.009329 s
20/02/19 06:28:53 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:53 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:53 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:28:53 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 253.9 KB, free 406.2 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.5 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3231
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.5 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3236
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3235
20/02/19 06:28:53 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.5 MB)
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3234
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3233
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3206
20/02/19 06:28:53 INFO ContextCleaner: Cleaned accumulator 3232
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.4 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO SparkContext: Created broadcast 150 from csv at <unknown>:0
20/02/19 06:28:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:53 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:28:53 INFO DAGScheduler: Got job 79 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:28:53 INFO DAGScheduler: Final stage: ResultStage 108 (csv at <unknown>:0)
20/02/19 06:28:53 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:28:53 INFO DAGScheduler: Missing parents: List()
20/02/19 06:28:53 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[419] at csv at <unknown>:0), which has no missing parents
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 13.9 KB, free 406.4 MB)
20/02/19 06:28:53 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 7.9 KB, free 406.4 MB)
20/02/19 06:28:53 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.4 MB)
20/02/19 06:28:53 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[419] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:53 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
20/02/19 06:28:53 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 131, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:28:53 INFO Executor: Running task 0.0 in stage 108.0 (TID 131)
20/02/19 06:28:53 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:53 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:53 INFO Executor: Finished task 0.0 in stage 108.0 (TID 131). 1481 bytes result sent to driver
20/02/19 06:28:53 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 131) in 17 ms on localhost (executor driver) (1/1)
20/02/19 06:28:53 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
20/02/19 06:28:53 INFO DAGScheduler: ResultStage 108 (csv at <unknown>:0) finished in 0.017 s
20/02/19 06:28:53 INFO DAGScheduler: Job 79 finished: csv at <unknown>:0, took 0.021658 s
20/02/19 06:28:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:28:54 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:28:54 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:28:54 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:28:54 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 254.9 KB, free 406.2 MB)
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 24.1 KB, free 406.2 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO SparkContext: Created broadcast 152 from sql at <unknown>:0
20/02/19 06:28:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:28:54 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:28:54 INFO DAGScheduler: Registering RDD 425 (sql at <unknown>:0)
20/02/19 06:28:54 INFO DAGScheduler: Got job 80 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:28:54 INFO DAGScheduler: Final stage: ResultStage 110 (sql at <unknown>:0)
20/02/19 06:28:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
20/02/19 06:28:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 109)
20/02/19 06:28:54 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[425] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 17.5 KB, free 406.1 MB)
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.1 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[425] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:54 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
20/02/19 06:28:54 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3261
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3264
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3263
20/02/19 06:28:54 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:54 INFO Executor: Running task 0.0 in stage 109.0 (TID 132)
20/02/19 06:28:54 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3265
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3262
20/02/19 06:28:54 INFO ContextCleaner: Cleaned accumulator 3296
20/02/19 06:28:54 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:28:54 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:28:54 INFO MemoryStore: Block rdd_422_0 stored as values in memory (estimated size 71.5 KB, free 406.4 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added rdd_422_0 in memory on 127.0.0.1:61681 (size: 71.5 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO Executor: Finished task 0.0 in stage 109.0 (TID 132). 2418 bytes result sent to driver
20/02/19 06:28:54 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 132) in 49 ms on localhost (executor driver) (1/1)
20/02/19 06:28:54 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
20/02/19 06:28:54 INFO DAGScheduler: ShuffleMapStage 109 (sql at <unknown>:0) finished in 0.049 s
20/02/19 06:28:54 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:54 INFO DAGScheduler: running: Set()
20/02/19 06:28:54 INFO DAGScheduler: waiting: Set(ResultStage 110)
20/02/19 06:28:54 INFO DAGScheduler: failed: Set()
20/02/19 06:28:54 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[428] at sql at <unknown>:0), which has no missing parents
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 7.0 KB, free 406.3 MB)
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.3 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[428] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:54 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
20/02/19 06:28:54 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 133, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:54 INFO Executor: Running task 0.0 in stage 110.0 (TID 133)
20/02/19 06:28:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:54 INFO Executor: Finished task 0.0 in stage 110.0 (TID 133). 1495 bytes result sent to driver
20/02/19 06:28:54 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 133) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:28:54 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
20/02/19 06:28:54 INFO DAGScheduler: ResultStage 110 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:28:54 INFO DAGScheduler: Job 80 finished: sql at <unknown>:0, took 0.066059 s
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:28:54 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:28:54 INFO DAGScheduler: Registering RDD 431 (collect at utils.scala:204)
20/02/19 06:28:54 INFO DAGScheduler: Got job 81 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:28:54 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:204)
20/02/19 06:28:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
20/02/19 06:28:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 111)
20/02/19 06:28:54 INFO DAGScheduler: Submitting ShuffleMapStage 111 (MapPartitionsRDD[431] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 17.5 KB, free 406.3 MB)
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.3 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 111 (MapPartitionsRDD[431] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:54 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
20/02/19 06:28:54 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:28:54 INFO Executor: Running task 0.0 in stage 111.0 (TID 134)
20/02/19 06:28:54 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:28:54 INFO Executor: Finished task 0.0 in stage 111.0 (TID 134). 1694 bytes result sent to driver
20/02/19 06:28:54 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 134) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:28:54 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
20/02/19 06:28:54 INFO DAGScheduler: ShuffleMapStage 111 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:28:54 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:28:54 INFO DAGScheduler: running: Set()
20/02/19 06:28:54 INFO DAGScheduler: waiting: Set(ResultStage 112)
20/02/19 06:28:54 INFO DAGScheduler: failed: Set()
20/02/19 06:28:54 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[434] at collect at utils.scala:204), which has no missing parents
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 7.0 KB, free 406.3 MB)
20/02/19 06:28:54 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.3 MB)
20/02/19 06:28:54 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:28:54 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
20/02/19 06:28:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[434] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:28:54 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
20/02/19 06:28:54 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 135, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:28:54 INFO Executor: Running task 0.0 in stage 112.0 (TID 135)
20/02/19 06:28:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:28:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:28:54 INFO Executor: Finished task 0.0 in stage 112.0 (TID 135). 1452 bytes result sent to driver
20/02/19 06:28:54 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 135) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:28:54 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
20/02/19 06:28:54 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:204) finished in 0.003 s
20/02/19 06:28:54 INFO DAGScheduler: Job 81 finished: collect at utils.scala:204, took 0.018842 s
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz14`
WHERE (0 = 1)
20/02/19 06:28:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:29:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3305
20/02/19 06:29:03 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3308
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3301
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3307
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3299
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3298
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3297
20/02/19 06:29:03 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:29:03 INFO ContextCleaner: Cleaned shuffle 29
20/02/19 06:29:03 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.4 MB)
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3303
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3300
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3357
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3302
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3306
20/02/19 06:29:03 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:29:03 INFO ContextCleaner: Cleaned accumulator 3304
20/02/19 06:29:04 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:29:04 INFO DAGScheduler: Got job 82 (collect at utils.scala:44) with 3 output partitions
20/02/19 06:29:04 INFO DAGScheduler: Final stage: ResultStage 113 (collect at utils.scala:44)
20/02/19 06:29:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:04 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[439] at map at utils.scala:41), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 5.9 KB, free 406.4 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 3.3 KB, free 406.4 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:61681 (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 113 (MapPartitionsRDD[439] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 113.0 with 3 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 136, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:29:04 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 137, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:29:04 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 138, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:29:04 INFO Executor: Running task 2.0 in stage 113.0 (TID 138)
20/02/19 06:29:04 INFO Executor: Running task 1.0 in stage 113.0 (TID 137)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 113.0 (TID 136)
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 113.0 (TID 136). 891 bytes result sent to driver
20/02/19 06:29:04 INFO Executor: Finished task 2.0 in stage 113.0 (TID 138). 894 bytes result sent to driver
20/02/19 06:29:04 INFO Executor: Finished task 1.0 in stage 113.0 (TID 137). 894 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 136) in 5 ms on localhost (executor driver) (1/3)
20/02/19 06:29:04 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 138) in 4 ms on localhost (executor driver) (2/3)
20/02/19 06:29:04 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 137) in 5 ms on localhost (executor driver) (3/3)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ResultStage 113 (collect at utils.scala:44) finished in 0.006 s
20/02/19 06:29:04 INFO DAGScheduler: Job 82 finished: collect at utils.scala:44, took 0.009474 s
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: DROP TABLE `mut_tab`
20/02/19 06:29:04 INFO MapPartitionsRDD: Removing RDD 394 from persistence list
20/02/19 06:29:04 INFO BlockManager: Removing RDD 394
20/02/19 06:29:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:29:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1706)) > 0)
20/02/19 06:29:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:29:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 253.9 KB, free 406.2 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.2 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 158 from csv at <unknown>:0
20/02/19 06:29:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:29:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:29:04 INFO DAGScheduler: Got job 83 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:29:04 INFO DAGScheduler: Final stage: ResultStage 114 (csv at <unknown>:0)
20/02/19 06:29:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:04 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[442] at csv at <unknown>:0), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 8.2 KB, free 406.2 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 4.3 KB, free 406.2 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:61681 (size: 4.3 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[442] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 114.0 (TID 139)
20/02/19 06:29:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:29:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 114.0 (TID 139). 1189 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 139) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ResultStage 114 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:29:04 INFO DAGScheduler: Job 83 finished: csv at <unknown>:0, took 0.011844 s
20/02/19 06:29:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:29:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:29:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:29:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 253.9 KB, free 405.9 MB)
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3443
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3448
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3447
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3418
20/02/19 06:29:04 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:61681 in memory (size: 3.3 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3444
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3445
20/02/19 06:29:04 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:61681 in memory (size: 4.3 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3446
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 23.9 KB, free 406.2 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:61681 (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 160 from csv at <unknown>:0
20/02/19 06:29:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:29:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:29:04 INFO DAGScheduler: Got job 84 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:29:04 INFO DAGScheduler: Final stage: ResultStage 115 (csv at <unknown>:0)
20/02/19 06:29:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:04 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[447] at csv at <unknown>:0), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 13.9 KB, free 406.2 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 7.9 KB, free 406.2 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:61681 (size: 7.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[447] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 115.0 (TID 140)
20/02/19 06:29:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:29:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 115.0 (TID 140). 1481 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 140) in 13 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ResultStage 115 (csv at <unknown>:0) finished in 0.014 s
20/02/19 06:29:04 INFO DAGScheduler: Job 84 finished: csv at <unknown>:0, took 0.017876 s
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:29:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:29:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:29:04 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:29:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 254.9 KB, free 405.9 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 24.1 KB, free 405.9 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:61681 (size: 24.1 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 162 from sql at <unknown>:0
20/02/19 06:29:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:29:04 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:29:04 INFO DAGScheduler: Registering RDD 453 (sql at <unknown>:0)
20/02/19 06:29:04 INFO DAGScheduler: Got job 85 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:29:04 INFO DAGScheduler: Final stage: ResultStage 117 (sql at <unknown>:0)
20/02/19 06:29:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
20/02/19 06:29:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
20/02/19 06:29:04 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[453] at sql at <unknown>:0), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 17.5 KB, free 405.9 MB)
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3473
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 9.0 KB, free 405.9 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:61681 in memory (size: 7.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3474
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[453] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
20/02/19 06:29:04 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:61681 in memory (size: 23.9 KB, free: 413.4 MB)
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3477
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3476
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3508
20/02/19 06:29:04 INFO ContextCleaner: Cleaned accumulator 3475
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 116.0 (TID 141)
20/02/19 06:29:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpoBXfm6/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:29:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:29:04 INFO MemoryStore: Block rdd_450_0 stored as values in memory (estimated size 71.8 KB, free 406.1 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added rdd_450_0 in memory on 127.0.0.1:61681 (size: 71.8 KB, free: 413.3 MB)
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 116.0 (TID 141). 2375 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 141) in 42 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ShuffleMapStage 116 (sql at <unknown>:0) finished in 0.044 s
20/02/19 06:29:04 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:29:04 INFO DAGScheduler: running: Set()
20/02/19 06:29:04 INFO DAGScheduler: waiting: Set(ResultStage 117)
20/02/19 06:29:04 INFO DAGScheduler: failed: Set()
20/02/19 06:29:04 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[456] at sql at <unknown>:0), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.0 KB, free 406.1 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.1 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.3 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[456] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 142, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 117.0 (TID 142)
20/02/19 06:29:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 117.0 (TID 142). 1452 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 142) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ResultStage 117 (sql at <unknown>:0) finished in 0.003 s
20/02/19 06:29:04 INFO DAGScheduler: Job 85 finished: sql at <unknown>:0, took 0.060137 s
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:29:04 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:29:04 INFO DAGScheduler: Registering RDD 459 (collect at utils.scala:204)
20/02/19 06:29:04 INFO DAGScheduler: Got job 86 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:29:04 INFO DAGScheduler: Final stage: ResultStage 119 (collect at utils.scala:204)
20/02/19 06:29:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
20/02/19 06:29:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 118)
20/02/19 06:29:04 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[459] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 17.5 KB, free 406.1 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 9.0 KB, free 406.0 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:61681 (size: 9.0 KB, free: 413.3 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[459] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 118.0 (TID 143)
20/02/19 06:29:04 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 118.0 (TID 143). 1737 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 143) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ShuffleMapStage 118 (collect at utils.scala:204) finished in 0.007 s
20/02/19 06:29:04 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:29:04 INFO DAGScheduler: running: Set()
20/02/19 06:29:04 INFO DAGScheduler: waiting: Set(ResultStage 119)
20/02/19 06:29:04 INFO DAGScheduler: failed: Set()
20/02/19 06:29:04 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[462] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 7.0 KB, free 406.0 MB)
20/02/19 06:29:04 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 3.7 KB, free 406.0 MB)
20/02/19 06:29:04 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:61681 (size: 3.7 KB, free: 413.3 MB)
20/02/19 06:29:04 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[462] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:04 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
20/02/19 06:29:04 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 144, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:29:04 INFO Executor: Running task 0.0 in stage 119.0 (TID 144)
20/02/19 06:29:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:04 INFO Executor: Finished task 0.0 in stage 119.0 (TID 144). 1495 bytes result sent to driver
20/02/19 06:29:04 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 144) in 3 ms on localhost (executor driver) (1/1)
20/02/19 06:29:04 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
20/02/19 06:29:04 INFO DAGScheduler: ResultStage 119 (collect at utils.scala:204) finished in 0.003 s
20/02/19 06:29:04 INFO DAGScheduler: Job 86 finished: collect at utils.scala:204, took 0.018894 s
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz15`
WHERE (0 = 1)
20/02/19 06:29:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:29:10 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:29:10 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 1000
20/02/19 06:29:10 INFO ContextCleaner: Cleaned shuffle 31
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3515
20/02/19 06:29:10 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:29:10 INFO DAGScheduler: Got job 87 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:29:10 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:204)
20/02/19 06:29:10 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:10 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.3 MB)
20/02/19 06:29:10 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:10 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[464] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3569
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3514
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3517
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3509
20/02/19 06:29:10 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 13.7 KB, free 406.0 MB)
20/02/19 06:29:10 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 7.6 KB, free 406.0 MB)
20/02/19 06:29:10 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.3 MB)
20/02/19 06:29:10 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3511
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3519
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3516
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3513
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3518
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3512
20/02/19 06:29:10 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3520
20/02/19 06:29:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[464] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:10 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
20/02/19 06:29:10 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:29:10 INFO Executor: Running task 0.0 in stage 120.0 (TID 145)
20/02/19 06:29:10 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:61681 in memory (size: 9.0 KB, free: 413.3 MB)
20/02/19 06:29:10 INFO ContextCleaner: Cleaned accumulator 3510
20/02/19 06:29:10 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:61681 in memory (size: 3.7 KB, free: 413.3 MB)
20/02/19 06:29:10 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:29:10 INFO Executor: 1 block locks were not released by TID = 145:
[rdd_422_0]
20/02/19 06:29:10 INFO Executor: Finished task 0.0 in stage 120.0 (TID 145). 8694 bytes result sent to driver
20/02/19 06:29:10 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 145) in 7 ms on localhost (executor driver) (1/1)
20/02/19 06:29:10 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
20/02/19 06:29:10 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:29:10 INFO DAGScheduler: Job 87 finished: collect at utils.scala:204, took 0.014810 s
20/02/19 06:29:35 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:29:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM ((SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)) `dbplyr_003`
LIMIT 1000
20/02/19 06:29:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:29:35 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:29:35 INFO DAGScheduler: Got job 88 (run at <unknown>:0) with 1 output partitions
20/02/19 06:29:35 INFO DAGScheduler: Final stage: ResultStage 121 (run at <unknown>:0)
20/02/19 06:29:35 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:35 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:35 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[466] at run at <unknown>:0), which has no missing parents
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 13.8 KB, free 406.1 MB)
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 7.6 KB, free 406.1 MB)
20/02/19 06:29:35 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[466] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:35 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
20/02/19 06:29:35 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:29:35 INFO Executor: Running task 0.0 in stage 121.0 (TID 146)
20/02/19 06:29:35 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:29:35 INFO CodeGenerator: Code generated in 16.2152 ms
20/02/19 06:29:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:29:35 INFO Executor: Finished task 0.0 in stage 121.0 (TID 146). 41383 bytes result sent to driver
20/02/19 06:29:35 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 146) in 11 ms on localhost (executor driver) (1/1)
20/02/19 06:29:35 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
20/02/19 06:29:35 INFO DAGScheduler: ResultStage 121 (run at <unknown>:0) finished in 0.011 s
20/02/19 06:29:35 INFO DAGScheduler: Job 88 finished: run at <unknown>:0, took 0.015332 s
20/02/19 06:29:35 INFO CodeGenerator: Code generated in 4.7211 ms
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 4.3 MB, free 401.8 MB)
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 95.3 KB, free 401.7 MB)
20/02/19 06:29:35 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:61681 (size: 95.3 KB, free: 413.2 MB)
20/02/19 06:29:35 INFO SparkContext: Created broadcast 169 from run at <unknown>:0
20/02/19 06:29:35 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3146
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3147
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3081
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3082
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3080
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3083
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3578
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3151
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3572
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3576
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3079
20/02/19 06:29:35 INFO ContextCleaner: Cleaned shuffle 28
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3154
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3574
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3570
20/02/19 06:29:35 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3581
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3577
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3078
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3153
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3580
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3655
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3157
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3156
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3575
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3155
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3657
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3571
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3150
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3149
20/02/19 06:29:35 INFO ContextCleaner: Cleaned shuffle 32
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3630
20/02/19 06:29:35 INFO BlockManager: Removing RDD 394
20/02/19 06:29:35 INFO ContextCleaner: Cleaned RDD 394
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3148
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3152
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3573
20/02/19 06:29:35 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO ContextCleaner: Cleaned accumulator 3579
20/02/19 06:29:35 INFO CodeGenerator: Code generated in 23.9651 ms
20/02/19 06:29:35 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:29:35 INFO DAGScheduler: Registering RDD 469 (collect at utils.scala:204)
20/02/19 06:29:35 INFO DAGScheduler: Got job 89 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:29:35 INFO DAGScheduler: Final stage: ResultStage 123 (collect at utils.scala:204)
20/02/19 06:29:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
20/02/19 06:29:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
20/02/19 06:29:35 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[469] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 28.3 KB, free 402.0 MB)
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 13.3 KB, free 402.0 MB)
20/02/19 06:29:35 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:61681 (size: 13.3 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[469] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:35 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
20/02/19 06:29:35 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:29:35 INFO Executor: Running task 0.0 in stage 122.0 (TID 147)
20/02/19 06:29:35 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:29:35 INFO CodeGenerator: Code generated in 6.6482 ms
20/02/19 06:29:35 INFO Executor: Finished task 0.0 in stage 122.0 (TID 147). 2409 bytes result sent to driver
20/02/19 06:29:35 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 147) in 37 ms on localhost (executor driver) (1/1)
20/02/19 06:29:35 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
20/02/19 06:29:35 INFO DAGScheduler: ShuffleMapStage 122 (collect at utils.scala:204) finished in 0.037 s
20/02/19 06:29:35 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:29:35 INFO DAGScheduler: running: Set()
20/02/19 06:29:35 INFO DAGScheduler: waiting: Set(ResultStage 123)
20/02/19 06:29:35 INFO DAGScheduler: failed: Set()
20/02/19 06:29:35 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[472] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 17.5 KB, free 402.0 MB)
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 8.1 KB, free 402.0 MB)
20/02/19 06:29:35 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[472] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:35 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
20/02/19 06:29:35 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 148, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:29:35 INFO Executor: Running task 0.0 in stage 123.0 (TID 148)
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:35 INFO Executor: Finished task 0.0 in stage 123.0 (TID 148). 2773 bytes result sent to driver
20/02/19 06:29:35 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 148) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:29:35 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
20/02/19 06:29:35 INFO DAGScheduler: ResultStage 123 (collect at utils.scala:204) finished in 0.009 s
20/02/19 06:29:35 INFO DAGScheduler: Job 89 finished: collect at utils.scala:204, took 0.057111 s
20/02/19 06:29:35 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:29:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 147 bytes
20/02/19 06:29:35 INFO DAGScheduler: Got job 90 (collect at utils.scala:204) with 3 output partitions
20/02/19 06:29:35 INFO DAGScheduler: Final stage: ResultStage 125 (collect at utils.scala:204)
20/02/19 06:29:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
20/02/19 06:29:35 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:35 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[472] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 17.5 KB, free 402.0 MB)
20/02/19 06:29:35 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 8.1 KB, free 401.9 MB)
20/02/19 06:29:35 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.3 MB)
20/02/19 06:29:35 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 125 (MapPartitionsRDD[472] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(1, 2, 3))
20/02/19 06:29:35 INFO TaskSchedulerImpl: Adding task set 125.0 with 3 tasks
20/02/19 06:29:35 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 149, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:29:35 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 150, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:29:35 INFO TaskSetManager: Starting task 2.0 in stage 125.0 (TID 151, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:29:35 INFO Executor: Running task 0.0 in stage 125.0 (TID 149)
20/02/19 06:29:35 INFO Executor: Running task 2.0 in stage 125.0 (TID 151)
20/02/19 06:29:35 INFO Executor: Running task 1.0 in stage 125.0 (TID 150)
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:35 INFO Executor: Finished task 0.0 in stage 125.0 (TID 149). 2769 bytes result sent to driver
20/02/19 06:29:35 INFO Executor: Finished task 1.0 in stage 125.0 (TID 150). 2792 bytes result sent to driver
20/02/19 06:29:35 INFO Executor: Finished task 2.0 in stage 125.0 (TID 151). 2763 bytes result sent to driver
20/02/19 06:29:35 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 149) in 15 ms on localhost (executor driver) (1/3)
20/02/19 06:29:35 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 150) in 15 ms on localhost (executor driver) (2/3)
20/02/19 06:29:35 INFO TaskSetManager: Finished task 2.0 in stage 125.0 (TID 151) in 15 ms on localhost (executor driver) (3/3)
20/02/19 06:29:35 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
20/02/19 06:29:36 INFO DAGScheduler: ResultStage 125 (collect at utils.scala:204) finished in 0.017 s
20/02/19 06:29:36 INFO DAGScheduler: Job 90 finished: collect at utils.scala:204, took 0.026658 s
20/02/19 06:29:48 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:29:48 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:29:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:29:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:29:48 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:29:48 INFO DAGScheduler: Got job 91 (run at <unknown>:0) with 1 output partitions
20/02/19 06:29:48 INFO DAGScheduler: Final stage: ResultStage 126 (run at <unknown>:0)
20/02/19 06:29:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:29:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:29:48 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[474] at run at <unknown>:0), which has no missing parents
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 13.8 KB, free 401.9 MB)
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 7.6 KB, free 401.9 MB)
20/02/19 06:29:48 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.2 MB)
20/02/19 06:29:48 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[474] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:48 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
20/02/19 06:29:48 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:29:48 INFO Executor: Running task 0.0 in stage 126.0 (TID 152)
20/02/19 06:29:48 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:29:48 INFO Executor: Finished task 0.0 in stage 126.0 (TID 152). 41340 bytes result sent to driver
20/02/19 06:29:48 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 152) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:29:48 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
20/02/19 06:29:48 INFO DAGScheduler: ResultStage 126 (run at <unknown>:0) finished in 0.008 s
20/02/19 06:29:48 INFO DAGScheduler: Job 91 finished: run at <unknown>:0, took 0.014179 s
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 4.3 MB, free 397.7 MB)
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 95.3 KB, free 397.6 MB)
20/02/19 06:29:48 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:61681 (size: 95.3 KB, free: 413.2 MB)
20/02/19 06:29:48 INFO SparkContext: Created broadcast 174 from run at <unknown>:0
20/02/19 06:29:48 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:29:48 INFO DAGScheduler: Registering RDD 477 (collect at utils.scala:204)
20/02/19 06:29:48 INFO DAGScheduler: Got job 92 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:29:48 INFO DAGScheduler: Final stage: ResultStage 128 (collect at utils.scala:204)
20/02/19 06:29:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
20/02/19 06:29:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 127)
20/02/19 06:29:48 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[477] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 28.3 KB, free 397.6 MB)
20/02/19 06:29:48 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 13.3 KB, free 397.5 MB)
20/02/19 06:29:48 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:61681 (size: 13.3 KB, free: 413.1 MB)
20/02/19 06:29:48 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[477] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:29:48 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
20/02/19 06:29:49 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:29:49 INFO Executor: Running task 0.0 in stage 127.0 (TID 153)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3359
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.2 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3772
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3774
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2867
20/02/19 06:29:49 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:29:49 INFO BlockManager: Removing RDD 45
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 45
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 799
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2727
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2079
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 561
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.2 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 869
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1082
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3363
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2656
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 870
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1011
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2944
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 185
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1010
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 866
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1668
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2654
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 560
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 182
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2237
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 796
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 422
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 181
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2940
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2724
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 178
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 363
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2659
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.2 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3364
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 423
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3367
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 347
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3358
20/02/19 06:29:49 INFO BlockManager: Removing RDD 366
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 366
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1081
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2240
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.2 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2234
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 109
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2245
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2231
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1080
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 349
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1075
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3368
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2728
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 24
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 873
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 412
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2242
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 562
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2732
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 413
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.2 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2239
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.3 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1007
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2251
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1670
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 794
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 362
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 359
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 113
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2238
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2870
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 9
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 186
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3365
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 350
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2730
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3360
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 26
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2936
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 872
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2232
20/02/19 06:29:49 INFO BlockManager: Removing RDD 103
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 103
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2731
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2250
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1074
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 30
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1969
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2723
20/02/19 06:29:49 INFO BlockManager: Removing RDD 338
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 338
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 179
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2080
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 236
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 1
20/02/19 06:29:49 INFO BlockManager: Removing RDD 271
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 271
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2934
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1671
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 2
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2942
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2722
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 798
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1077
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 424
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2945
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2943
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1078
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 871
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2082
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 180
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.3 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2655
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 865
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 558
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2236
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 183
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 358
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 20
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 868
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 414
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3369
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 864
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2726
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3366
20/02/19 06:29:49 INFO ContextCleaner: Cleaned shuffle 7
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 177
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1006
20/02/19 06:29:49 INFO BlockManager: Removing RDD 73
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 73
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 797
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 348
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 863
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2939
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2248
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1083
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 862
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2083
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2866
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2935
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2247
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 345
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 867
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 795
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 112
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 419
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2869
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 559
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2658
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:61681 in memory (size: 137.7 KB, free: 413.4 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2868
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3361
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 418
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 417
20/02/19 06:29:49 INFO BlockManager: Removing RDD 131
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 131
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.4 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 176
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2081
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2078
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1008
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2725
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 415
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2938
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2871
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1076
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2244
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1672
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1084
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1669
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 111
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2729
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1085
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1079
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 110
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 352
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:61681 in memory (size: 8.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2733
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:61681 in memory (size: 13.3 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 187
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1667
20/02/19 06:29:49 INFO BlockManager: Removing RDD 15
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 15
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 421
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2246
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2235
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2233
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 184
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO BlockManager: Removing RDD 217
20/02/19 06:29:49 INFO ContextCleaner: Cleaned RDD 217
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2941
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 3362
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1009
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 416
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2937
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2249
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2243
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 420
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 346
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2657
20/02/19 06:29:49 INFO Executor: Finished task 0.0 in stage 127.0 (TID 153). 2495 bytes result sent to driver
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:61681 in memory (size: 8.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 2241
20/02/19 06:29:49 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 153) in 157 ms on localhost (executor driver) (1/1)
20/02/19 06:29:49 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
20/02/19 06:29:49 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:61681 in memory (size: 24.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO DAGScheduler: ShuffleMapStage 127 (collect at utils.scala:204) finished in 0.158 s
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 557
20/02/19 06:29:49 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 1134
20/02/19 06:29:49 INFO DAGScheduler: running: Set()
20/02/19 06:29:49 INFO ContextCleaner: Cleaned accumulator 108
20/02/19 06:29:49 INFO DAGScheduler: waiting: Set(ResultStage 128)
20/02/19 06:29:49 INFO DAGScheduler: failed: Set()
20/02/19 06:29:49 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[480] at collect at utils.scala:204), which has no missing parents
20/02/19 06:29:49 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 17.7 KB, free 404.5 MB)
20/02/19 06:29:49 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 8.1 KB, free 404.5 MB)
20/02/19 06:29:49 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.5 MB)
20/02/19 06:29:49 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
20/02/19 06:29:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[480] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:29:49 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks
20/02/19 06:29:49 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 154, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:29:49 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 155, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:29:49 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 156, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:29:49 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 157, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:29:49 INFO Executor: Running task 1.0 in stage 128.0 (TID 155)
20/02/19 06:29:49 INFO Executor: Running task 2.0 in stage 128.0 (TID 156)
20/02/19 06:29:49 INFO Executor: Running task 0.0 in stage 128.0 (TID 154)
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:49 INFO Executor: Running task 3.0 in stage 128.0 (TID 157)
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:29:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:29:49 INFO Executor: Finished task 1.0 in stage 128.0 (TID 155). 2793 bytes result sent to driver
20/02/19 06:29:49 INFO Executor: Finished task 0.0 in stage 128.0 (TID 154). 2843 bytes result sent to driver
20/02/19 06:29:49 INFO Executor: Finished task 3.0 in stage 128.0 (TID 157). 2787 bytes result sent to driver
20/02/19 06:29:49 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 155) in 10 ms on localhost (executor driver) (1/4)
20/02/19 06:29:49 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 154) in 10 ms on localhost (executor driver) (2/4)
20/02/19 06:29:49 INFO Executor: Finished task 2.0 in stage 128.0 (TID 156). 2773 bytes result sent to driver
20/02/19 06:29:49 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 157) in 10 ms on localhost (executor driver) (3/4)
20/02/19 06:29:49 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 156) in 12 ms on localhost (executor driver) (4/4)
20/02/19 06:29:49 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
20/02/19 06:29:49 INFO DAGScheduler: ResultStage 128 (collect at utils.scala:204) finished in 0.012 s
20/02/19 06:29:49 INFO DAGScheduler: Job 92 finished: collect at utils.scala:204, took 0.184347 s
20/02/19 06:30:24 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:30:24 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:30:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:30:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:30:24 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:30:24 INFO DAGScheduler: Got job 93 (run at <unknown>:0) with 1 output partitions
20/02/19 06:30:24 INFO DAGScheduler: Final stage: ResultStage 129 (run at <unknown>:0)
20/02/19 06:30:24 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:30:24 INFO DAGScheduler: Missing parents: List()
20/02/19 06:30:24 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[482] at run at <unknown>:0), which has no missing parents
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 13.8 KB, free 404.5 MB)
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 7.6 KB, free 404.5 MB)
20/02/19 06:30:24 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.5 MB)
20/02/19 06:30:24 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1006
20/02/19 06:30:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[482] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:30:24 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks
20/02/19 06:30:24 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:30:24 INFO Executor: Running task 0.0 in stage 129.0 (TID 158)
20/02/19 06:30:24 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:30:24 INFO Executor: Finished task 0.0 in stage 129.0 (TID 158). 41340 bytes result sent to driver
20/02/19 06:30:24 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 158) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:30:24 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
20/02/19 06:30:24 INFO DAGScheduler: ResultStage 129 (run at <unknown>:0) finished in 0.005 s
20/02/19 06:30:24 INFO DAGScheduler: Job 93 finished: run at <unknown>:0, took 0.010664 s
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 4.3 MB, free 400.2 MB)
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 95.3 KB, free 400.1 MB)
20/02/19 06:30:24 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:61681 (size: 95.3 KB, free: 413.4 MB)
20/02/19 06:30:24 INFO SparkContext: Created broadcast 178 from run at <unknown>:0
20/02/19 06:30:24 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:30:24 INFO DAGScheduler: Registering RDD 485 (collect at utils.scala:204)
20/02/19 06:30:24 INFO DAGScheduler: Got job 94 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:30:24 INFO DAGScheduler: Final stage: ResultStage 131 (collect at utils.scala:204)
20/02/19 06:30:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
20/02/19 06:30:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
20/02/19 06:30:24 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[485] at collect at utils.scala:204), which has no missing parents
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 28.3 KB, free 400.1 MB)
20/02/19 06:30:24 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:61681 in memory (size: 8.1 KB, free: 413.4 MB)
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 13.3 KB, free 400.1 MB)
20/02/19 06:30:24 INFO ContextCleaner: Cleaned accumulator 3867
20/02/19 06:30:24 INFO ContextCleaner: Cleaned accumulator 3865
20/02/19 06:30:24 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:61681 (size: 13.3 KB, free: 413.4 MB)
20/02/19 06:30:24 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1006
20/02/19 06:30:24 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.4 MB)
20/02/19 06:30:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[485] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:30:24 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
20/02/19 06:30:24 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 159, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:30:24 INFO Executor: Running task 0.0 in stage 130.0 (TID 159)
20/02/19 06:30:24 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:30:24 INFO Executor: Finished task 0.0 in stage 130.0 (TID 159). 2452 bytes result sent to driver
20/02/19 06:30:24 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 159) in 30 ms on localhost (executor driver) (1/1)
20/02/19 06:30:24 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
20/02/19 06:30:24 INFO DAGScheduler: ShuffleMapStage 130 (collect at utils.scala:204) finished in 0.031 s
20/02/19 06:30:24 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:30:24 INFO DAGScheduler: running: Set()
20/02/19 06:30:24 INFO DAGScheduler: waiting: Set(ResultStage 131)
20/02/19 06:30:24 INFO DAGScheduler: failed: Set()
20/02/19 06:30:24 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[488] at collect at utils.scala:204), which has no missing parents
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 17.7 KB, free 400.1 MB)
20/02/19 06:30:24 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 8.1 KB, free 400.1 MB)
20/02/19 06:30:24 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.4 MB)
20/02/19 06:30:24 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
20/02/19 06:30:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 131 (MapPartitionsRDD[488] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:30:24 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks
20/02/19 06:30:24 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 160, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:30:24 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 161, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:30:24 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 162, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:30:24 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 163, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:30:24 INFO Executor: Running task 0.0 in stage 131.0 (TID 160)
20/02/19 06:30:24 INFO Executor: Running task 3.0 in stage 131.0 (TID 163)
20/02/19 06:30:24 INFO Executor: Running task 2.0 in stage 131.0 (TID 162)
20/02/19 06:30:24 INFO Executor: Running task 1.0 in stage 131.0 (TID 161)
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:30:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:30:24 INFO Executor: Finished task 1.0 in stage 131.0 (TID 161). 2793 bytes result sent to driver
20/02/19 06:30:24 INFO Executor: Finished task 3.0 in stage 131.0 (TID 163). 2830 bytes result sent to driver
20/02/19 06:30:24 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 161) in 10 ms on localhost (executor driver) (1/4)
20/02/19 06:30:24 INFO Executor: Finished task 0.0 in stage 131.0 (TID 160). 2843 bytes result sent to driver
20/02/19 06:30:24 INFO Executor: Finished task 2.0 in stage 131.0 (TID 162). 2816 bytes result sent to driver
20/02/19 06:30:24 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 163) in 11 ms on localhost (executor driver) (2/4)
20/02/19 06:30:24 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 160) in 11 ms on localhost (executor driver) (3/4)
20/02/19 06:30:24 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 162) in 12 ms on localhost (executor driver) (4/4)
20/02/19 06:30:24 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
20/02/19 06:30:24 INFO DAGScheduler: ResultStage 131 (collect at utils.scala:204) finished in 0.012 s
20/02/19 06:30:24 INFO DAGScheduler: Job 94 finished: collect at utils.scala:204, took 0.060386 s
20/02/19 06:34:48 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:34:48 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:34:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:34:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:34:48 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:34:48 INFO DAGScheduler: Got job 95 (run at <unknown>:0) with 1 output partitions
20/02/19 06:34:48 INFO DAGScheduler: Final stage: ResultStage 132 (run at <unknown>:0)
20/02/19 06:34:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:34:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:34:48 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[490] at run at <unknown>:0), which has no missing parents
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 13.8 KB, free 400.1 MB)
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 7.6 KB, free 400.1 MB)
20/02/19 06:34:48 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.4 MB)
20/02/19 06:34:48 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1006
20/02/19 06:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[490] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:34:48 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
20/02/19 06:34:48 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:34:48 INFO Executor: Running task 0.0 in stage 132.0 (TID 164)
20/02/19 06:34:48 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:34:48 INFO Executor: Finished task 0.0 in stage 132.0 (TID 164). 41340 bytes result sent to driver
20/02/19 06:34:48 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 164) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:34:48 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
20/02/19 06:34:48 INFO DAGScheduler: ResultStage 132 (run at <unknown>:0) finished in 0.007 s
20/02/19 06:34:48 INFO DAGScheduler: Job 95 finished: run at <unknown>:0, took 0.011886 s
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 4.3 MB, free 395.8 MB)
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 95.3 KB, free 395.7 MB)
20/02/19 06:34:48 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:61681 (size: 95.3 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO SparkContext: Created broadcast 182 from run at <unknown>:0
20/02/19 06:34:48 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:34:48 INFO DAGScheduler: Registering RDD 493 (collect at utils.scala:204)
20/02/19 06:34:48 INFO DAGScheduler: Got job 96 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:34:48 INFO DAGScheduler: Final stage: ResultStage 134 (collect at utils.scala:204)
20/02/19 06:34:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)
20/02/19 06:34:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 133)
20/02/19 06:34:48 INFO DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[493] at collect at utils.scala:204), which has no missing parents
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 28.3 KB, free 395.7 MB)
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 13.3 KB, free 395.7 MB)
20/02/19 06:34:48 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:61681 in memory (size: 13.3 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:61681 (size: 13.3 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1006
20/02/19 06:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[493] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:34:48 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
20/02/19 06:34:48 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:34:48 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO Executor: Running task 0.0 in stage 133.0 (TID 165)
20/02/19 06:34:48 INFO ContextCleaner: Cleaned accumulator 3960
20/02/19 06:34:48 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:61681 in memory (size: 8.1 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:34:48 INFO ContextCleaner: Cleaned accumulator 3958
20/02/19 06:34:48 INFO Executor: Finished task 0.0 in stage 133.0 (TID 165). 2366 bytes result sent to driver
20/02/19 06:34:48 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 165) in 35 ms on localhost (executor driver) (1/1)
20/02/19 06:34:48 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
20/02/19 06:34:48 INFO DAGScheduler: ShuffleMapStage 133 (collect at utils.scala:204) finished in 0.035 s
20/02/19 06:34:48 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:34:48 INFO DAGScheduler: running: Set()
20/02/19 06:34:48 INFO DAGScheduler: waiting: Set(ResultStage 134)
20/02/19 06:34:48 INFO DAGScheduler: failed: Set()
20/02/19 06:34:48 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[496] at collect at utils.scala:204), which has no missing parents
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 17.7 KB, free 395.8 MB)
20/02/19 06:34:48 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 8.1 KB, free 395.8 MB)
20/02/19 06:34:48 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.3 MB)
20/02/19 06:34:48 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
20/02/19 06:34:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 134 (MapPartitionsRDD[496] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:34:48 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks
20/02/19 06:34:48 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 166, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:34:48 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 167, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:34:48 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 168, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:34:48 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 169, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:34:48 INFO Executor: Running task 0.0 in stage 134.0 (TID 166)
20/02/19 06:34:48 INFO Executor: Running task 3.0 in stage 134.0 (TID 169)
20/02/19 06:34:48 INFO Executor: Running task 2.0 in stage 134.0 (TID 168)
20/02/19 06:34:48 INFO Executor: Running task 1.0 in stage 134.0 (TID 167)
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
20/02/19 06:34:48 INFO Executor: Finished task 2.0 in stage 134.0 (TID 168). 2773 bytes result sent to driver
20/02/19 06:34:48 INFO Executor: Finished task 0.0 in stage 134.0 (TID 166). 2800 bytes result sent to driver
20/02/19 06:34:48 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 168) in 16 ms on localhost (executor driver) (1/4)
20/02/19 06:34:48 INFO Executor: Finished task 1.0 in stage 134.0 (TID 167). 2750 bytes result sent to driver
20/02/19 06:34:48 INFO Executor: Finished task 3.0 in stage 134.0 (TID 169). 2744 bytes result sent to driver
20/02/19 06:34:48 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 166) in 18 ms on localhost (executor driver) (2/4)
20/02/19 06:34:48 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 167) in 17 ms on localhost (executor driver) (3/4)
20/02/19 06:34:48 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 169) in 17 ms on localhost (executor driver) (4/4)
20/02/19 06:34:48 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
20/02/19 06:34:48 INFO DAGScheduler: ResultStage 134 (collect at utils.scala:204) finished in 0.019 s
20/02/19 06:34:48 INFO DAGScheduler: Job 96 finished: collect at utils.scala:204, took 0.075360 s
20/02/19 06:35:22 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:35:22 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:35:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:35:22 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:35:22 INFO DAGScheduler: Got job 97 (run at <unknown>:0) with 1 output partitions
20/02/19 06:35:22 INFO DAGScheduler: Final stage: ResultStage 135 (run at <unknown>:0)
20/02/19 06:35:22 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:35:22 INFO DAGScheduler: Missing parents: List()
20/02/19 06:35:22 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[498] at run at <unknown>:0), which has no missing parents
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 13.8 KB, free 395.7 MB)
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 7.6 KB, free 395.7 MB)
20/02/19 06:35:22 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:61681 (size: 7.6 KB, free: 413.3 MB)
20/02/19 06:35:22 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1006
20/02/19 06:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[498] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:35:22 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks
20/02/19 06:35:22 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:35:22 INFO Executor: Running task 0.0 in stage 135.0 (TID 170)
20/02/19 06:35:22 INFO BlockManager: Found block rdd_450_0 locally
20/02/19 06:35:22 INFO Executor: Finished task 0.0 in stage 135.0 (TID 170). 41383 bytes result sent to driver
20/02/19 06:35:22 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 170) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:35:22 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
20/02/19 06:35:22 INFO DAGScheduler: ResultStage 135 (run at <unknown>:0) finished in 0.006 s
20/02/19 06:35:22 INFO DAGScheduler: Job 97 finished: run at <unknown>:0, took 0.013297 s
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 4.3 MB, free 391.5 MB)
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 95.3 KB, free 391.4 MB)
20/02/19 06:35:22 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:61681 (size: 95.3 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO SparkContext: Created broadcast 186 from run at <unknown>:0
20/02/19 06:35:22 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:35:22 INFO DAGScheduler: Registering RDD 501 (collect at utils.scala:204)
20/02/19 06:35:22 INFO DAGScheduler: Got job 98 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:35:22 INFO DAGScheduler: Final stage: ResultStage 137 (collect at utils.scala:204)
20/02/19 06:35:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)
20/02/19 06:35:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
20/02/19 06:35:22 INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[501] at collect at utils.scala:204), which has no missing parents
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 28.3 KB, free 391.4 MB)
20/02/19 06:35:22 INFO ContextCleaner: Cleaned accumulator 4051
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 13.3 KB, free 391.4 MB)
20/02/19 06:35:22 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:61681 (size: 13.3 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1006
20/02/19 06:35:22 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:61681 in memory (size: 13.3 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[501] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:35:22 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
20/02/19 06:35:22 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:35:22 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:61681 in memory (size: 8.1 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO Executor: Running task 0.0 in stage 136.0 (TID 171)
20/02/19 06:35:22 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:61681 in memory (size: 7.6 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO ContextCleaner: Cleaned accumulator 4053
20/02/19 06:35:22 INFO BlockManager: Found block rdd_422_0 locally
20/02/19 06:35:22 INFO Executor: Finished task 0.0 in stage 136.0 (TID 171). 2452 bytes result sent to driver
20/02/19 06:35:22 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 171) in 34 ms on localhost (executor driver) (1/1)
20/02/19 06:35:22 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
20/02/19 06:35:22 INFO DAGScheduler: ShuffleMapStage 136 (collect at utils.scala:204) finished in 0.034 s
20/02/19 06:35:22 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:35:22 INFO DAGScheduler: running: Set()
20/02/19 06:35:22 INFO DAGScheduler: waiting: Set(ResultStage 137)
20/02/19 06:35:22 INFO DAGScheduler: failed: Set()
20/02/19 06:35:22 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[504] at collect at utils.scala:204), which has no missing parents
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 17.7 KB, free 391.4 MB)
20/02/19 06:35:22 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 8.1 KB, free 391.4 MB)
20/02/19 06:35:22 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:61681 (size: 8.1 KB, free: 413.2 MB)
20/02/19 06:35:22 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
20/02/19 06:35:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 137 (MapPartitionsRDD[504] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:35:22 INFO TaskSchedulerImpl: Adding task set 137.0 with 4 tasks
20/02/19 06:35:22 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 172, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:35:22 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 173, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:35:22 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 174, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:35:22 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 175, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:35:22 INFO Executor: Running task 0.0 in stage 137.0 (TID 172)
20/02/19 06:35:22 INFO Executor: Running task 3.0 in stage 137.0 (TID 175)
20/02/19 06:35:22 INFO Executor: Running task 1.0 in stage 137.0 (TID 173)
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:35:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:35:22 INFO Executor: Finished task 3.0 in stage 137.0 (TID 175). 2744 bytes result sent to driver
20/02/19 06:35:22 INFO Executor: Running task 2.0 in stage 137.0 (TID 174)
20/02/19 06:35:22 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 175) in 9 ms on localhost (executor driver) (1/4)
20/02/19 06:35:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:35:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:35:23 INFO Executor: Finished task 0.0 in stage 137.0 (TID 172). 2800 bytes result sent to driver
20/02/19 06:35:23 INFO Executor: Finished task 1.0 in stage 137.0 (TID 173). 2750 bytes result sent to driver
20/02/19 06:35:23 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 172) in 12 ms on localhost (executor driver) (2/4)
20/02/19 06:35:23 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 173) in 12 ms on localhost (executor driver) (3/4)
20/02/19 06:35:23 INFO Executor: Finished task 2.0 in stage 137.0 (TID 174). 2859 bytes result sent to driver
20/02/19 06:35:23 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 174) in 14 ms on localhost (executor driver) (4/4)
20/02/19 06:35:23 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
20/02/19 06:35:23 INFO DAGScheduler: ResultStage 137 (collect at utils.scala:204) finished in 0.016 s
20/02/19 06:35:23 INFO DAGScheduler: Job 98 finished: collect at utils.scala:204, took 0.069592 s
20/02/19 06:36:16 INFO SparkContext: Invoking stop() from shutdown hook
20/02/19 06:36:16 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/19 06:36:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/19 06:36:16 INFO MemoryStore: MemoryStore cleared
20/02/19 06:36:16 INFO BlockManager: BlockManager stopped
20/02/19 06:36:16 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/19 06:36:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/19 06:36:16 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1944)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1943)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:36:16 INFO SparkContext: Successfully stopped SparkContext
20/02/19 06:36:16 INFO ShutdownHookManager: Shutdown hook called
20/02/19 06:36:16 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63
20/02/19 06:36:16 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913\userFiles-1076dcd7-9a56-4772-9cf7-0b831e8c0e63
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:36:16 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913
20/02/19 06:36:16 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-5c153085-9ebf-4b28-9c7f-bc5671fc3913
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:36:59 INFO SparkContext: Running Spark version 2.2.1
20/02/19 06:36:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/19 06:36:59 INFO SparkContext: Submitted application: sparklyr
20/02/19 06:36:59 INFO SecurityManager: Changing view acls to: Reinhard
20/02/19 06:36:59 INFO SecurityManager: Changing modify acls to: Reinhard
20/02/19 06:36:59 INFO SecurityManager: Changing view acls groups to: 
20/02/19 06:36:59 INFO SecurityManager: Changing modify acls groups to: 
20/02/19 06:36:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Reinhard); groups with view permissions: Set(); users  with modify permissions: Set(Reinhard); groups with modify permissions: Set()
20/02/19 06:36:59 INFO Utils: Successfully started service 'sparkDriver' on port 51281.
20/02/19 06:36:59 INFO SparkEnv: Registering MapOutputTracker
20/02/19 06:36:59 INFO SparkEnv: Registering BlockManagerMaster
20/02/19 06:36:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/19 06:36:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/19 06:36:59 INFO DiskBlockManager: Created local directory at C:\Users\Reinhard\AppData\Local\Temp\blockmgr-4df3f720-436b-43d3-bb50-0e62853be45d
20/02/19 06:36:59 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
20/02/19 06:36:59 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/19 06:36:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/19 06:36:59 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/19 06:36:59 INFO SparkContext: Added JAR file:/D:/apps/R/R-3.6.1/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:51281/jars/sparklyr-2.0-2.11.jar with timestamp 1582090619872
20/02/19 06:36:59 INFO Executor: Starting executor ID driver on host localhost
20/02/19 06:36:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51302.
20/02/19 06:36:59 INFO NettyBlockTransferService: Server created on 127.0.0.1:51302
20/02/19 06:36:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/19 06:36:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51302, None)
20/02/19 06:36:59 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51302 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 51302, None)
20/02/19 06:36:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51302, None)
20/02/19 06:36:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51302, None)
20/02/19 06:37:00 INFO SharedState: loading hive config file: file:/C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/conf/hive-site.xml
20/02/19 06:37:00 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive').
20/02/19 06:37:00 INFO SharedState: Warehouse path is 'C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive'.
20/02/19 06:37:01 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/02/19 06:37:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:37:02 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:37:02 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:37:02 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
20/02/19 06:37:02 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:02 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:02 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
20/02/19 06:37:03 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/19 06:37:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 413.9 MB)
20/02/19 06:37:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.9 MB)
20/02/19 06:37:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51302 (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:37:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/19 06:37:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
20/02/19 06:37:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/19 06:37:03 INFO Executor: Fetching spark://127.0.0.1:51281/jars/sparklyr-2.0-2.11.jar with timestamp 1582090619872
20/02/19 06:37:03 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51281 after 16 ms (0 ms spent in bootstraps)
20/02/19 06:37:03 INFO Utils: Fetching spark://127.0.0.1:51281/jars/sparklyr-2.0-2.11.jar to C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3\fetchFileTemp3694519306454703354.tmp
20/02/19 06:37:03 INFO Executor: Adding file:/C:/Users/Reinhard/AppData/Local/Temp/spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac/userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3/sparklyr-2.0-2.11.jar to class loader
20/02/19 06:37:03 INFO CodeGenerator: Code generated in 151.0826 ms
20/02/19 06:37:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
20/02/19 06:37:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 613 ms on localhost (executor driver) (1/1)
20/02/19 06:37:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/19 06:37:03 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.636 s
20/02/19 06:37:03 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.828302 s
20/02/19 06:37:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
20/02/19 06:37:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:37:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:04 INFO CodeGenerator: Code generated in 6.3969 ms
20/02/19 06:37:04 INFO CodeGenerator: Code generated in 11.5978 ms
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 253.9 KB, free 413.7 MB)
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.6 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51302 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO SparkContext: Created broadcast 1 from csv at <unknown>:0
20/02/19 06:37:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:37:04 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:37:04 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
20/02/19 06:37:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0), which has no missing parents
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 413.6 MB)
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.6 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51302 (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/19 06:37:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/19 06:37:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:37:04 INFO CodeGenerator: Code generated in 6.9024 ms
20/02/19 06:37:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1275 bytes result sent to driver
20/02/19 06:37:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 62 ms on localhost (executor driver) (1/1)
20/02/19 06:37:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/19 06:37:04 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 0.063 s
20/02/19 06:37:04 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 0.082559 s
20/02/19 06:37:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:37:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:37:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:04 INFO CodeGenerator: Code generated in 3.653 ms
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 253.9 KB, free 413.4 MB)
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 49
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 50
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 51
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.4 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51302 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO SparkContext: Created broadcast 3 from csv at <unknown>:0
20/02/19 06:37:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51302 in memory (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 53
20/02/19 06:37:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:51302 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 54
20/02/19 06:37:04 INFO ContextCleaner: Cleaned accumulator 52
20/02/19 06:37:04 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:37:04 INFO DAGScheduler: Got job 2 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:37:04 INFO DAGScheduler: Final stage: ResultStage 2 (csv at <unknown>:0)
20/02/19 06:37:04 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:04 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0), which has no missing parents
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.9 KB, free 413.6 MB)
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.6 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51302 (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/19 06:37:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/19 06:37:04 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:37:04 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1524 bytes result sent to driver
20/02/19 06:37:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 90 ms on localhost (executor driver) (1/1)
20/02/19 06:37:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/19 06:37:04 INFO DAGScheduler: ResultStage 2 (csv at <unknown>:0) finished in 0.091 s
20/02/19 06:37:04 INFO DAGScheduler: Job 2 finished: csv at <unknown>:0, took 0.103766 s
20/02/19 06:37:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:37:04 INFO CodeGenerator: Code generated in 5.3921 ms
20/02/19 06:37:04 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:37:04 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:37:04 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:37:04 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:04 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:37:04 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:37:04 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 254.9 KB, free 413.4 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51302 in memory (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.4 MB)
20/02/19 06:37:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51302 (size: 24.1 KB, free: 413.9 MB)
20/02/19 06:37:04 INFO SparkContext: Created broadcast 5 from sql at <unknown>:0
20/02/19 06:37:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 6.7491 ms
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 6.5945 ms
20/02/19 06:37:05 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:37:05 INFO DAGScheduler: Registering RDD 18 (sql at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/19 06:37:05 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 413.4 MB)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 114
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51302 (size: 9.0 KB, free: 413.9 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/19 06:37:05 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 4.7982 ms
20/02/19 06:37:05 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:05 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 71.5 KB, free 413.3 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:51302 (size: 71.5 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 2.8747 ms
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 12.3762 ms
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 226 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 0.227 s
20/02/19 06:37:05 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:37:05 INFO DAGScheduler: running: Set()
20/02/19 06:37:05 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/19 06:37:05 INFO DAGScheduler: failed: Set()
20/02/19 06:37:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51302 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/19 06:37:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 31 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.031 s
20/02/19 06:37:05 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 0.311296 s
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51302 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 175
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 3.9329 ms
20/02/19 06:37:05 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:37:05 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
20/02/19 06:37:05 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
20/02/19 06:37:05 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 413.3 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51302 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/19 06:37:05 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1737 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
20/02/19 06:37:05 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:37:05 INFO DAGScheduler: running: Set()
20/02/19 06:37:05 INFO DAGScheduler: waiting: Set(ResultStage 6)
20/02/19 06:37:05 INFO DAGScheduler: failed: Set()
20/02/19 06:37:05 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 413.2 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.2 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51302 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/19 06:37:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1538 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.006 s
20/02/19 06:37:05 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.031402 s
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz1`
WHERE (0 = 1)
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51302 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:51302 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO CodeGenerator: Code generated in 4.4302 ms
20/02/19 06:37:05 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:37:05 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:05 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.9 KB, free 413.3 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.3 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51302 (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 894 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.005 s
20/02/19 06:37:05 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.010291 s
20/02/19 06:37:05 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:05 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#102)) > 0)
20/02/19 06:37:05 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:37:05 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 253.9 KB, free 413.0 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.0 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51302 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 11 from csv at <unknown>:0
20/02/19 06:37:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51302 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 236
20/02/19 06:37:05 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:37:05 INFO DAGScheduler: Got job 6 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 8 (csv at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:05 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 413.0 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.0 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51302 (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/19 06:37:05 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:37:05 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1189 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ResultStage 8 (csv at <unknown>:0) finished in 0.005 s
20/02/19 06:37:05 INFO DAGScheduler: Job 6 finished: csv at <unknown>:0, took 0.012219 s
20/02/19 06:37:05 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:05 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:37:05 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:37:05 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 253.9 KB, free 412.7 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.7 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51302 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 13 from csv at <unknown>:0
20/02/19 06:37:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:05 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:37:05 INFO DAGScheduler: Got job 7 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 9 (csv at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:05 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 13.9 KB, free 412.7 MB)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 266
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 263
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.9 KB, free 412.7 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51302 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51302 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 261
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 265
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51302 in memory (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 264
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 262
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/19 06:37:05 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:37:05 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:05 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1481 bytes result sent to driver
20/02/19 06:37:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 15 ms on localhost (executor driver) (1/1)
20/02/19 06:37:05 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/19 06:37:05 INFO DAGScheduler: ResultStage 9 (csv at <unknown>:0) finished in 0.015 s
20/02/19 06:37:05 INFO DAGScheduler: Job 7 finished: csv at <unknown>:0, took 0.025931 s
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:37:05 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:37:05 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:37:05 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:37:05 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:37:05 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 254.9 KB, free 412.7 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.1 KB, free 412.7 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51302 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 15 from sql at <unknown>:0
20/02/19 06:37:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:51302 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 294
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 291
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 326
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 293
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 295
20/02/19 06:37:05 INFO ContextCleaner: Cleaned accumulator 292
20/02/19 06:37:05 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:51302 in memory (size: 7.9 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:37:05 INFO DAGScheduler: Registering RDD 46 (sql at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:37:05 INFO DAGScheduler: Final stage: ResultStage 11 (sql at <unknown>:0)
20/02/19 06:37:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
20/02/19 06:37:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
20/02/19 06:37:05 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0), which has no missing parents
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 17.5 KB, free 413.0 MB)
20/02/19 06:37:05 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.0 MB)
20/02/19 06:37:05 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51302 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:37:05 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:05 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/19 06:37:05 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:37:05 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/19 06:37:06 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpUP2cIF/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:37:06 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:37:06 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 71.8 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:51302 (size: 71.8 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2461 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 47 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ShuffleMapStage 10 (sql at <unknown>:0) finished in 0.047 s
20/02/19 06:37:06 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:37:06 INFO DAGScheduler: running: Set()
20/02/19 06:37:06 INFO DAGScheduler: waiting: Set(ResultStage 11)
20/02/19 06:37:06 INFO DAGScheduler: failed: Set()
20/02/19 06:37:06 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51302 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1495 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ResultStage 11 (sql at <unknown>:0) finished in 0.005 s
20/02/19 06:37:06 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.062680 s
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 333
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 335
20/02/19 06:37:06 INFO ContextCleaner: Cleaned shuffle 2
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 328
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 329
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 334
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 337
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:51302 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 327
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 338
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 330
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 332
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 387
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 336
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:51302 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 331
20/02/19 06:37:06 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:37:06 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
20/02/19 06:37:06 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:37:06 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
20/02/19 06:37:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/02/19 06:37:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/02/19 06:37:06 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 17.5 KB, free 412.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.1 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51302 (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/19 06:37:06 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1694 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.009 s
20/02/19 06:37:06 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:37:06 INFO DAGScheduler: running: Set()
20/02/19 06:37:06 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/02/19 06:37:06 INFO DAGScheduler: failed: Set()
20/02/19 06:37:06 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51302 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1495 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:37:06 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.024351 s
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz2`
WHERE (0 = 1)
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 5.7049 ms
20/02/19 06:37:06 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:37:06 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:37:06 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
20/02/19 06:37:06 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:06 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:06 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:51302 in memory (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:51302 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.7 KB, free 412.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:51302 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/02/19 06:37:06 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 16.5491 ms
20/02/19 06:37:06 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_15_0]
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1385 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 50 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.050 s
20/02/19 06:37:06 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.064970 s
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:37:06 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:51302 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 473
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 475
20/02/19 06:37:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:37:06 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:37:06 INFO DAGScheduler: Got job 11 (run at <unknown>:0) with 1 output partitions
20/02/19 06:37:06 INFO DAGScheduler: Final stage: ResultStage 15 (run at <unknown>:0)
20/02/19 06:37:06 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:37:06 INFO DAGScheduler: Missing parents: List()
20/02/19 06:37:06 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KB, free 412.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:51302 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/02/19 06:37:06 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 41383 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ResultStage 15 (run at <unknown>:0) finished in 0.015 s
20/02/19 06:37:06 INFO DAGScheduler: Job 11 finished: run at <unknown>:0, took 0.022567 s
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 23.8034 ms
20/02/19 06:37:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 6.2493 ms
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 81
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:51302 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 122
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 121
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 82
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 117
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 83
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 115
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 125
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51302 in memory (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 124
20/02/19 06:37:06 INFO ContextCleaner: Cleaned shuffle 0
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 116
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 118
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 123
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 120
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 126
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 80
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 119
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 0
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51302 in memory (size: 3.3 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51302 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:37:06 INFO ContextCleaner: Cleaned accumulator 79
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 4.3 MB, free 409.0 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 95.3 KB, free 408.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:51302 (size: 95.3 KB, free: 413.6 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 22 from run at <unknown>:0
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 24.5551 ms
20/02/19 06:37:06 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:37:06 INFO DAGScheduler: Registering RDD 62 (collect at utils.scala:204)
20/02/19 06:37:06 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:37:06 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:204)
20/02/19 06:37:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
20/02/19 06:37:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
20/02/19 06:37:06 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.3 KB, free 408.9 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.3 KB, free 408.9 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:51302 (size: 13.3 KB, free: 413.6 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
20/02/19 06:37:06 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 7.0803 ms
20/02/19 06:37:06 INFO CodeGenerator: Code generated in 3.7837 ms
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2495 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 67 ms on localhost (executor driver) (1/1)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:204) finished in 0.068 s
20/02/19 06:37:06 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:37:06 INFO DAGScheduler: running: Set()
20/02/19 06:37:06 INFO DAGScheduler: waiting: Set(ResultStage 17)
20/02/19 06:37:06 INFO DAGScheduler: failed: Set()
20/02/19 06:37:06 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204), which has no missing parents
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 17.7 KB, free 408.8 MB)
20/02/19 06:37:06 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.1 KB, free 408.8 MB)
20/02/19 06:37:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:51302 (size: 8.1 KB, free: 413.6 MB)
20/02/19 06:37:06 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
20/02/19 06:37:06 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:37:06 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
20/02/19 06:37:06 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:37:06 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 18, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:37:06 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:37:06 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 20, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:37:06 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
20/02/19 06:37:06 INFO Executor: Running task 1.0 in stage 17.0 (TID 18)
20/02/19 06:37:06 INFO Executor: Running task 3.0 in stage 17.0 (TID 20)
20/02/19 06:37:06 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:37:06 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2800 bytes result sent to driver
20/02/19 06:37:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/19 06:37:06 INFO Executor: Finished task 3.0 in stage 17.0 (TID 20). 2744 bytes result sent to driver
20/02/19 06:37:06 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2773 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 15 ms on localhost (executor driver) (1/4)
20/02/19 06:37:06 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 15 ms on localhost (executor driver) (2/4)
20/02/19 06:37:06 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 20) in 14 ms on localhost (executor driver) (3/4)
20/02/19 06:37:06 INFO Executor: Finished task 1.0 in stage 17.0 (TID 18). 2793 bytes result sent to driver
20/02/19 06:37:06 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 18) in 18 ms on localhost (executor driver) (4/4)
20/02/19 06:37:06 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/19 06:37:06 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:204) finished in 0.020 s
20/02/19 06:37:06 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.106984 s
20/02/19 06:37:08 INFO SparkContext: Invoking stop() from shutdown hook
20/02/19 06:37:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/19 06:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/19 06:37:08 INFO MemoryStore: MemoryStore cleared
20/02/19 06:37:08 INFO BlockManager: BlockManager stopped
20/02/19 06:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/19 06:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/19 06:37:08 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1944)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1943)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:37:08 INFO SparkContext: Successfully stopped SparkContext
20/02/19 06:37:08 INFO ShutdownHookManager: Shutdown hook called
20/02/19 06:37:08 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3
20/02/19 06:37:08 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac\userFiles-6af71d1c-a906-46c8-9f8d-20883459d3a3
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:37:08 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac
20/02/19 06:37:08 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-97f0012e-0ce2-47e8-86e1-b27c532b59ac
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:38:12 INFO SparkContext: Running Spark version 2.2.1
20/02/19 06:38:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/19 06:38:13 INFO SparkContext: Submitted application: sparklyr
20/02/19 06:38:13 INFO SecurityManager: Changing view acls to: Reinhard
20/02/19 06:38:13 INFO SecurityManager: Changing modify acls to: Reinhard
20/02/19 06:38:13 INFO SecurityManager: Changing view acls groups to: 
20/02/19 06:38:13 INFO SecurityManager: Changing modify acls groups to: 
20/02/19 06:38:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Reinhard); groups with view permissions: Set(); users  with modify permissions: Set(Reinhard); groups with modify permissions: Set()
20/02/19 06:38:13 INFO Utils: Successfully started service 'sparkDriver' on port 51515.
20/02/19 06:38:13 INFO SparkEnv: Registering MapOutputTracker
20/02/19 06:38:13 INFO SparkEnv: Registering BlockManagerMaster
20/02/19 06:38:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/19 06:38:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/19 06:38:13 INFO DiskBlockManager: Created local directory at C:\Users\Reinhard\AppData\Local\Temp\blockmgr-2d945b70-31ad-48a6-8c6f-50c2d63aa829
20/02/19 06:38:13 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
20/02/19 06:38:13 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/19 06:38:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/19 06:38:13 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/19 06:38:13 INFO SparkContext: Added JAR file:/D:/apps/R/R-3.6.1/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:51515/jars/sparklyr-2.0-2.11.jar with timestamp 1582090693608
20/02/19 06:38:13 INFO Executor: Starting executor ID driver on host localhost
20/02/19 06:38:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51538.
20/02/19 06:38:13 INFO NettyBlockTransferService: Server created on 127.0.0.1:51538
20/02/19 06:38:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/19 06:38:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51538, None)
20/02/19 06:38:13 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51538 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 51538, None)
20/02/19 06:38:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51538, None)
20/02/19 06:38:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51538, None)
20/02/19 06:38:13 INFO SharedState: loading hive config file: file:/C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/conf/hive-site.xml
20/02/19 06:38:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive').
20/02/19 06:38:13 INFO SharedState: Warehouse path is 'C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive'.
20/02/19 06:38:14 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/02/19 06:38:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:38:16 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:38:16 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:38:16 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
20/02/19 06:38:16 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:16 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
20/02/19 06:38:16 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/19 06:38:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 413.9 MB)
20/02/19 06:38:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.9 MB)
20/02/19 06:38:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51538 (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:38:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/19 06:38:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
20/02/19 06:38:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/19 06:38:16 INFO Executor: Fetching spark://127.0.0.1:51515/jars/sparklyr-2.0-2.11.jar with timestamp 1582090693608
20/02/19 06:38:16 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51515 after 11 ms (0 ms spent in bootstraps)
20/02/19 06:38:16 INFO Utils: Fetching spark://127.0.0.1:51515/jars/sparklyr-2.0-2.11.jar to C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6\fetchFileTemp5552432341452322983.tmp
20/02/19 06:38:17 INFO Executor: Adding file:/C:/Users/Reinhard/AppData/Local/Temp/spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9/userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6/sparklyr-2.0-2.11.jar to class loader
20/02/19 06:38:17 INFO CodeGenerator: Code generated in 158.4202 ms
20/02/19 06:38:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
20/02/19 06:38:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 600 ms on localhost (executor driver) (1/1)
20/02/19 06:38:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/19 06:38:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.622 s
20/02/19 06:38:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.816433 s
20/02/19 06:38:17 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:17 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
20/02/19 06:38:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:38:17 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:17 INFO CodeGenerator: Code generated in 6.0368 ms
20/02/19 06:38:17 INFO CodeGenerator: Code generated in 11.9332 ms
20/02/19 06:38:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 253.9 KB, free 413.7 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.6 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51538 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 1 from csv at <unknown>:0
20/02/19 06:38:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:18 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:38:18 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:38:18 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
20/02/19 06:38:18 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:18 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0), which has no missing parents
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 413.6 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.6 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51538 (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/19 06:38:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/19 06:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 5.9939 ms
20/02/19 06:38:18 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1275 bytes result sent to driver
20/02/19 06:38:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 59 ms on localhost (executor driver) (1/1)
20/02/19 06:38:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/19 06:38:18 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 0.060 s
20/02/19 06:38:18 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 0.080230 s
20/02/19 06:38:18 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:18 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:38:18 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:38:18 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 4.3769 ms
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 253.9 KB, free 413.4 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.4 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51538 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 3 from csv at <unknown>:0
20/02/19 06:38:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51538 in memory (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 49
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 51
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 54
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 53
20/02/19 06:38:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:51538 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 50
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 52
20/02/19 06:38:18 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:38:18 INFO DAGScheduler: Got job 2 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:38:18 INFO DAGScheduler: Final stage: ResultStage 2 (csv at <unknown>:0)
20/02/19 06:38:18 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:18 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0), which has no missing parents
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.9 KB, free 413.6 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.6 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51538 (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/19 06:38:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/19 06:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:38:18 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1567 bytes result sent to driver
20/02/19 06:38:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 89 ms on localhost (executor driver) (1/1)
20/02/19 06:38:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/19 06:38:18 INFO DAGScheduler: ResultStage 2 (csv at <unknown>:0) finished in 0.090 s
20/02/19 06:38:18 INFO DAGScheduler: Job 2 finished: csv at <unknown>:0, took 0.102936 s
20/02/19 06:38:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 5.4077 ms
20/02/19 06:38:18 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:38:18 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:38:18 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:38:18 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:18 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:38:18 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:38:18 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 254.9 KB, free 413.4 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51538 in memory (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.4 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51538 (size: 24.1 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 5 from sql at <unknown>:0
20/02/19 06:38:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 8.5571 ms
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 6.0778 ms
20/02/19 06:38:18 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:38:18 INFO DAGScheduler: Registering RDD 18 (sql at <unknown>:0)
20/02/19 06:38:18 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:38:18 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
20/02/19 06:38:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/19 06:38:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/19 06:38:18 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 413.4 MB)
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 114
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51538 (size: 9.0 KB, free: 413.9 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/19 06:38:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:38:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/19 06:38:18 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 5.8388 ms
20/02/19 06:38:18 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:18 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 71.5 KB, free 413.3 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:51538 (size: 71.5 KB, free: 413.8 MB)
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 2.9577 ms
20/02/19 06:38:18 INFO CodeGenerator: Code generated in 11.661 ms
20/02/19 06:38:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
20/02/19 06:38:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 200 ms on localhost (executor driver) (1/1)
20/02/19 06:38:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/19 06:38:18 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 0.202 s
20/02/19 06:38:18 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:38:18 INFO DAGScheduler: running: Set()
20/02/19 06:38:18 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/19 06:38:18 INFO DAGScheduler: failed: Set()
20/02/19 06:38:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0), which has no missing parents
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:38:18 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:38:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51538 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:38:18 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/19 06:38:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:38:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/19 06:38:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/02/19 06:38:18 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
20/02/19 06:38:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 32 ms on localhost (executor driver) (1/1)
20/02/19 06:38:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/19 06:38:18 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.032 s
20/02/19 06:38:18 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 0.282971 s
20/02/19 06:38:18 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:38:18 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51538 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:38:18 INFO ContextCleaner: Cleaned accumulator 175
20/02/19 06:38:19 INFO CodeGenerator: Code generated in 3.78 ms
20/02/19 06:38:19 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:38:19 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
20/02/19 06:38:19 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
20/02/19 06:38:19 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 413.3 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51538 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/19 06:38:19 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1737 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
20/02/19 06:38:19 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:38:19 INFO DAGScheduler: running: Set()
20/02/19 06:38:19 INFO DAGScheduler: waiting: Set(ResultStage 6)
20/02/19 06:38:19 INFO DAGScheduler: failed: Set()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 413.2 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.2 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51538 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1495 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:38:19 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.035669 s
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz1`
WHERE (0 = 1)
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:51538 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51538 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO CodeGenerator: Code generated in 4.2204 ms
20/02/19 06:38:19 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:38:19 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.9 KB, free 413.3 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.3 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51538 (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 851 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.004 s
20/02/19 06:38:19 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.010266 s
20/02/19 06:38:19 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:19 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#102)) > 0)
20/02/19 06:38:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:38:19 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 253.9 KB, free 413.0 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.0 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51538 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 11 from csv at <unknown>:0
20/02/19 06:38:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 236
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51538 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:38:19 INFO DAGScheduler: Got job 6 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 8 (csv at <unknown>:0)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 413.0 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.0 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51538 (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/19 06:38:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:38:19 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1232 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 8 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:38:19 INFO DAGScheduler: Job 6 finished: csv at <unknown>:0, took 0.011141 s
20/02/19 06:38:19 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:19 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:38:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:38:19 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 253.9 KB, free 412.7 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 412.7 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51538 (size: 23.9 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 13 from csv at <unknown>:0
20/02/19 06:38:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:19 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:38:19 INFO DAGScheduler: Got job 7 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 9 (csv at <unknown>:0)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 13.9 KB, free 412.7 MB)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 118
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 121
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 262
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 264
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.9 KB, free 412.7 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51538 (size: 7.9 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51538 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 265
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 266
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 263
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51538 in memory (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 261
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 125
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 115
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 82
20/02/19 06:38:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:38:19 INFO ContextCleaner: Cleaned shuffle 0
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 126
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 81
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 79
20/02/19 06:38:19 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51538 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 80
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 119
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51538 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 0
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 122
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51538 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 124
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 120
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 123
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 116
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 117
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 83
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1481 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 17 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 9 (csv at <unknown>:0) finished in 0.017 s
20/02/19 06:38:19 INFO DAGScheduler: Job 7 finished: csv at <unknown>:0, took 0.071658 s
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:38:19 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:38:19 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:38:19 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:38:19 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 254.9 KB, free 413.0 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.0 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51538 (size: 24.1 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 15 from sql at <unknown>:0
20/02/19 06:38:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:38:19 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:38:19 INFO DAGScheduler: Registering RDD 46 (sql at <unknown>:0)
20/02/19 06:38:19 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 11 (sql at <unknown>:0)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
20/02/19 06:38:19 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 17.5 KB, free 413.0 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.0 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51538 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/19 06:38:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpWuO5HO/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:38:19 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 326
20/02/19 06:38:19 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 71.8 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:51538 (size: 71.8 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2461 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 119 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ShuffleMapStage 10 (sql at <unknown>:0) finished in 0.120 s
20/02/19 06:38:19 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:38:19 INFO DAGScheduler: running: Set()
20/02/19 06:38:19 INFO DAGScheduler: waiting: Set(ResultStage 11)
20/02/19 06:38:19 INFO DAGScheduler: failed: Set()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51538 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1495 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 6 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 11 (sql at <unknown>:0) finished in 0.006 s
20/02/19 06:38:19 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.139524 s
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:38:19 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:38:19 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
20/02/19 06:38:19 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/02/19 06:38:19 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 17.5 KB, free 412.9 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.1 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51538 (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/19 06:38:19 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1737 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.008 s
20/02/19 06:38:19 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:38:19 INFO DAGScheduler: running: Set()
20/02/19 06:38:19 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/02/19 06:38:19 INFO DAGScheduler: failed: Set()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 412.9 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51538 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1495 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.004 s
20/02/19 06:38:19 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.024772 s
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz2`
WHERE (0 = 1)
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:38:19 INFO CodeGenerator: Code generated in 5.7013 ms
20/02/19 06:38:19 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:38:19 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.7 KB, free 412.9 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:51538 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/02/19 06:38:19 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:51538 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO ContextCleaner: Cleaned accumulator 387
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:51538 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:51538 in memory (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO CodeGenerator: Code generated in 9.1691 ms
20/02/19 06:38:19 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_15_0]
20/02/19 06:38:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1385 bytes result sent to driver
20/02/19 06:38:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 35 ms on localhost (executor driver) (1/1)
20/02/19 06:38:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/19 06:38:19 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.035 s
20/02/19 06:38:19 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.041596 s
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:38:19 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:38:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:38:19 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:38:19 INFO DAGScheduler: Got job 11 (run at <unknown>:0) with 1 output partitions
20/02/19 06:38:19 INFO DAGScheduler: Final stage: ResultStage 15 (run at <unknown>:0)
20/02/19 06:38:19 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:38:19 INFO DAGScheduler: Missing parents: List()
20/02/19 06:38:19 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0), which has no missing parents
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KB, free 412.9 MB)
20/02/19 06:38:19 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.6 KB, free 412.9 MB)
20/02/19 06:38:19 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:51538 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:38:19 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:19 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/19 06:38:19 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:38:19 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/02/19 06:38:19 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:38:20 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 41426 bytes result sent to driver
20/02/19 06:38:20 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 14 ms on localhost (executor driver) (1/1)
20/02/19 06:38:20 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/19 06:38:20 INFO DAGScheduler: ResultStage 15 (run at <unknown>:0) finished in 0.015 s
20/02/19 06:38:20 INFO DAGScheduler: Job 11 finished: run at <unknown>:0, took 0.023812 s
20/02/19 06:38:20 INFO CodeGenerator: Code generated in 25.2261 ms
20/02/19 06:38:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:38:20 INFO CodeGenerator: Code generated in 4.2452 ms
20/02/19 06:38:20 INFO ContextCleaner: Cleaned accumulator 473
20/02/19 06:38:20 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:51538 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:38:20 INFO ContextCleaner: Cleaned accumulator 475
20/02/19 06:38:20 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:51538 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 4.3 MB, free 408.7 MB)
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 95.3 KB, free 408.6 MB)
20/02/19 06:38:20 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:51538 (size: 95.3 KB, free: 413.6 MB)
20/02/19 06:38:20 INFO SparkContext: Created broadcast 22 from run at <unknown>:0
20/02/19 06:38:20 INFO CodeGenerator: Code generated in 14.7423 ms
20/02/19 06:38:20 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:38:20 INFO DAGScheduler: Registering RDD 62 (collect at utils.scala:204)
20/02/19 06:38:20 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:38:20 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:204)
20/02/19 06:38:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
20/02/19 06:38:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
20/02/19 06:38:20 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.3 KB, free 408.6 MB)
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.3 KB, free 408.5 MB)
20/02/19 06:38:20 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:51538 (size: 13.3 KB, free: 413.6 MB)
20/02/19 06:38:20 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:38:20 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/19 06:38:20 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:38:20 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
20/02/19 06:38:20 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:38:20 INFO CodeGenerator: Code generated in 6.0149 ms
20/02/19 06:38:20 INFO CodeGenerator: Code generated in 3.2952 ms
20/02/19 06:38:20 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2495 bytes result sent to driver
20/02/19 06:38:20 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 53 ms on localhost (executor driver) (1/1)
20/02/19 06:38:20 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/19 06:38:20 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:204) finished in 0.054 s
20/02/19 06:38:20 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:38:20 INFO DAGScheduler: running: Set()
20/02/19 06:38:20 INFO DAGScheduler: waiting: Set(ResultStage 17)
20/02/19 06:38:20 INFO DAGScheduler: failed: Set()
20/02/19 06:38:20 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204), which has no missing parents
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 17.7 KB, free 408.5 MB)
20/02/19 06:38:20 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.1 KB, free 408.5 MB)
20/02/19 06:38:20 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:51538 (size: 8.1 KB, free: 413.6 MB)
20/02/19 06:38:20 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
20/02/19 06:38:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:38:20 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
20/02/19 06:38:20 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:38:20 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 18, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:38:20 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:38:20 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 20, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:38:20 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
20/02/19 06:38:20 INFO Executor: Running task 1.0 in stage 17.0 (TID 18)
20/02/19 06:38:20 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
20/02/19 06:38:20 INFO Executor: Running task 3.0 in stage 17.0 (TID 20)
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:38:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:38:20 INFO Executor: Finished task 1.0 in stage 17.0 (TID 18). 2750 bytes result sent to driver
20/02/19 06:38:20 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2800 bytes result sent to driver
20/02/19 06:38:20 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2773 bytes result sent to driver
20/02/19 06:38:20 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 18) in 14 ms on localhost (executor driver) (1/4)
20/02/19 06:38:20 INFO Executor: Finished task 3.0 in stage 17.0 (TID 20). 2744 bytes result sent to driver
20/02/19 06:38:20 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 14 ms on localhost (executor driver) (2/4)
20/02/19 06:38:20 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 13 ms on localhost (executor driver) (3/4)
20/02/19 06:38:20 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 20) in 14 ms on localhost (executor driver) (4/4)
20/02/19 06:38:20 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/19 06:38:20 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:204) finished in 0.015 s
20/02/19 06:38:20 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.082252 s
20/02/19 06:38:21 INFO SparkContext: Invoking stop() from shutdown hook
20/02/19 06:38:21 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/19 06:38:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/19 06:38:21 INFO MemoryStore: MemoryStore cleared
20/02/19 06:38:21 INFO BlockManager: BlockManager stopped
20/02/19 06:38:21 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/19 06:38:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/19 06:38:21 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1944)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1943)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:38:21 INFO SparkContext: Successfully stopped SparkContext
20/02/19 06:38:21 INFO ShutdownHookManager: Shutdown hook called
20/02/19 06:38:21 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9
20/02/19 06:38:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:38:21 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6
20/02/19 06:38:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-fb96c4b0-7313-4124-9c21-5f8e02b641c9\userFiles-c470bb05-9083-4113-b00c-cd0f1dd786a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:43:40 INFO SparkContext: Running Spark version 2.2.1
20/02/19 06:43:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/19 06:43:41 INFO SparkContext: Submitted application: sparklyr
20/02/19 06:43:41 INFO SecurityManager: Changing view acls to: Reinhard
20/02/19 06:43:41 INFO SecurityManager: Changing modify acls to: Reinhard
20/02/19 06:43:41 INFO SecurityManager: Changing view acls groups to: 
20/02/19 06:43:41 INFO SecurityManager: Changing modify acls groups to: 
20/02/19 06:43:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Reinhard); groups with view permissions: Set(); users  with modify permissions: Set(Reinhard); groups with modify permissions: Set()
20/02/19 06:43:41 INFO Utils: Successfully started service 'sparkDriver' on port 52189.
20/02/19 06:43:41 INFO SparkEnv: Registering MapOutputTracker
20/02/19 06:43:41 INFO SparkEnv: Registering BlockManagerMaster
20/02/19 06:43:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/19 06:43:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/19 06:43:41 INFO DiskBlockManager: Created local directory at C:\Users\Reinhard\AppData\Local\Temp\blockmgr-baffe4ac-4da7-47bd-a550-794544c53f3b
20/02/19 06:43:41 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
20/02/19 06:43:41 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/19 06:43:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/19 06:43:41 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/19 06:43:41 INFO SparkContext: Added JAR file:/D:/apps/R/R-3.6.1/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:52189/jars/sparklyr-2.0-2.11.jar with timestamp 1582091021617
20/02/19 06:43:41 INFO Executor: Starting executor ID driver on host localhost
20/02/19 06:43:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52210.
20/02/19 06:43:41 INFO NettyBlockTransferService: Server created on 127.0.0.1:52210
20/02/19 06:43:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/19 06:43:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52210, None)
20/02/19 06:43:41 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52210 with 413.9 MB RAM, BlockManagerId(driver, 127.0.0.1, 52210, None)
20/02/19 06:43:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52210, None)
20/02/19 06:43:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52210, None)
20/02/19 06:43:42 INFO SharedState: loading hive config file: file:/C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/conf/hive-site.xml
20/02/19 06:43:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive').
20/02/19 06:43:42 INFO SharedState: Warehouse path is 'C:/Users/Reinhard/AppData/Local/spark/spark-2.2.1-bin-hadoop2.7/tmp/hive'.
20/02/19 06:43:42 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/02/19 06:43:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:43:45 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:43:45 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:43:45 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
20/02/19 06:43:45 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:45 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
20/02/19 06:43:45 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/19 06:43:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 413.9 MB)
20/02/19 06:43:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.9 MB)
20/02/19 06:43:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52210 (size: 3.3 KB, free: 413.9 MB)
20/02/19 06:43:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/19 06:43:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
20/02/19 06:43:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/19 06:43:45 INFO Executor: Fetching spark://127.0.0.1:52189/jars/sparklyr-2.0-2.11.jar with timestamp 1582091021617
20/02/19 06:43:45 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52189 after 16 ms (0 ms spent in bootstraps)
20/02/19 06:43:45 INFO Utils: Fetching spark://127.0.0.1:52189/jars/sparklyr-2.0-2.11.jar to C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2\fetchFileTemp3483061655609548643.tmp
20/02/19 06:43:45 INFO Executor: Adding file:/C:/Users/Reinhard/AppData/Local/Temp/spark-689f6ed2-8447-4ed4-a020-d8d684f7b266/userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2/sparklyr-2.0-2.11.jar to class loader
20/02/19 06:43:46 INFO CodeGenerator: Code generated in 240.3975 ms
20/02/19 06:43:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
20/02/19 06:43:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 790 ms on localhost (executor driver) (1/1)
20/02/19 06:43:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/19 06:43:46 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.816 s
20/02/19 06:43:46 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1.090519 s
20/02/19 06:43:46 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
20/02/19 06:43:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:43:46 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:46 INFO CodeGenerator: Code generated in 6.4837 ms
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 17.6938 ms
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 253.9 KB, free 413.7 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.6 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52210 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 1 from csv at <unknown>:0
20/02/19 06:43:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:47 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:43:47 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:43:47 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
20/02/19 06:43:47 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:47 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:47 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0), which has no missing parents
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 413.6 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.6 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52210 (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/19 06:43:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/19 06:43:47 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 9.7273 ms
20/02/19 06:43:47 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1232 bytes result sent to driver
20/02/19 06:43:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 84 ms on localhost (executor driver) (1/1)
20/02/19 06:43:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/19 06:43:47 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 0.085 s
20/02/19 06:43:47 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 0.107826 s
20/02/19 06:43:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:52210 in memory (size: 4.3 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52210 in memory (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:47 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:43:47 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:43:47 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 4.1784 ms
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 253.9 KB, free 413.7 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.6 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52210 (size: 23.9 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 3 from csv at <unknown>:0
20/02/19 06:43:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:47 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:43:47 INFO DAGScheduler: Got job 2 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:43:47 INFO DAGScheduler: Final stage: ResultStage 2 (csv at <unknown>:0)
20/02/19 06:43:47 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:47 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0), which has no missing parents
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.9 KB, free 413.6 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.6 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52210 (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/19 06:43:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/19 06:43:47 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:43:47 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1524 bytes result sent to driver
20/02/19 06:43:47 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 98 ms on localhost (executor driver) (1/1)
20/02/19 06:43:47 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/19 06:43:47 INFO DAGScheduler: ResultStage 2 (csv at <unknown>:0) finished in 0.100 s
20/02/19 06:43:47 INFO DAGScheduler: Job 2 finished: csv at <unknown>:0, took 0.109967 s
20/02/19 06:43:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 5.6287 ms
20/02/19 06:43:47 INFO SparkSqlParser: Parsing command: ref_tab
20/02/19 06:43:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `ref_tab`
20/02/19 06:43:47 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:52210 in memory (size: 7.9 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkSqlParser: Parsing command: `ref_tab`
20/02/19 06:43:47 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:47 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:43:47 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:43:47 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 254.9 KB, free 413.4 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.1 KB, free 413.4 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52210 (size: 24.1 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 5 from sql at <unknown>:0
20/02/19 06:43:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 8.0539 ms
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 7.6895 ms
20/02/19 06:43:47 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:43:47 INFO ContextCleaner: Cleaned accumulator 114
20/02/19 06:43:47 INFO DAGScheduler: Registering RDD 18 (sql at <unknown>:0)
20/02/19 06:43:47 INFO DAGScheduler: Got job 3 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:43:47 INFO DAGScheduler: Final stage: ResultStage 4 (sql at <unknown>:0)
20/02/19 06:43:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/19 06:43:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/19 06:43:47 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.5 KB, free 413.4 MB)
20/02/19 06:43:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:43:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52210 (size: 9.0 KB, free: 413.9 MB)
20/02/19 06:43:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:47 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/19 06:43:47 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:43:47 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/19 06:43:47 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/ref.tab.gz, range: 0-20021, partition values: [empty row]
20/02/19 06:43:47 INFO CodeGenerator: Code generated in 5.5943 ms
20/02/19 06:43:47 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:48 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 71.5 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:52210 (size: 71.5 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO CodeGenerator: Code generated in 2.9275 ms
20/02/19 06:43:48 INFO CodeGenerator: Code generated in 14.0617 ms
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 208 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) finished in 0.210 s
20/02/19 06:43:48 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:43:48 INFO DAGScheduler: running: Set()
20/02/19 06:43:48 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/19 06:43:48 INFO DAGScheduler: failed: Set()
20/02/19 06:43:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52210 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/19 06:43:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 47 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ResultStage 4 (sql at <unknown>:0) finished in 0.048 s
20/02/19 06:43:48 INFO DAGScheduler: Job 3 finished: sql at <unknown>:0, took 0.307152 s
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `ref_tab`
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:52210 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52210 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO CodeGenerator: Code generated in 3.9791 ms
20/02/19 06:43:48 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:43:48 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
20/02/19 06:43:48 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:43:48 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
20/02/19 06:43:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/02/19 06:43:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
20/02/19 06:43:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.5 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52210 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/19 06:43:48 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1694 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 13 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
20/02/19 06:43:48 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:43:48 INFO DAGScheduler: running: Set()
20/02/19 06:43:48 INFO DAGScheduler: waiting: Set(ResultStage 6)
20/02/19 06:43:48 INFO DAGScheduler: failed: Set()
20/02/19 06:43:48 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:52210 (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/19 06:43:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1495 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
20/02/19 06:43:48 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.031853 s
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `ref_tab` AS `zzz1`
WHERE (0 = 1)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 119
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:52210 in memory (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 175
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:52210 in memory (size: 3.7 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 124
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 126
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 125
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 117
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 82
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 79
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 123
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 115
20/02/19 06:43:48 INFO ContextCleaner: Cleaned shuffle 0
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 52
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 81
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 116
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 53
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 83
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:52210 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 54
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 50
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 80
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 122
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 120
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52210 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 118
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 49
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 51
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 121
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 0
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:43:48 INFO CodeGenerator: Code generated in 5.0212 ms
20/02/19 06:43:48 INFO SparkContext: Starting job: collect at utils.scala:44
20/02/19 06:43:48 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
20/02/19 06:43:48 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
20/02/19 06:43:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.9 KB, free 413.6 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.3 KB, free 413.6 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:52210 (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 937 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.005 s
20/02/19 06:43:48 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.010263 s
20/02/19 06:43:48 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:48 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#102)) > 0)
20/02/19 06:43:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:43:48 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 253.9 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:52210 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 11 from csv at <unknown>:0
20/02/19 06:43:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:48 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:43:48 INFO DAGScheduler: Got job 6 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:43:48 INFO DAGScheduler: Final stage: ResultStage 8 (csv at <unknown>:0)
20/02/19 06:43:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:48 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:52210 in memory (size: 3.3 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 236
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:52210 (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/19 06:43:48 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:43:48 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1189 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ResultStage 8 (csv at <unknown>:0) finished in 0.006 s
20/02/19 06:43:48 INFO DAGScheduler: Job 6 finished: csv at <unknown>:0, took 0.023535 s
20/02/19 06:43:48 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:48 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:43:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
20/02/19 06:43:48 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 253.9 KB, free 413.1 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 413.0 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:52210 (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 13 from csv at <unknown>:0
20/02/19 06:43:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:48 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/19 06:43:48 INFO DAGScheduler: Got job 7 (csv at <unknown>:0) with 1 output partitions
20/02/19 06:43:48 INFO DAGScheduler: Final stage: ResultStage 9 (csv at <unknown>:0)
20/02/19 06:43:48 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:48 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 13.9 KB, free 413.0 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.9 KB, free 413.0 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:52210 (size: 7.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/19 06:43:48 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:43:48 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1481 bytes result sent to driver
20/02/19 06:43:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 17 ms on localhost (executor driver) (1/1)
20/02/19 06:43:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/19 06:43:48 INFO DAGScheduler: ResultStage 9 (csv at <unknown>:0) finished in 0.018 s
20/02/19 06:43:48 INFO DAGScheduler: Job 7 finished: csv at <unknown>:0, took 0.023540 s
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: mut_tab
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: CACHE TABLE `mut_tab`
20/02/19 06:43:48 INFO SparkSqlParser: Parsing command: `mut_tab`
20/02/19 06:43:48 INFO FileSourceStrategy: Pruning directories with: 
20/02/19 06:43:48 INFO FileSourceStrategy: Post-Scan Filters: 
20/02/19 06:43:48 INFO FileSourceStrategy: Output Data Schema: struct<kmer: string, count: int>
20/02/19 06:43:48 INFO FileSourceScanExec: Pushed Filters: 
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 254.9 KB, free 412.8 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.1 KB, free 412.7 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:52210 (size: 24.1 KB, free: 413.7 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 15 from sql at <unknown>:0
20/02/19 06:43:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 262
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 265
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:52210 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 291
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 264
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:52210 in memory (size: 4.3 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 294
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 261
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 326
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 266
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 293
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 263
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 292
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:52210 in memory (size: 7.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO ContextCleaner: Cleaned accumulator 295
20/02/19 06:43:48 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:52210 in memory (size: 23.9 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/19 06:43:48 INFO DAGScheduler: Registering RDD 46 (sql at <unknown>:0)
20/02/19 06:43:48 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
20/02/19 06:43:48 INFO DAGScheduler: Final stage: ResultStage 11 (sql at <unknown>:0)
20/02/19 06:43:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
20/02/19 06:43:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
20/02/19 06:43:48 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0), which has no missing parents
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 17.5 KB, free 413.3 MB)
20/02/19 06:43:48 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.0 KB, free 413.3 MB)
20/02/19 06:43:48 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:52210 (size: 9.0 KB, free: 413.8 MB)
20/02/19 06:43:48 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/19 06:43:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:43:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/19 06:43:48 INFO FileScanRDD: Reading File path: file:///C:/Users/Reinhard/AppData/Local/Temp/RtmpkXmwex/mut.tab.gz, range: 0-19783, partition values: [empty row]
20/02/19 06:43:48 INFO CodecPool: Got brand-new decompressor [.gz]
20/02/19 06:43:49 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 71.8 KB, free 413.2 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:52210 (size: 71.8 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2418 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 97 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ShuffleMapStage 10 (sql at <unknown>:0) finished in 0.102 s
20/02/19 06:43:49 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:43:49 INFO DAGScheduler: running: Set()
20/02/19 06:43:49 INFO DAGScheduler: waiting: Set(ResultStage 11)
20/02/19 06:43:49 INFO DAGScheduler: failed: Set()
20/02/19 06:43:49 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 413.2 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.2 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:52210 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1409 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 0 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ResultStage 11 (sql at <unknown>:0) finished in 0.000 s
20/02/19 06:43:49 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 0.137551 s
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `mut_tab`
20/02/19 06:43:49 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:43:49 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
20/02/19 06:43:49 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:43:49 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
20/02/19 06:43:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/02/19 06:43:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/02/19 06:43:49 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 17.5 KB, free 413.2 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.1 KB, free 413.2 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:52210 (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/19 06:43:49 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1694 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 16 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.016 s
20/02/19 06:43:49 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:43:49 INFO DAGScheduler: running: Set()
20/02/19 06:43:49 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/02/19 06:43:49 INFO DAGScheduler: failed: Set()
20/02/19 06:43:49 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 413.2 MB)
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 332
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:52210 in memory (size: 9.0 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 413.2 MB)
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 335
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 387
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:52210 (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 328
20/02/19 06:43:49 INFO ContextCleaner: Cleaned shuffle 2
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 336
20/02/19 06:43:49 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 338
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 327
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 330
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:52210 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 329
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 331
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 333
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 337
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 334
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1409 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 15 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.015 s
20/02/19 06:43:49 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.036174 s
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mut_tab` AS `zzz2`
WHERE (0 = 1)
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
LIMIT 11
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 4.4561 ms
20/02/19 06:43:49 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:43:49 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
20/02/19 06:43:49 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
20/02/19 06:43:49 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:49 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:49 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.7 KB, free 413.2 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.6 KB, free 413.2 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:52210 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/02/19 06:43:49 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 13.3003 ms
20/02/19 06:43:49 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_15_0]
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1342 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 37 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.038 s
20/02/19 06:43:49 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.045353 s
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: SELECT `kmer`
FROM `ref_tab`
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:43:49 INFO SparkSqlParser: Parsing command: (SELECT `kmer`
FROM `ref_tab`)
EXCEPT
(SELECT `kmer`
FROM `mut_tab`)
20/02/19 06:43:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:43:49 INFO SparkContext: Starting job: run at <unknown>:0
20/02/19 06:43:49 INFO DAGScheduler: Got job 11 (run at <unknown>:0) with 1 output partitions
20/02/19 06:43:49 INFO DAGScheduler: Final stage: ResultStage 15 (run at <unknown>:0)
20/02/19 06:43:49 INFO DAGScheduler: Parents of final stage: List()
20/02/19 06:43:49 INFO DAGScheduler: Missing parents: List()
20/02/19 06:43:49 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KB, free 413.2 MB)
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 473
20/02/19 06:43:49 INFO ContextCleaner: Cleaned accumulator 475
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.6 KB, free 413.2 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:52210 (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[59] at run at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:52210 in memory (size: 3.7 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:52210 in memory (size: 9.1 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:52210 in memory (size: 7.6 KB, free: 413.7 MB)
20/02/19 06:43:49 INFO BlockManager: Found block rdd_43_0 locally
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 41383 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 18 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO DAGScheduler: ResultStage 15 (run at <unknown>:0) finished in 0.020 s
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: Job 11 finished: run at <unknown>:0, took 0.034379 s
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 27.7397 ms
20/02/19 06:43:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 4.7985 ms
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 4.3 MB, free 409.0 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 95.3 KB, free 408.9 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:52210 (size: 95.3 KB, free: 413.6 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 22 from run at <unknown>:0
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 14.4956 ms
20/02/19 06:43:49 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:52210 in memory (size: 7.6 KB, free: 413.6 MB)
20/02/19 06:43:49 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/19 06:43:49 INFO DAGScheduler: Registering RDD 62 (collect at utils.scala:204)
20/02/19 06:43:49 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
20/02/19 06:43:49 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:204)
20/02/19 06:43:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
20/02/19 06:43:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
20/02/19 06:43:49 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 28.3 KB, free 408.9 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.3 KB, free 408.9 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:52210 (size: 13.3 KB, free: 413.6 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[62] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5292 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
20/02/19 06:43:49 INFO BlockManager: Found block rdd_15_0 locally
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 5.8954 ms
20/02/19 06:43:49 INFO CodeGenerator: Code generated in 4.1705 ms
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2366 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 46 ms on localhost (executor driver) (1/1)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ShuffleMapStage 16 (collect at utils.scala:204) finished in 0.047 s
20/02/19 06:43:49 INFO DAGScheduler: looking for newly runnable stages
20/02/19 06:43:49 INFO DAGScheduler: running: Set()
20/02/19 06:43:49 INFO DAGScheduler: waiting: Set(ResultStage 17)
20/02/19 06:43:49 INFO DAGScheduler: failed: Set()
20/02/19 06:43:49 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204), which has no missing parents
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 17.7 KB, free 408.8 MB)
20/02/19 06:43:49 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.1 KB, free 408.8 MB)
20/02/19 06:43:49 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:52210 (size: 8.1 KB, free: 413.6 MB)
20/02/19 06:43:49 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
20/02/19 06:43:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[65] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/19 06:43:49 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
20/02/19 06:43:49 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, ANY, 4726 bytes)
20/02/19 06:43:49 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 18, localhost, executor driver, partition 1, ANY, 4726 bytes)
20/02/19 06:43:49 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 19, localhost, executor driver, partition 2, ANY, 4726 bytes)
20/02/19 06:43:49 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 20, localhost, executor driver, partition 3, ANY, 4726 bytes)
20/02/19 06:43:49 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
20/02/19 06:43:49 INFO Executor: Running task 2.0 in stage 17.0 (TID 19)
20/02/19 06:43:49 INFO Executor: Running task 1.0 in stage 17.0 (TID 18)
20/02/19 06:43:49 INFO Executor: Running task 3.0 in stage 17.0 (TID 20)
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
20/02/19 06:43:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/19 06:43:49 INFO Executor: Finished task 2.0 in stage 17.0 (TID 19). 2773 bytes result sent to driver
20/02/19 06:43:49 INFO Executor: Finished task 3.0 in stage 17.0 (TID 20). 2744 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 19) in 11 ms on localhost (executor driver) (1/4)
20/02/19 06:43:49 INFO Executor: Finished task 1.0 in stage 17.0 (TID 18). 2750 bytes result sent to driver
20/02/19 06:43:49 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2843 bytes result sent to driver
20/02/19 06:43:49 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 20) in 12 ms on localhost (executor driver) (2/4)
20/02/19 06:43:49 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 18) in 12 ms on localhost (executor driver) (3/4)
20/02/19 06:43:49 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 13 ms on localhost (executor driver) (4/4)
20/02/19 06:43:49 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/19 06:43:49 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:204) finished in 0.014 s
20/02/19 06:43:49 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.070796 s
20/02/19 06:43:51 INFO SparkContext: Invoking stop() from shutdown hook
20/02/19 06:43:51 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:52210 in memory (size: 8.1 KB, free: 413.6 MB)
20/02/19 06:43:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:52210 in memory (size: 13.3 KB, free: 413.6 MB)
20/02/19 06:43:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/19 06:43:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/19 06:43:51 INFO MemoryStore: MemoryStore cleared
20/02/19 06:43:51 INFO BlockManager: BlockManager stopped
20/02/19 06:43:51 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/19 06:43:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/19 06:43:51 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1944)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1943)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:43:51 INFO SparkContext: Successfully stopped SparkContext
20/02/19 06:43:51 INFO ShutdownHookManager: Shutdown hook called
20/02/19 06:43:51 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266
20/02/19 06:43:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
20/02/19 06:43:51 INFO ShutdownHookManager: Deleting directory C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2
20/02/19 06:43:51 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2
java.io.IOException: Failed to delete: C:\Users\Reinhard\AppData\Local\Temp\spark-689f6ed2-8447-4ed4-a020-d8d684f7b266\userFiles-0d3dd9a1-ee8b-4f47-a681-c768581269d2
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
